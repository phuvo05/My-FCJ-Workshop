<!doctype html><html lang=vi class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=../../../../images/favicon.png type=image/png><title>Ngày 45 - Decoder Transformer & Triển Khai GPT2 :: Báo cáo thực tập</title>
<link href=../../../../css/nucleus.css?1765296067 rel=stylesheet><link href=../../../../css/fontawesome-all.min.css?1765296067 rel=stylesheet><link href=../../../../css/hybrid.css?1765296067 rel=stylesheet><link href=../../../../css/featherlight.min.css?1765296067 rel=stylesheet><link href=../../../../css/perfect-scrollbar.min.css?1765296067 rel=stylesheet><link href=../../../../css/auto-complete.css?1765296067 rel=stylesheet><link href=../../../../css/atom-one-dark-reasonable.css?1765296067 rel=stylesheet><link href=../../../../css/theme.css?1765296067 rel=stylesheet><link href=../../../../css/hugo-theme.css?1765296067 rel=stylesheet><link href=../../../../css/theme-workshop.css?1765296067 rel=stylesheet><script src=../../../../js/jquery-3.3.1.min.js?1765296067></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=../../../../vi/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=../../../../><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=../../../../js/lunr.min.js?1765296067></script><script type=text/javascript src=../../../../js/auto-complete.js?1765296067></script><script type=text/javascript>var baseurl="https://phuvo05.github.io/My-FCJ-Workshop//vi"</script><script type=text/javascript src=../../../../js/search.js?1765296067></script></div><div class=highlightable><ul class=topics><li data-nav-id=/vi/1-worklog/ title=Worklog class="dd-item
parent"><a href=../../../../vi/1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.1-week1/ title="Tuần 1 - Kiến thức Nền tảng Cloud Computing" class=dd-item><a href=../../../../vi/1-worklog/1.1-week1/><b>1.1. </b>Tuần 1 - Kiến thức Nền tảng Cloud Computing
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.1-week1/1.1.1-day01-2025-09-08/ title="Ngày 01 - Giới thiệu về Điện toán Đám mây" class=dd-item><a href=../../../../vi/1-worklog/1.1-week1/1.1.1-day01-2025-09-08/><b>1.1.1. </b>Ngày 01 - Giới thiệu về Điện toán Đám mây
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.1-week1/1.1.2-day02-2025-09-09/ title="Ngày 02 - Hạ tầng Toàn cầu của AWS" class=dd-item><a href=../../../../vi/1-worklog/1.1-week1/1.1.2-day02-2025-09-09/><b>1.1.2. </b>Ngày 02 - Hạ tầng Toàn cầu của AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.1-week1/1.1.3-day03-2025-09-10/ title="Ngày 03 - Công cụ Quản lý AWS" class=dd-item><a href=../../../../vi/1-worklog/1.1-week1/1.1.3-day03-2025-09-10/><b>1.1.3. </b>Ngày 03 - Công cụ Quản lý AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.1-week1/1.1.4-day04-2025-09-11/ title="Ngày 04 - Tối ưu Chi phí trên AWS" class=dd-item><a href=../../../../vi/1-worklog/1.1-week1/1.1.4-day04-2025-09-11/><b>1.1.4. </b>Ngày 04 - Tối ưu Chi phí trên AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.1-week1/1.1.5-day05-2025-09-12/ title="Ngày 05 - AWS Well-Architected Framework" class=dd-item><a href=../../../../vi/1-worklog/1.1-week1/1.1.5-day05-2025-09-12/><b>1.1.5. </b>Ngày 05 - AWS Well-Architected Framework
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.2-week2/ title="Tuần 2 - Dịch vụ Mạng trên AWS" class=dd-item><a href=../../../../vi/1-worklog/1.2-week2/><b>1.2. </b>Tuần 2 - Dịch vụ Mạng trên AWS
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.2-week2/1.2.1-day06-2025-09-15/ title="Ngày 06 - Kiến thức Cơ bản về Amazon VPC" class=dd-item><a href=../../../../vi/1-worklog/1.2-week2/1.2.1-day06-2025-09-15/><b>1.2.1. </b>Ngày 06 - Kiến thức Cơ bản về Amazon VPC
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.2-week2/1.2.2-day07-2025-09-16/ title="Ngày 07 - Định tuyến VPC & Network Interface" class=dd-item><a href=../../../../vi/1-worklog/1.2-week2/1.2.2-day07-2025-09-16/><b>1.2.2. </b>Ngày 07 - Định tuyến VPC & Network Interface
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.2-week2/1.2.3-day08-2025-09-17/ title="Ngày 08 - Bảo mật VPC & Flow Logs" class=dd-item><a href=../../../../vi/1-worklog/1.2-week2/1.2.3-day08-2025-09-17/><b>1.2.3. </b>Ngày 08 - Bảo mật VPC & Flow Logs
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.2-week2/1.2.4-day09-2025-09-18/ title="Ngày 09 - Kết nối VPC & Cân bằng tải" class=dd-item><a href=../../../../vi/1-worklog/1.2-week2/1.2.4-day09-2025-09-18/><b>1.2.4. </b>Ngày 09 - Kết nối VPC & Cân bằng tải
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.2-week2/1.2.5-day10-2025-09-19/ title="Ngày 10 - Elastic Load Balancing" class=dd-item><a href=../../../../vi/1-worklog/1.2-week2/1.2.5-day10-2025-09-19/><b>1.2.5. </b>Ngày 10 - Elastic Load Balancing
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.3-week3/ title="Tuần 3 - Dịch vụ Compute trên AWS" class=dd-item><a href=../../../../vi/1-worklog/1.3-week3/><b>1.3. </b>Tuần 3 - Dịch vụ Compute trên AWS
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.3-week3/1.3.1-day11-2025-09-22/ title="Ngày 11 - Kiến thức cơ bản về Amazon EC2" class=dd-item><a href=../../../../vi/1-worklog/1.3-week3/1.3.1-day11-2025-09-22/><b>1.3.1. </b>Ngày 11 - Kiến thức cơ bản về Amazon EC2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.3-week3/1.3.2-day12-2025-09-23/ title="Ngày 12 - Lưu trữ & Sao lưu cho EC2" class=dd-item><a href=../../../../vi/1-worklog/1.3-week3/1.3.2-day12-2025-09-23/><b>1.3.2. </b>Ngày 12 - Lưu trữ & Sao lưu cho EC2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.3-week3/1.3.3-day13-2025-09-24/ title="Ngày 13 - Instance Store & User Data" class=dd-item><a href=../../../../vi/1-worklog/1.3-week3/1.3.3-day13-2025-09-24/><b>1.3.3. </b>Ngày 13 - Instance Store & User Data
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.3-week3/1.3.4-day14-2025-09-25/ title="Ngày 14 - EC2 Auto Scaling" class=dd-item><a href=../../../../vi/1-worklog/1.3-week3/1.3.4-day14-2025-09-25/><b>1.3.4. </b>Ngày 14 - EC2 Auto Scaling
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.3-week3/1.3.5-day15-2025-09-26/ title="Ngày 15 - Lightsail, EFS & FSx" class=dd-item><a href=../../../../vi/1-worklog/1.3-week3/1.3.5-day15-2025-09-26/><b>1.3.5. </b>Ngày 15 - Lightsail, EFS & FSx
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.4-week4/ title="Tuần 4 - Dịch vụ Lưu trữ trên AWS" class=dd-item><a href=../../../../vi/1-worklog/1.4-week4/><b>1.4. </b>Tuần 4 - Dịch vụ Lưu trữ trên AWS
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.4-week4/1.4.1-day16-2025-09-29/ title="Ngày 16 - Kiến thức cơ bản về Amazon S3" class=dd-item><a href=../../../../vi/1-worklog/1.4-week4/1.4.1-day16-2025-09-29/><b>1.4.1. </b>Ngày 16 - Kiến thức cơ bản về Amazon S3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.4-week4/1.4.2-day17-2025-09-30/ title="Ngày 17 - Tính năng nâng cao của S3" class=dd-item><a href=../../../../vi/1-worklog/1.4-week4/1.4.2-day17-2025-09-30/><b>1.4.2. </b>Ngày 17 - Tính năng nâng cao của S3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.4-week4/1.4.3-day18-2025-10-01/ title="Ngày 18 - AWS Snow Family & Hybrid Storage" class=dd-item><a href=../../../../vi/1-worklog/1.4-week4/1.4.3-day18-2025-10-01/><b>1.4.3. </b>Ngày 18 - AWS Snow Family & Hybrid Storage
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.4-week4/1.4.4-day19-2025-10-02/ title="Ngày 19 - Disaster Recovery trên AWS" class=dd-item><a href=../../../../vi/1-worklog/1.4-week4/1.4.4-day19-2025-10-02/><b>1.4.4. </b>Ngày 19 - Disaster Recovery trên AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.4-week4/1.4.5-day20-2025-10-03/ title="Ngày 20 - AWS Backup & FSx" class=dd-item><a href=../../../../vi/1-worklog/1.4-week4/1.4.5-day20-2025-10-03/><b>1.4.5. </b>Ngày 20 - AWS Backup & FSx
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.5-week5/ title="Tuần 5 - Bảo mật & Danh tính trên AWS" class=dd-item><a href=../../../../vi/1-worklog/1.5-week5/><b>1.5. </b>Tuần 5 - Bảo mật & Danh tính trên AWS
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.5-week5/1.5.1-day21-2025-10-06/ title="Ngày 21 - Shared Responsibility & Kiến thức IAM cơ bản" class=dd-item><a href=../../../../vi/1-worklog/1.5-week5/1.5.1-day21-2025-10-06/><b>1.5.1. </b>Ngày 21 - Shared Responsibility & Kiến thức IAM cơ bản
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.5-week5/1.5.2-day22-2025-10-07/ title="Ngày 22 - IAM Policies & Roles" class=dd-item><a href=../../../../vi/1-worklog/1.5-week5/1.5.2-day22-2025-10-07/><b>1.5.2. </b>Ngày 22 - IAM Policies & Roles
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.5-week5/1.5.3-day23-2025-10-08/ title="Ngày 23 - Amazon Cognito & Organizations" class=dd-item><a href=../../../../vi/1-worklog/1.5-week5/1.5.3-day23-2025-10-08/><b>1.5.3. </b>Ngày 23 - Amazon Cognito & Organizations
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.5-week5/1.5.4-day24-2025-10-09/ title="Ngày 24 - SCPs, Identity Center & KMS" class=dd-item><a href=../../../../vi/1-worklog/1.5-week5/1.5.4-day24-2025-10-09/><b>1.5.4. </b>Ngày 24 - SCPs, Identity Center & KMS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.5-week5/1.5.5-day25-2025-10-10/ title="Ngày 25 - AWS Security Hub & Automation" class=dd-item><a href=../../../../vi/1-worklog/1.5-week5/1.5.5-day25-2025-10-10/><b>1.5.5. </b>Ngày 25 - AWS Security Hub & Automation
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.6-week6/ title="Tuần 6 - AWS Database Services" class=dd-item><a href=../../../../vi/1-worklog/1.6-week6/><b>1.6. </b>Tuần 6 - AWS Database Services
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.6-week6/1.6.1-day26-2025-10-13/ title="Ngày 26 - Kiến thức Cơ bản về Cơ sở dữ liệu" class=dd-item><a href=../../../../vi/1-worklog/1.6-week6/1.6.1-day26-2025-10-13/><b>1.6.1. </b>Ngày 26 - Kiến thức Cơ bản về Cơ sở dữ liệu
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.6-week6/1.6.2-day27-2025-10-14/ title="Ngày 27 - Amazon RDS & Aurora" class=dd-item><a href=../../../../vi/1-worklog/1.6-week6/1.6.2-day27-2025-10-14/><b>1.6.2. </b>Ngày 27 - Amazon RDS & Aurora
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.6-week6/1.6.3-day28-2025-10-15/ title="Ngày 28 - Amazon Redshift" class=dd-item><a href=../../../../vi/1-worklog/1.6-week6/1.6.3-day28-2025-10-15/><b>1.6.3. </b>Ngày 28 - Amazon Redshift
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.6-week6/1.6.4-day29-2025-10-16/ title="Ngày 29 - Amazon ElastiCache" class=dd-item><a href=../../../../vi/1-worklog/1.6-week6/1.6.4-day29-2025-10-16/><b>1.6.4. </b>Ngày 29 - Amazon ElastiCache
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.6-week6/1.6.5-day30-2025-10-17/ title="Ngày 30 - Database Migration & Best Practices" class=dd-item><a href=../../../../vi/1-worklog/1.6-week6/1.6.5-day30-2025-10-17/><b>1.6.5. </b>Ngày 30 - Database Migration & Best Practices
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.7-week7/ title="Tuần 7 - Vertical Slice Delivery" class=dd-item><a href=../../../../vi/1-worklog/1.7-week7/><b>1.7. </b>Tuần 7 - Vertical Slice Delivery
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.7-week7/1.7.1-day31-2025-10-20/ title="Ngày 31 - Khởi động Vertical Slice" class=dd-item><a href=../../../../vi/1-worklog/1.7-week7/1.7.1-day31-2025-10-20/><b>1.7.1. </b>Ngày 31 - Khởi động Vertical Slice
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.7-week7/1.7.2-day32-2025-10-21/ title="Ngày 32 - Contract-First & Mocking" class=dd-item><a href=../../../../vi/1-worklog/1.7-week7/1.7.2-day32-2025-10-21/><b>1.7.2. </b>Ngày 32 - Contract-First & Mocking
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.7-week7/1.7.3-day33-2025-10-22/ title="Ngày 33 - Next.js App Router" class=dd-item><a href=../../../../vi/1-worklog/1.7-week7/1.7.3-day33-2025-10-22/><b>1.7.3. </b>Ngày 33 - Next.js App Router
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.7-week7/1.7.4-day34-2025-10-23/ title="Ngày 34 - FastAPI Clean Architecture" class=dd-item><a href=../../../../vi/1-worklog/1.7-week7/1.7.4-day34-2025-10-23/><b>1.7.4. </b>Ngày 34 - FastAPI Clean Architecture
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.7-week7/1.7.5-day35-2025-10-24/ title="Ngày 35 - Contract Testing & Retrospective" class=dd-item><a href=../../../../vi/1-worklog/1.7-week7/1.7.5-day35-2025-10-24/><b>1.7.5. </b>Ngày 35 - Contract Testing & Retrospective
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.8-week8/ title="Tuần 8 - Xử Lý Ngôn Ngữ Tự Nhiên & Deep Learning" class=dd-item><a href=../../../../vi/1-worklog/1.8-week8/><b>1.8. </b>Tuần 8 - Xử Lý Ngôn Ngữ Tự Nhiên & Deep Learning
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.8-week8/1.8.1-day36-2025-10-27/ title="Ngày 36 - Nền Tảng NLP & Ứng Dụng" class=dd-item><a href=../../../../vi/1-worklog/1.8-week8/1.8.1-day36-2025-10-27/><b>1.8.1. </b>Ngày 36 - Nền Tảng NLP & Ứng Dụng
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.8-week8/1.8.2-day37-2025-10-28/ title="Ngày 37 - Tìm Kiếm Giọng Nói & Kiến Trúc Chatbot" class=dd-item><a href=../../../../vi/1-worklog/1.8-week8/1.8.2-day37-2025-10-28/><b>1.8.2. </b>Ngày 37 - Tìm Kiếm Giọng Nói & Kiến Trúc Chatbot
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.8-week8/1.8.3-day38-2025-10-29/ title="Ngày 38 - Mô Hình Seq2seq & LSTM Chi Tiết" class=dd-item><a href=../../../../vi/1-worklog/1.8-week8/1.8.3-day38-2025-10-29/><b>1.8.3. </b>Ngày 38 - Mô Hình Seq2seq & LSTM Chi Tiết
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.8-week8/1.8.4-day39-2025-10-30/ title="Ngày 39 - NMT & Tóm Tắt Văn Bản" class=dd-item><a href=../../../../vi/1-worklog/1.8-week8/1.8.4-day39-2025-10-30/><b>1.8.4. </b>Ngày 39 - NMT & Tóm Tắt Văn Bản
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.8-week8/1.8.5-day40-2025-10-31/ title="Ngày 40 - Đánh Giá MT & Chiến Lược Decoding" class=dd-item><a href=../../../../vi/1-worklog/1.8-week8/1.8.5-day40-2025-10-31/><b>1.8.5. </b>Ngày 40 - Đánh Giá MT & Chiến Lược Decoding
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.9-week9/ title="Tuần 9 - Kiến Trúc & Triển Khai Transformer" class="dd-item
parent"><a href=../../../../vi/1-worklog/1.9-week9/><b>1.9. </b>Tuần 9 - Kiến Trúc & Triển Khai Transformer
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.9-week9/1.9.1-day41-2025-11-03/ title="Ngày 41 - Vấn Đề RNN & Tại Sao Cần Transformers" class=dd-item><a href=../../../../vi/1-worklog/1.9-week9/1.9.1-day41-2025-11-03/><b>1.9.1. </b>Ngày 41 - Vấn Đề RNN & Tại Sao Cần Transformers
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.9-week9/1.9.2-day42-2025-11-04/ title="Ngày 42 - Tổng Quan Kiến Trúc Transformer" class=dd-item><a href=../../../../vi/1-worklog/1.9-week9/1.9.2-day42-2025-11-04/><b>1.9.2. </b>Ngày 42 - Tổng Quan Kiến Trúc Transformer
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.9-week9/1.9.3-day43-2025-11-05/ title="Ngày 43 - Sâu Hơn Về Scaled Dot-Product Attention" class=dd-item><a href=../../../../vi/1-worklog/1.9-week9/1.9.3-day43-2025-11-05/><b>1.9.3. </b>Ngày 43 - Sâu Hơn Về Scaled Dot-Product Attention
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/ title="Ngày 44 - Các Loại Attention: Self, Masked, Encoder-Decoder" class=dd-item><a href=../../../../vi/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/><b>1.9.4. </b>Ngày 44 - Các Loại Attention: Self, Masked, Encoder-Decoder
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/ title="Ngày 45 - Decoder Transformer & Triển Khai GPT2" class="dd-item
active"><a href=../../../../vi/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/><b>1.9.5. </b>Ngày 45 - Decoder Transformer & Triển Khai GPT2
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.10-week10/ title="Tuần 10 - Transfer Learning, BERT & T5" class=dd-item><a href=../../../../vi/1-worklog/1.10-week10/><b>1.10. </b>Tuần 10 - Transfer Learning, BERT & T5
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.10-week10/1.10.1-day46-2025-11-10/ title="Ngày 46 - Nền tảng Transfer Learning" class=dd-item><a href=../../../../vi/1-worklog/1.10-week10/1.10.1-day46-2025-11-10/><b>1.10.1. </b>Ngày 46 - Nền tảng Transfer Learning
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.10-week10/1.10.2-day47-2025-11-11/ title="Ngày 47 - Hai chế độ Question Answering" class=dd-item><a href=../../../../vi/1-worklog/1.10-week10/1.10.2-day47-2025-11-11/><b>1.10.2. </b>Ngày 47 - Hai chế độ Question Answering
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.10-week10/1.10.3-day48-2025-11-12/ title="Ngày 48 - BERT và ngữ cảnh hai chiều" class=dd-item><a href=../../../../vi/1-worklog/1.10-week10/1.10.3-day48-2025-11-12/><b>1.10.3. </b>Ngày 48 - BERT và ngữ cảnh hai chiều
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.10-week10/1.10.4-day49-2025-11-13/ title="Ngày 49 - T5 đa nhiệm dạng text-to-text" class=dd-item><a href=../../../../vi/1-worklog/1.10-week10/1.10.4-day49-2025-11-13/><b>1.10.4. </b>Ngày 49 - T5 đa nhiệm dạng text-to-text
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.10-week10/1.10.5-day50-2025-11-14/ title="Ngày 50 - Thực hành fine-tuning" class=dd-item><a href=../../../../vi/1-worklog/1.10-week10/1.10.5-day50-2025-11-14/><b>1.10.5. </b>Ngày 50 - Thực hành fine-tuning
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.11-week11/ title="Tuần 11 - Lambda Managed Instances & ghi chú re:Invent" class=dd-item><a href=../../../../vi/1-worklog/1.11-week11/><b>1.11. </b>Tuần 11 - Lambda Managed Instances & ghi chú re:Invent
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.11-week11/1.11.1-day51-2025-11-17/ title="Ngày 51 - Tổng quan Lambda Managed Instances" class=dd-item><a href=../../../../vi/1-worklog/1.11-week11/1.11.1-day51-2025-11-17/><b>1.11.1. </b>Ngày 51 - Tổng quan Lambda Managed Instances
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.11-week11/1.11.2-day52-2025-11-18/ title="Ngày 52 - Thiết lập Capacity Provider" class=dd-item><a href=../../../../vi/1-worklog/1.11-week11/1.11.2-day52-2025-11-18/><b>1.11.2. </b>Ngày 52 - Thiết lập Capacity Provider
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.11-week11/1.11.3-day53-2025-11-19/ title="Ngày 53 - Hàm chạy trên LMI" class=dd-item><a href=../../../../vi/1-worklog/1.11-week11/1.11.3-day53-2025-11-19/><b>1.11.3. </b>Ngày 53 - Hàm chạy trên LMI
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.11-week11/1.11.4-day54-2025-11-20/ title="Ngày 54 - Mạng & quan sát" class=dd-item><a href=../../../../vi/1-worklog/1.11-week11/1.11.4-day54-2025-11-20/><b>1.11.4. </b>Ngày 54 - Mạng & quan sát
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.11-week11/1.11.5-day55-2025-11-21/ title="Ngày 55 - Scaling & vận hành" class=dd-item><a href=../../../../vi/1-worklog/1.11-week11/1.11.5-day55-2025-11-21/><b>1.11.5. </b>Ngày 55 - Scaling & vận hành
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/1-worklog/1.12-week12/ title="Tuần 12 - Thông báo AWS re:Invent 2025" class=dd-item><a href=../../../../vi/1-worklog/1.12-week12/><b>1.12. </b>Tuần 12 - Thông báo AWS re:Invent 2025
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.12-week12/1.12.1-day56-2025-11-24/ title="Ngày 56 - Dòng Nova & Agent" class=dd-item><a href=../../../../vi/1-worklog/1.12-week12/1.12.1-day56-2025-11-24/><b>1.12.1. </b>Ngày 56 - Dòng Nova & Agent
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.12-week12/1.12.2-day57-2025-11-25/ title="Ngày 57 - Bedrock & AgentCore" class=dd-item><a href=../../../../vi/1-worklog/1.12-week12/1.12.2-day57-2025-11-25/><b>1.12.2. </b>Ngày 57 - Bedrock & AgentCore
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.12-week12/1.12.3-day58-2025-11-26/ title="Ngày 58 - Vector & dữ liệu riêng tư" class=dd-item><a href=../../../../vi/1-worklog/1.12-week12/1.12.3-day58-2025-11-26/><b>1.12.3. </b>Ngày 58 - Vector & dữ liệu riêng tư
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.12-week12/1.12.4-day59-2025-11-27/ title="Ngày 59 - Nền tảng SageMaker AI" class=dd-item><a href=../../../../vi/1-worklog/1.12-week12/1.12.4-day59-2025-11-27/><b>1.12.4. </b>Ngày 59 - Nền tảng SageMaker AI
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.12-week12/1.12.5-day60-2025-11-28/ title="Ngày 60 - Compute mới" class=dd-item><a href=../../../../vi/1-worklog/1.12-week12/1.12.5-day60-2025-11-28/><b>1.12.5. </b>Ngày 60 - Compute mới
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/vi/2-proposal/ title="Bản đề xuất" class=dd-item><a href=../../../../vi/2-proposal/><b>2. </b>Bản đề xuất
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/ title="Các bài blogs đã dịch" class=dd-item><a href=../../../../vi/3-blogstranslated/><b>3. </b>Các bài blogs đã dịch
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/3-blogstranslated/3.1-blog1/ title="Blog 1" class=dd-item><a href=../../../../vi/3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/3.2-blog2/ title="Blog 2" class=dd-item><a href=../../../../vi/3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=../../../../vi/3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/4-eventparticipated/ title="Các Sự Kiện Tham Gia" class=dd-item><a href=../../../../vi/4-eventparticipated/><b>4. </b>Các Sự Kiện Tham Gia
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/4-eventparticipated/4.1-event1/ title="Sự Kiện 1 - Vietnam Cloud Day 2025" class=dd-item><a href=../../../../vi/4-eventparticipated/4.1-event1/>Sự Kiện 1 - Vietnam Cloud Day 2025
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.2-event2/ title="Sự Kiện 2 - AWS GenAI Builder Club" class=dd-item><a href=../../../../vi/4-eventparticipated/4.2-event2/>Sự Kiện 2 - AWS GenAI Builder Club
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/ title=Workshop class=dd-item><a href=../../../../vi/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.1-workshop-overview/ title="Giới thiệu" class=dd-item><a href=../../../../vi/5-workshop/5.1-workshop-overview/><b>5.1. </b>Giới thiệu
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.2-prerequisite/ title="Chuẩn bị" class=dd-item><a href=../../../../vi/5-workshop/5.2-prerequisite/><b>5.2. </b>Chuẩn bị
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-create-lambda-and-bedrock-call/ title="Tạo Lambda và gọi Bedrock" class=dd-item><a href=../../../../vi/5-workshop/5.3-create-lambda-and-bedrock-call/><b>5.3. </b>Tạo Lambda và gọi Bedrock
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.1-create-lambda/ title="Tạo Lambda Function" class=dd-item><a href=../../../../vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.1-create-lambda/><b>5.3.1. </b>Tạo Lambda Function
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.2-call-bedrock-converse/ title="Thêm code gọi Converse API" class=dd-item><a href=../../../../vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.2-call-bedrock-converse/><b>5.3.2. </b>Thêm code gọi Converse API
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.3-test-lambda/ title="Kiểm thử Lambda Function" class=dd-item><a href=../../../../vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.3-test-lambda/><b>5.3.3. </b>Kiểm thử Lambda Function
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/5.4-api-gateway-integration/ title="Tạo API Gateway" class=dd-item><a href=../../../../vi/5-workshop/5.4-api-gateway-integration/><b>5.4. </b>Tạo API Gateway
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.4-api-gateway-integration/5.4.1-create-http-api/ title="Tạo HTTP API" class=dd-item><a href=../../../../vi/5-workshop/5.4-api-gateway-integration/5.4.1-create-http-api/><b>5.4.1. </b>Tạo HTTP API
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.4-api-gateway-integration/5.4.2-integrate-lambda/ title="Gắn API với Lambda" class=dd-item><a href=../../../../vi/5-workshop/5.4-api-gateway-integration/5.4.2-integrate-lambda/><b>5.4.2. </b>Gắn API với Lambda
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/5.5-testing-and-logs/ title="Kiểm thử" class=dd-item><a href=../../../../vi/5-workshop/5.5-testing-and-logs/><b>5.5. </b>Kiểm thử
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.6-cleanup/ title="Dọn dẹp tài nguyên" class=dd-item><a href=../../../../vi/5-workshop/5.6-cleanup/><b>5.6. </b>Dọn dẹp tài nguyên
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/6-self-evaluation/ title="Tự đánh giá" class=dd-item><a href=../../../../vi/6-self-evaluation/><b>6. </b>Tự đánh giá
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/7-feedback/ title="Chia sẻ, đóng góp ý kiến" class=dd-item><a href=../../../../vi/7-feedback/><b>7. </b>Chia sẻ, đóng góp ý kiến
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://phuvo05.github.io/My-FCJ-Workshop/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/>English</option><option id=vi value=https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/ selected>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=../../../../vi/>Báo cáo thực tập</a> > <a href=../../../../vi/1-worklog/>Worklog</a> > <a href=../../../../vi/1-worklog/1.9-week9/>Tuần 9 - Kiến Trúc & Triển Khai Transformer</a> > Ngày 45 - Decoder Transformer & Triển Khai GPT2
          
 </span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><ul><li><a href=#bước-1-word-embedding--positional-encoding>Bước 1: Word Embedding + Positional Encoding</a></li><li><a href=#bước-2-decoder-block>Bước 2: Decoder Block</a></li><li><a href=#bước-3-multi-head-attention>Bước 3: Multi-Head Attention</a></li><li><a href=#bước-4-feed-forward-network>Bước 4: Feed-Forward Network</a></li><li><a href=#bước-5-causal-mask-để-ngăn-chặn-attend-vào-tương-lai>Bước 5: Causal Mask (để ngăn chặn attend vào tương lai)</a></li></ul></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Ngày 45 - Decoder Transformer & Triển Khai GPT2</h1><p><strong>Ngày:</strong> 2025-11-07 (Thứ Sáu)<br><strong>Trạng Thái:</strong> &ldquo;Hoàn Thành&rdquo;</p><hr><h1 id=xây-dựng-decoder-transformer-kiến-trúc-gpt2><strong>Xây Dựng Decoder Transformer: Kiến Trúc GPT2</strong></h1><p>Bây giờ hãy xem cách tất cả những phần này kết hợp lại trong mã thực tế!</p><hr><h1 id=cấu-trúc-transformer-decoder-kiểu-gpt2><strong>Cấu Trúc Transformer Decoder (kiểu GPT2)</strong></h1><pre tabindex=0><code>Đầu Vào: Câu được tokenize [1, 2, 3, 4, 5]
  ↓
Lớp Embedding: Chuyển đổi tokens thành vectors
  ↓
Thêm Positional Encoding: Thêm thông tin vị trí
  ↓
┌──────────────────────────────────┐
│  Decoder Block (N lần)           │
│  ├─ Masked Self-Attention        │
│  ├─ Residual + LayerNorm         │
│  ├─ Feed-Forward                 │
│  └─ Residual + LayerNorm         │
└──────────────────────────────────┘
  ↓
Lớp Linear: Chiếu tới kích thước vocab
  ↓
Softmax: Chuyển đổi thành xác suất
  ↓
Đầu Ra: Xác suất cho từ tiếp theo
</code></pre><hr><h1 id=triển-khai-pytorch><strong>Triển Khai PyTorch</strong></h1><h3 id=bước-1-word-embedding--positional-encoding>Bước 1: Word Embedding + Positional Encoding</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>TransformerDecoder</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, vocab_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>, d_model<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, num_layers<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>, 
</span></span><span style=display:flex><span>                 num_heads<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>, d_ff<span style=color:#f92672>=</span><span style=color:#ae81ff>2048</span>, max_seq_len<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span>, dropout<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 1. Lớp embedding</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>embedding <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding(vocab_size, d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 2. Positional encoding (được học)</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>positional_encoding <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding(max_seq_len, d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 3. Các decoder blocks (lặp N lần)</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>decoder_layers <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ModuleList([
</span></span><span style=display:flex><span>            DecoderBlock(d_model, num_heads, d_ff, dropout)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(num_layers)
</span></span><span style=display:flex><span>        ])
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 4. Lớp đầu ra</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>final_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_model, vocab_size)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>softmax <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Softmax(dim<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>d_model <span style=color:#f92672>=</span> d_model
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, input_ids, mask<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># input_ids shape: [batch_size, seq_length]</span>
</span></span><span style=display:flex><span>        batch_size, seq_len <span style=color:#f92672>=</span> input_ids<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 1. Nhúng các tokens</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>embedding(input_ids)  <span style=color:#75715e># [batch, seq_len, d_model]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 2. Thêm positional encoding</span>
</span></span><span style=display:flex><span>        positions <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>arange(seq_len, device<span style=color:#f92672>=</span>input_ids<span style=color:#f92672>.</span>device)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        pos_encoding <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>positional_encoding(positions)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> x <span style=color:#f92672>+</span> pos_encoding  <span style=color:#75715e># [batch, seq_len, d_model]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 3. Truyền qua các lớp decoder</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> decoder_layer <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>decoder_layers:
</span></span><span style=display:flex><span>            x <span style=color:#f92672>=</span> decoder_layer(x, mask)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 4. Chiếu tới vocab</span>
</span></span><span style=display:flex><span>        logits <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>final_layer(x)  <span style=color:#75715e># [batch, seq_len, vocab_size]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> logits
</span></span></code></pre></div><h3 id=bước-2-decoder-block>Bước 2: Decoder Block</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DecoderBlock</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, d_model, num_heads, d_ff, dropout):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 1. Masked multi-head attention</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>self_attention <span style=color:#f92672>=</span> MultiHeadAttention(d_model, num_heads, dropout)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>norm1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LayerNorm(d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 2. Feed-forward network</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>feed_forward <span style=color:#f92672>=</span> FeedForward(d_model, d_ff, dropout)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>norm2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LayerNorm(d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(dropout)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x, mask<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># x shape: [batch, seq_len, d_model]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Masked Self-Attention + Residual + Norm</span>
</span></span><span style=display:flex><span>        attn_output <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>self_attention(x, x, x, mask)  <span style=color:#75715e># Q=K=V</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> x <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>dropout(attn_output)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>norm1(x)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Feed-Forward + Residual + Norm</span>
</span></span><span style=display:flex><span>        ff_output <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>feed_forward(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> x <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>dropout(ff_output)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>norm2(x)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div><h3 id=bước-3-multi-head-attention>Bước 3: Multi-Head Attention</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MultiHeadAttention</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, d_model, num_heads, dropout):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>assert</span> d_model <span style=color:#f92672>%</span> num_heads <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>num_heads <span style=color:#f92672>=</span> num_heads
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>d_k <span style=color:#f92672>=</span> d_model <span style=color:#f92672>//</span> num_heads
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Các phép chiếu tuyến tính cho Q, K, V</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>W_q <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_model, d_model)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>W_k <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_model, d_model)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>W_v <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_model, d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Phép chiếu đầu ra</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>W_o <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_model, d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(dropout)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, Q, K, V, mask<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        batch_size <span style=color:#f92672>=</span> Q<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 1. Các phép chiếu tuyến tính và chia thành nhiều đầu</span>
</span></span><span style=display:flex><span>        Q <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>W_q(Q)  <span style=color:#75715e># [batch, seq_len, d_model]</span>
</span></span><span style=display:flex><span>        K <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>W_k(K)
</span></span><span style=display:flex><span>        V <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>W_v(V)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Reshape cho multi-head: [batch, seq_len, num_heads, d_k]</span>
</span></span><span style=display:flex><span>        Q <span style=color:#f92672>=</span> Q<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, self<span style=color:#f92672>.</span>num_heads, self<span style=color:#f92672>.</span>d_k)<span style=color:#f92672>.</span>transpose(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        K <span style=color:#f92672>=</span> K<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, self<span style=color:#f92672>.</span>num_heads, self<span style=color:#f92672>.</span>d_k)<span style=color:#f92672>.</span>transpose(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        V <span style=color:#f92672>=</span> V<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, self<span style=color:#f92672>.</span>num_heads, self<span style=color:#f92672>.</span>d_k)<span style=color:#f92672>.</span>transpose(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># Bây giờ: [batch, num_heads, seq_len, d_k]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 2. Scaled dot-product attention</span>
</span></span><span style=display:flex><span>        scores <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>matmul(Q, K<span style=color:#f92672>.</span>transpose(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)) <span style=color:#f92672>/</span> math<span style=color:#f92672>.</span>sqrt(self<span style=color:#f92672>.</span>d_k)
</span></span><span style=display:flex><span>        <span style=color:#75715e># [batch, num_heads, seq_len, seq_len]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 3. Áp dụng mask (cho causal masking trong decoder)</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> mask <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>            scores <span style=color:#f92672>=</span> scores<span style=color:#f92672>.</span>masked_fill(mask <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1e9</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 4. Softmax</span>
</span></span><span style=display:flex><span>        attention_weights <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>softmax(scores, dim<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        attention_weights <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dropout(attention_weights)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 5. Nhân với value</span>
</span></span><span style=display:flex><span>        context <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>matmul(attention_weights, V)
</span></span><span style=display:flex><span>        <span style=color:#75715e># [batch, num_heads, seq_len, d_k]</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 6. Ghép các đầu</span>
</span></span><span style=display:flex><span>        context <span style=color:#f92672>=</span> context<span style=color:#f92672>.</span>transpose(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>)<span style=color:#f92672>.</span>contiguous()
</span></span><span style=display:flex><span>        context <span style=color:#f92672>=</span> context<span style=color:#f92672>.</span>view(batch_size, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, self<span style=color:#f92672>.</span>d_model)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 7. Phép chiếu tuyến tính cuối cùng</span>
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>W_o(context)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> output
</span></span></code></pre></div><h3 id=bước-4-feed-forward-network>Bước 4: Feed-Forward Network</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>FeedForward</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, d_model, d_ff, dropout):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>linear1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_model, d_ff)  <span style=color:#75715e># 512 → 2048</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>linear2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(d_ff, d_model)  <span style=color:#75715e># 2048 → 512</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>relu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(dropout)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>linear1(x)      <span style=color:#75715e># Mở rộng</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(x)         <span style=color:#75715e># Non-linearity</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dropout(x)      <span style=color:#75715e># Regularization</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>linear2(x)      <span style=color:#75715e># Nén</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div><h3 id=bước-5-causal-mask-để-ngăn-chặn-attend-vào-tương-lai>Bước 5: Causal Mask (để ngăn chặn attend vào tương lai)</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_causal_mask</span>(seq_len, device):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Tạo một mask ngăn chặn attention tới các vị trí tương lai.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Đầu Ra:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [1, 0, 0, 0]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [1, 1, 0, 0]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [1, 1, 1, 0]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [1, 1, 1, 1]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Vị trí i chỉ có thể attend tới các vị trí 0...i
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    mask <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tril(torch<span style=color:#f92672>.</span>ones(seq_len, seq_len, device<span style=color:#f92672>=</span>device))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> mask<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>0</span>)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>0</span>)  <span style=color:#75715e># [1, 1, seq_len, seq_len]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sử Dụng:</span>
</span></span><span style=display:flex><span>mask <span style=color:#f92672>=</span> create_causal_mask(seq_len<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, device<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;cuda&#39;</span>)
</span></span></code></pre></div><hr><h1 id=vòng-lặp-huấn-luyện><strong>Vòng Lặp Huấn Luyện</strong></h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_transformer</span>(model, train_loader, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, learning_rate<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0001</span>):
</span></span><span style=display:flex><span>    optimizer <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span>learning_rate)
</span></span><span style=display:flex><span>    loss_fn <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(epochs):
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> batch_idx, (input_ids, target_ids) <span style=color:#f92672>in</span> enumerate(train_loader):
</span></span><span style=display:flex><span>            <span style=color:#75715e># Forward pass</span>
</span></span><span style=display:flex><span>            logits <span style=color:#f92672>=</span> model(input_ids)
</span></span><span style=display:flex><span>            <span style=color:#75715e># logits: [batch, seq_len, vocab_size]</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># target_ids: [batch, seq_len]</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># Tính toán loss</span>
</span></span><span style=display:flex><span>            loss <span style=color:#f92672>=</span> loss_fn(
</span></span><span style=display:flex><span>                logits<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, vocab_size),
</span></span><span style=display:flex><span>                target_ids<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># Backward pass</span>
</span></span><span style=display:flex><span>            optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>            loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>            optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, Loss: </span><span style=color:#e6db74>{</span>total_loss<span style=color:#f92672>/</span>len(train_loader)<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><hr><h1 id=suy-luận-tạo-văn-bản><strong>Suy Luận (Tạo Văn Bản)</strong></h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_text</span>(model, start_token, max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, device<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;cuda&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Tạo văn bản tự động sử dụng transformer được huấn luyện.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>    generated <span style=color:#f92672>=</span> [start_token]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(max_length):
</span></span><span style=display:flex><span>            <span style=color:#75715e># Chuẩn bị đầu vào</span>
</span></span><span style=display:flex><span>            input_ids <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(generated, device<span style=color:#f92672>=</span>device)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># Forward pass</span>
</span></span><span style=display:flex><span>            logits <span style=color:#f92672>=</span> model(input_ids)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># Lấy logits cho vị trí cuối cùng</span>
</span></span><span style=display:flex><span>            last_logits <span style=color:#f92672>=</span> logits[<span style=color:#ae81ff>0</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, :]  <span style=color:#75715e># [vocab_size]</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># Lấy mẫu hoặc tham lam</span>
</span></span><span style=display:flex><span>            next_token <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(last_logits)<span style=color:#f92672>.</span>item()  <span style=color:#75715e># Tham lam</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Hoặc: next_token = torch.multinomial(softmax(last_logits), 1).item()  # Lấy mẫu</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            generated<span style=color:#f92672>.</span>append(next_token)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> next_token <span style=color:#f92672>==</span> end_token:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> generated
</span></span></code></pre></div><hr><h1 id=ví-dụ-hoàn-chỉnh-hoạt-động><strong>Ví Dụ Hoàn Chỉnh Hoạt Động</strong></h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Khởi tạo mô hình</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> TransformerDecoder(
</span></span><span style=display:flex><span>    vocab_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>,
</span></span><span style=display:flex><span>    d_model<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>,
</span></span><span style=display:flex><span>    num_layers<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>,
</span></span><span style=display:flex><span>    num_heads<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>,
</span></span><span style=display:flex><span>    d_ff<span style=color:#f92672>=</span><span style=color:#ae81ff>2048</span>,
</span></span><span style=display:flex><span>    max_seq_len<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span>,
</span></span><span style=display:flex><span>    dropout<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>to(<span style=color:#e6db74>&#39;cuda&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Tạo dữ liệu giả</span>
</span></span><span style=display:flex><span>batch_size, seq_len <span style=color:#f92672>=</span> <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>128</span>
</span></span><span style=display:flex><span>input_ids <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>10000</span>, (batch_size, seq_len))<span style=color:#f92672>.</span>to(<span style=color:#e6db74>&#39;cuda&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Forward pass</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> model(input_ids)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Output shape: </span><span style=color:#e6db74>{</span>output<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)  <span style=color:#75715e># [32, 128, 10000]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Tạo causal mask</span>
</span></span><span style=display:flex><span>mask <span style=color:#f92672>=</span> create_causal_mask(seq_len, <span style=color:#e6db74>&#39;cuda&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Forward với mask</span>
</span></span><span style=display:flex><span>output_masked <span style=color:#f92672>=</span> model(input_ids, mask)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Masked output shape: </span><span style=color:#e6db74>{</span>output_masked<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Tạo văn bản</span>
</span></span><span style=display:flex><span>generated <span style=color:#f92672>=</span> generate_text(model, start_token<span style=color:#f92672>=</span><span style=color:#ae81ff>101</span>, max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Generated sequence: </span><span style=color:#e6db74>{</span>generated<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><hr><h1 id=tóm-tắt-các-thành-phần-chính><strong>Tóm Tắt Các Thành Phần Chính</strong></h1><table><thead><tr><th style=text-align:left>Thành Phần</th><th style=text-align:left>Mục Đích</th><th style=text-align:left>Kích Thước</th></tr></thead><tbody><tr><td style=text-align:left><strong>Embedding</strong></td><td style=text-align:left>Token → Vector</td><td style=text-align:left>vocab_size → d_model</td></tr><tr><td style=text-align:left><strong>Positional Encoding</strong></td><td style=text-align:left>Thêm thông tin vị trí</td><td style=text-align:left>d_model</td></tr><tr><td style=text-align:left><strong>Multi-Head Attention</strong></td><td style=text-align:left>Học mối quan hệ</td><td style=text-align:left>d_model → d_model</td></tr><tr><td style=text-align:left><strong>Feed-Forward</strong></td><td style=text-align:left>Phép biến đổi phi tuyến</td><td style=text-align:left>d_model → d_ff → d_model</td></tr><tr><td style=text-align:left><strong>LayerNorm</strong></td><td style=text-align:left>Ổn định huấn luyện</td><td style=text-align:left>per-element</td></tr><tr><td style=text-align:left><strong>Output Layer</strong></td><td style=text-align:left>Chiếu tới vocab</td><td style=text-align:left>d_model → vocab_size</td></tr></tbody></table><hr><h1 id=tại-sao-kiến-trúc-này-hoạt-động><strong>Tại Sao Kiến Trúc Này Hoạt Động</strong></h1><p>✅ <strong>Xử Lý Song Song:</strong> Tất cả các vị trí được xử lý cùng nhau (nhanh!)
✅ <strong>Phụ Thuộc Dài Hạn:</strong> Attention trực tiếp tới bất kỳ vị trí nào (không có vanishing gradients!)
✅ <strong>Có Thể Diễn Giải:</strong> Có thể hình dung các mô hình attention
✅ <strong>Có Thể Mở Rộng:</strong> Có thể lớn lên tới hàng tỷ tham số</p><hr><h1 id=các-biến-thể-gpt2><strong>Các Biến Thể GPT2</strong></h1><ul><li><strong>GPT-2 Small:</strong> 117M tham số</li><li><strong>GPT-2 Medium:</strong> 345M tham số</li><li><strong>GPT-2 Large:</strong> 762M tham số</li><li><strong>GPT-2 XL:</strong> 1.5B tham số</li></ul><p>Tất cả sử dụng kiến trúc decoder giống nhau, chỉ được mở rộng!</p><hr><h1 id=bước-tiếp-theo><strong>Bước Tiếp Theo</strong></h1><ol><li><strong>Huấn Luyện Trước:</strong> Huấn luyện trên kho ngữ liệu văn bản lớn (Wikipedia, Sách, v.v.)</li><li><strong>Tinh Chỉnh:</strong> Điều chỉnh cho các tác vụ cụ thể (dịch, phân loại, v.v.)</li><li><strong>Đánh Giá:</strong> Đo chất lượng (perplexity, BLEU, đánh giá của con người)</li><li><strong>Triển Khai:</strong> Sử dụng cho các ứng dụng thực tế</li></ol><hr><h1 id=tóm-tắt-tuần-9><strong>Tóm Tắt Tuần 9</strong></h1><p>Chúng ta đã bao quát:</p><ul><li>✅ Tại sao transformers thay thế RNNs</li><li>✅ Kiến trúc transformer hoàn chỉnh</li><li>✅ Cơ chế scaled dot-product attention</li><li>✅ Self, masked, và encoder-decoder attention</li><li>✅ Chi tiết triển khai và code</li></ul><p><strong>Đây là nền tảng của NLP hiện đại!</strong> Tất cả các mô hình tiên tiến (BERT, GPT, T5, Claude, ChatGPT) đều dựa trên kiến trúc transformer.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=../../../../vi/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/ title="Ngày 44 - Các Loại Attention: Self, Masked, Encoder-Decoder"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=../../../../vi/1-worklog/1.10-week10/ title="Tuần 10 - Transfer Learning, BERT & T5" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=../../../../js/clipboard.min.js?1765296067></script><script src=../../../../js/perfect-scrollbar.min.js?1765296067></script><script src=../../../../js/perfect-scrollbar.jquery.min.js?1765296067></script><script src=../../../../js/jquery.sticky.js?1765296067></script><script src=../../../../js/featherlight.min.js?1765296067></script><script src=../../../../js/highlight.pack.js?1765296067></script><script>hljs.initHighlightingOnLoad()</script><script src=../../../../js/modernizr.custom-3.6.0.js?1765296067></script><script src=../../../../js/learn.js?1765296067></script><script src=../../../../js/hugo-learn.js?1765296067></script><link href=../../../../mermaid/mermaid.css?1765296067 rel=stylesheet><script src=../../../../mermaid/mermaid.js?1765296067></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>