[{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Võ Thiên Phú\nSố điện thoại: 0335072711\nEmail: phuvo05kid@gmail.com\nTrường: Đại học FPT-HCM\nNgành: Trí Tuệ Nhân Tạo\nLớp: AWS092025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 09/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Di chuyển từ AWS CodeDeploy sang Amazon ECS để triển khai xanh/xanh bởi Mike Rizzo, Islam Mahgoub và Olly Pomeroy vào ngày 16 tháng 9 năm 2025 trong Amazon Elastic Container Service, AWS CodeDeploy, Phương pháp thực hành tốt nhất, Công cụ dành cho nhà phát triển, DevOps, Chia sẻ liên kết cố định hướng dẫn kỹ thuật\nVới triển khai màu xanh lam/xanh lá cây, bạn có thể phát hành phần mềm mới bằng cách chuyển lưu lượng truy cập giữa hai môi trường giống hệt nhau đang chạy các phiên bản khác nhau của ứng dụng. Điều này giảm thiểu rủi ro phổ biến liên quan đến việc triển khai các bản phát hành phần mềm mới, bằng cách tạo điều kiện cho việc kiểm tra an toàn các triển khai mới và cung cấp khả năng khôi phục với thời gian ngừng hoạt động gần như bằng không.\nCho đến gần đây, Amazon Elastic Container Service (Amazon ECS) chỉ hỗ trợ các bản cập nhật luân phiên như một chiến lược triển khai gốc và bạn cần sử dụng AWS CodeDeploy nếu muốn triển khai các triển khai xanh/xanh. Điều này đã thay đổi với sự ra mắt gần đây của triển khai ECS xanh/xanh lá cây.\nTriển khai ECS màu xanh lam/xanh lá cây cung cấp chức năng tương tự như CodeDeploy, nhưng có một số khác biệt về các tính năng có sẵn và cách triển khai chúng. Bài đăng này nhắm mục tiêu đến các tổ chức hiện đang sử dụng CodeDeploy để triển khai xanh/xanh trên Amazon ECS và đang xem xét việc di chuyển sang khả năng Amazon ECS mới. Nó cung cấp hướng dẫn về (1) các yếu tố cần xem xét khi lập kế hoạch di chuyển của bạn, (2) ánh xạ các khái niệm CodeDeploy tương đương trong triển khai ECS xanh/xanh lá cây và (3) chiến lược di chuyển.\nLập kế hoạch di chuyển\nKhi di chuyển từ CodeDeploy sang triển khai xanh/xanh ECS, bạn nên xem xét các điểm sau đây như một phần của quy trình lập kế hoạch:\n· Khả năng mới: Triển khai ECS xanh/xanh cho phép một số trường hợp sử dụng không được hỗ trợ với CodeDeploy. Chúng bao gồm những điều sau:\no Tùy chọn khám phá dịch vụ: CodeDeploy chỉ hỗ trợ các dịch vụ do Elastic Load Balancing (ELB) cung cấp, trong khi triển khai ECS xanh/xanh lá cây hỗ trợ cả ELB và ECS ServiceConnect.\no Hỗ trợ dịch vụ không giao diện: Triển khai ECS xanh/xanh lá cây có thể được sử dụng trong các tình huống không cần tiếp xúc với dịch vụ, ví dụ như dịch vụ xử lý hàng đợi.\no Hỗ trợ Amazon EBS: Triển khai ECS xanh/xanh hỗ trợ cấu hình ổ đĩa Amazon Elastic Block Store (Amazon EBS) khi triển khai dịch vụ.\no Nhiều nhóm mục tiêu: bộ điều khiển triển khai ECS cho phép một dịch vụ được liên kết với nhiều nhóm mục tiêu, có nghĩa là nó có thể được truy cập đồng thời thông qua nhiều cân bằng tải (ví dụ: để tách tiếp xúc với dịch vụ bên trong và bên ngoài).\no Cấu hình trình nghe ALB linh hoạt: CodeDeploy cần các trình nghe riêng biệt cho các dịch vụ khác nhau cũng như cho các điểm cuối sản xuất và thử nghiệm. ECS màu xanh lam/xanh lá cây hoạt động ở cấp độ quy tắc trình nghe, có nghĩa là bạn có thể hưởng lợi từ việc sử dụng một trình nghe duy nhất với định tuyến yêu cầu nâng cao dựa trên tên máy chủ, tiêu đề HTTP, đường dẫn, phương thức, chuỗi truy vấn hoặc IP nguồn. Ví dụ: bạn có thể sử dụng cổng listener chung cho nhiều dịch vụ bằng cách sử dụng định tuyến dựa trên đường dẫn và hỗ trợ thử nghiệm A/B bằng cách sử dụng định tuyến dựa trên chuỗi truy vấn. Bạn cũng có thể hỗ trợ sản xuất màu xanh lam/xanh lá cây và kiểm tra lưu lượng truy cập trên cùng một cổng trình nghe.\n· Cải tiến hoạt động: Triển khai ECS xanh/xanh lá cây cung cấp (1) sự liên kết tốt hơn với các tính năng hiện có của Amazon ECS (chẳng hạn như bộ ngắt mạch, lịch sử triển khai và móc vòng đời), giúp chuyển đổi giữa các chiến lược triển khai Amazon ECS khác nhau, (2) thời gian thực thi móc vòng đời dài hơn (móc CodeDeploy được giới hạn trong 1 giờ) và (3) hỗ trợ AWS CloudFormation được cải thiện (không cần các tệp AppSpec riêng biệt để sửa đổi dịch vụ và móc vòng đời).\n· Giới hạn cấu hình triển khai: CodeDeploy hỗ trợ cấu hình triển khai canary, tuyến tính và tất cả cùng một lúc. Khi viết bài này, ECS xanh lam / xanh lá cây chỉ hỗ trợ tất cả cùng một lúc. Nếu đang sử dụng triển khai tuyến tính hoặc canary CodeDeploy, trước tiên bạn cần chuyển sang cấu hình CodeDeploy tất cả cùng một lúc trước khi di chuyển sang triển khai xanh lam/xanh ECS.\n· Sự khác biệt về API / CLI: Có sự khác biệt về API (và các lệnh CLI liên quan) giữa hai cách tiếp cận. Việc ánh xạ từ API này sang API khác thường đơn giản nhưng hãy lưu ý rằng việc triển khai ECS xanh lam/xanh lá cây dựa nhiều hơn vào các móc vòng đời để kiểm soát các bước triển khai. Ví dụ: khi CodeDeploy hỗ trợ tùy chọn thời gian chờ để kiểm tra triển khai mới (trước khi định tuyến lại lưu lượng sản xuất đến nó), bạn cần sử dụng hook để đạt được điều này với triển khai ECS màu xanh lam/xanh lá cây.\n· Sự khác biệt của bảng điều khiển: Nếu bạn đang sử dụng bảng điều khiển CodeDeploy như một phần của hoạt động của mình, thì hãy lưu ý rằng bảng điều khiển Amazon ECS không cung cấp các tùy chọn ghi đè thủ công tiến trình triển khai (ví dụ: buộc định tuyến lại hoặc chấm dứt sớm thời gian nướng). Thay vào đó, bạn có thể tạo giao diện người dùng tùy chỉnh (tích hợp với các quy trình hoạt động rộng hơn) thông qua móc vòng đời Amazon ECS (được cho là cách tiếp cận an toàn hơn).\n· Đường dẫn di chuyển: Có một số tùy chọn có sẵn để di chuyển dịch vụ từ CodeDeploy sang triển khai xanh/xanh ECS và bạn cần xem xét tùy chọn nào phù hợp nhất với môi trường của mình. Các tùy chọn này, cùng với những ưu và nhược điểm liên quan của chúng, sẽ được đề cập chi tiết hơn ở phần sau của bài đăng này.\n· Hỗ trợ quy trình: Hỗ trợ triển khai ECS màu xanh lam/xanh lá cây ban đầu có thể bị hạn chế trong các công cụ quy trình hiện có. Tích hợp quy trình nâng cao hơn có thể yêu cầu sử dụng các hành động tùy chỉnh trong một khoảng thời gian tạm thời. Khi viết bài này, hành động \u0026ldquo;tiêu chuẩn\u0026rdquo; của Amazon ECS của CodePipeline có thể được sử dụng để triển khai các thay đổi hình ảnh bộ chứa thông qua triển khai ECS màu xanh lam/xanh lá cây (nhưng không phải các thay đổi cấu hình dịch vụ khác).\nTừ CodeDeploy đến triển khai ECS xanh/xanh lá cây\nKhi ước tính chi phí triển khai để di chuyển sang triển khai ECS màu xanh lam/xanh lá cây, bạn phải hiểu sự khác biệt của API và cách bạn có thể ánh xạ các tính năng CodeDeploy với các tính năng triển khai màu xanh lam/xanh lá cây tương đương của ECS. Giả sử bạn đang bắt đầu từ cấu hình \u0026ldquo;tất cả cùng một lúc\u0026rdquo; của CodeDeploy, phần này sẽ hướng dẫn bạn qua những điểm khác biệt chính.\nCấu hình cân bằng tải và tạo dịch vụ\nKhi tạo dịch vụ Amazon ECS bằng CodeDeploy, trước tiên bạn tạo cân bằng tải với trình nghe sản xuất và (tùy chọn) trình nghe thử nghiệm. Mỗi trình nghe được cấu hình với một quy tắc (mặc định) duy nhất định tuyến tất cả lưu lượng truy cập đến một nhóm mục tiêu duy nhất (nhóm mục tiêu chính) như trong Hình 1 (a). Sau đó, bạn tạo một dịch vụ Amazon ECS được định cấu hình để sử dụng trình nghe và nhóm đích, với loại deploymentController được đặt thành CODE_DEPLOY. Việc tạo dịch vụ dẫn đến việc tạo ra một TaskSet (màu xanh lam) được đăng ký với nhóm mục tiêu được chỉ định.\nHình 1: Cấu hình ban đầu của cân bằng tải\nVới dịch vụ được tạo, bạn tạo một nhóm triển khai CodeDeploy (như một phần của ứng dụng CodeDeploy) và định cấu hình nhóm đó với các chi tiết về cụm ECS, tên dịch vụ, trình nghe cân bằng tải, hai nhóm mục tiêu (nhóm mục tiêu chính được sử dụng trong quy tắc trình nghe sản xuất và nhóm mục tiêu phụ được sử dụng cho các tác vụ thay thế), vai trò dịch vụ AWS Identity and Access Management (IAM) để cấp quyền CodeDeploy thao tác tài nguyên Amazon ECS và ELBvà các tham số khác nhau kiểm soát hành vi triển khai.\nTriển khai ECS xanh/xanh chỉ định cấu hình triển khai trong chính dịch vụ Amazon ECS. Trình nghe sản xuất cân bằng tải phải được định cấu hình trước với quy tắc bao gồm hai nhóm mục tiêu có trọng số lần lượt là 1 và 0. Là một phần của quá trình tạo dịch vụ, bạn chỉ định Tên tài nguyên Amazon (ARN) của quy tắc trình nghe này, hai nhóm đích, vai trò IAM (để cấp quyền Amazon ECS thao tác với nhóm nghe và nhóm đích), loại deploymentController được đặt thành ECS và deploymentConfiguration.strategy được đặt thành BLUE_GREEN. Điều này tạo ra một ServiceRevision (màu xanh lam) với các nhiệm vụ được đăng ký với nhóm mục tiêu chính.\nMặc dù cả hai cách tiếp cận đều dẫn đến việc tạo ra một tập hợp tác vụ ban đầu, nhưng cách triển khai cơ bản khác nhau ở chỗ CodeDeploy sử dụngBộ nhiệm vụ, trong khi Amazon ECS sử dụngSửa đổi dịch vụ. Sau này được giới thiệu như một phần củaAPI triển khai dịch vụ Amazon ECS, cung cấp khả năng hiển thị tốt hơn về quy trình triển khai và lịch sử triển khai dịch vụ.\nTriển khai bản sửa đổi dịch vụ\nHình 2 cho thấy cách triển khai một bản sửa đổi dịch vụ mới. CodeDeploy triển khai phiên bản mới của dịch vụ bằng cách sử dụng CreateDeployment(), chỉ định tên ứng dụng CodeDeploy, tên nhóm triển khai và chi tiết sửa đổi trong tệp AppSpec. Điều này phải chứa định nghĩa tác vụ cho phiên bản mới, tên vùng chứa và cổng để sử dụng. Triển khai ECS màu xanh lam/xanh lá cây tạo triển khai dịch vụ mới bằng cách gọi UpdateService(), chuyển thông tin chi tiết về định nghĩa tác vụ thay thế.\nHình 2: Triển khai bản sửa đổi dịch vụ\nTheo tùy chọn, tệp CodeDeploy AppSpec cũng có thể được sử dụng để chỉ định các thay đổi cấu hình dịch vụ khác, chẳng hạn như cấu hình mạng và chiến lược nhà cung cấp dung lượng, đồng thời để chỉ định các móc vòng đời (xem phần sau). Khi sử dụng Amazon ECS, bạn chỉ định những thay đổi này bằng cách sử dụng UpdateService().\nHình 3: Định tuyến lại lưu lượng truy cập\nHình 3 cho thấy sự khác biệt trong cách đạt được định tuyến lại giao thông. Trong CodeDeploy, việc triển khai tạo một TaskSet thay thế (màu xanh lá cây) và đăng ký các tác vụ của nó với nhóm mục tiêu phụ. Khi điều này trở nên lành mạnh, nó có sẵn để thử nghiệm (tùy chọn) và sản xuất. Trong cả hai trường hợp, việc định tuyến lại đạt được bằng cách thay đổi quy tắc listener tương ứng để trỏ vào nhóm mục tiêu phụ được liên kết với TaskSet màu xanh lá cây. Khôi phục đạt được bằng cách thay đổi quy tắc trình nghe sản xuất trở lại nhóm mục tiêu chính.\nNgược lại, với triển khai ECS xanh/xanh lá cây, việc triển khai dịch vụ tạo ra một ServiceRevision mới với các tác vụ (màu xanh lá cây) và đăng ký chúng với nhóm mục tiêu phụ. Sau đó, định tuyến lại và khôi phục đạt được bằng cách chuyển đổi trọng số trên quy tắc listener.\nMóc vòng đời\nCả triển khai CodeDeploy và ECS xanh/xanh đều hỗ trợ hook vòng đời (tùy chọn), trong đó các hàm AWS Lambda có thể được kích hoạt bởi các sự kiện vòng đời cụ thể. Hook rất hữu ích để tăng cường quy trình triển khai với logic tùy chỉnh. Ví dụ: bạn có thể sử dụng móc vòng đời để tự động kiểm tra trên cổng thử nghiệm, trước khi tiến hành định tuyến lại lưu lượng truy cập trực tiếp đến cổng sản xuất.\nTriển khai CodeDeploy và ECS xanh lam/xanh lục thường tuân theo các vòng đời tương tự nhau, nhưng có sự khác biệt về cách chỉ định các tùy chọn cấu hình và móc vòng đời:\n· CodeDeploy chỉ định các móc vòng đời như một phần của tệp AppSpec được cung cấp cho CreateDeployment(). Điều này có nghĩa là các hook cần được cấu hình cho mọi triển khai. Triển khai ECS màu xanh lam/xanh lá cây chỉ định các hook (cùng với vai trò IAM cấp quyền cho Amazon ECS để gọi các hàm Lambda được liên kết) như một phần của cấu hình dịch vụ và mọi thay đổi sẽ cần lệnh gọi UpdateService().\n· Các sự kiện vòng đời CodeDeploy và Amazon ECS tương đương nhau, nhưng chúng có tên khác nhau, như được hiển thị trong bảng dưới đây:\nSự kiện vòng đời Triển khai mã ECS xanh lam / xanh lá cây Trước khi tạo nhiệm vụ mới Trước khi cài đặt PRE_SCALE_UP Nhiệm vụ mới đã sẵn sàng Sau khi cài đặt POST_SCALE_UP Trước khi cổng kiểm tra được bật Không tương đương TEST_TRAFFIC_SHIFT Cổng kiểm tra đã sẵn sàng nhận lưu lượng truy cập SauAllowTestTraffic POST_TEST_TRAFFIC_SHIFT Trước khi định tuyến lại lưu lượng truy cập sản phẩm sang màu xanh lá cây TrướcCho phép lưu lượng truy cập PRODUCTION_TRAFFIC_SHIFT Đã hoàn tất việc định tuyến lại lưu lượng sản phẩm sang màu xanh lá cây AfterAllowLưu lượng truy cập POST_PRODUCTION_TRAFFIC_SHIFT · Cả triển khai CodeDeploy và ECS xanh/xanh lá cây đều sử dụng Lambda để triển khai hook, nhưng đầu vào và đầu ra dự kiến khác nhau, đặc biệt là cách hàm Lambda trả về phản hồi trạng thái hook. Trong CodeDeploy, hàm phải gọi PutLifecycleEventHookExecutionStatus() để trả về trạng thái thực thi hook, có thể là Thành công hoặc Không thành công. Trong Amazon ECS, bản thân phản hồi Lambda được sử dụng để cho biết trạng thái thực thi hook.\n· CodeDeploy gọi mỗi hook dưới dạng lệnh gọi một lần và mong đợi trạng thái thực thi cuối cùng sẽ được trả về trong vòng một giờ. Hook Amazon ECS linh hoạt hơn ở chỗ chúng có thể trả về một chỉ báo IN_PROGRESS, báo hiệu rằng hook nên được gọi lại nhiều lần cho đến khi kết quả là THÀNH CÔNG hoặc THẤT BẠI. Hook được gọi sau mỗi 30 giây theo mặc định, nhưng thời gian của lệnh gọi tiếp theo có thể được định cấu hình bằng cách truyền một tham số trong phản hồi.\nCác cân nhắc triển khai khác\nCodeDeploy cung cấp một số tùy chọn nâng cao cho các nhóm triển khai, bạn có thể cần ánh xạ đến các tùy chọn tương đương của Amazon ECS. Chúng bao gồm những điều sau:\n· Trình kích hoạt Amazon Simple Notification Service (Amazon SNS): sử dụng các sự kiện Amazon EventBridge từ Amazon ECS để phát hành các thay đổi trạng thái đối với chủ đề SNS.\n· Phát hiện cảnh báo Amazon CloudWatch và tự động khôi phục: sử dụng các tính năng phát hiện lỗi triển khai Amazon ECS.\nĐường dẫn di chuyển\nSau khi xem xét sự khác biệt triển khai giữa triển khai CodeDeploy và ECS xanh/xanh, bạn cũng cần xác định phương pháp di chuyển phù hợp. Có một số tùy chọn có sẵn và bạn phải đánh giá tùy chọn nào phù hợp nhất với kiến trúc và yêu cầu của bạn. Các yếu tố liên quan bao gồm:\n· Thời gian ngừng hoạt động: Có bất kỳ thời gian ngừng hoạt động nào không, và nếu có trong bao lâu?\n· Khôi phục sang CodeDeploy: Bạn có cần giữ lại khả năng quay lại quá trình di chuyển nếu việc chuyển sang triển khai ECS màu xanh lam/xanh lá cây gặp trục trặc không? Bạn có thể coi đây là một \u0026ldquo;chiến lược xanh lam / xanh lá cây cho giải pháp xanh lam / xanh lá cây!\u0026rdquo;\n· Khám phá dịch vụ: Bạn có thể thay đổi địa chỉ dịch vụ (URI ALB mới) hay bạn cần giữ nguyên địa chỉ?\n· Hiệu suất và/hoặc tốc độ triển khai\n· Chi phí\nNếu bạn dự định tiếp tục cung cấp dịch vụ của mình bằng cách sử dụng cân bằng tải, các tùy chọn di chuyển sau đây thể hiện các biến thể về mức độ sử dụng lại tài nguyên hiện có, xem xét cả bản thân dịch vụ Amazon ECS và tài nguyên cân bằng tải. Trong mọi trường hợp, bạn phải tạo vai trò IAM để chuyển đến bộ điều khiển triển khai Amazon ECS, cho phép bộ điều khiển này thao tác với các tài nguyên cân bằng tải cần thiết.\nTùy chọn 1: Cập nhật tại chỗ\nTrong cách tiếp cận này, bạn cập nhật dịch vụ Amazon ECS hiện có để sử dụng bộ điều khiển triển khai Amazon ECS với chiến lược triển khai màu xanh lam/xanh lá cây thay vì bộ điều khiển triển khai CodeDeploy. Bạn sử dụng lại cùng một trình nghe cân bằng tải và các nhóm mục tiêu được sử dụng cho CodeDeploy. Như đã đề cập trước đây, CodeDeploy định cấu hình trình nghe của cân bằng tải được đính kèm với dịch vụ bằng một quy tắc (mặc định) duy nhất định tuyến tất cả lưu lượng truy cập đến một nhóm mục tiêu duy nhất (nhóm mục tiêu chính). Đối với triển khai ECS màu xanh lam/xanh lá cây, trình nghe cân bằng tải phải được định cấu hình trước với quy tắc bao gồm hai nhóm mục tiêu có trọng số là 1 và 0. Theo đó, cần thực hiện các bước sau:\n1. Thay đổi quy tắc mặc định của trình nghe sản xuất/thử nghiệm để bao gồm nhóm mục tiêu thay thế và đặt trọng số của nhóm mục tiêu và nhóm mục tiêu thay thế lần lượt là 1 và 0.\n2. Cập nhật dịch vụ Amazon ECS hiện có bằng cách gọi UpdateService(), đặt tham số deploymentController thành ECS và tham số deploymentStrategy thành BLUE/GREEN. Bạn chuyển ARN của vai trò IAM, nhóm đích, nhóm mục tiêu thay thế, quy tắc trình nghe sản xuất và quy tắc trình nghe thử nghiệm (không bắt buộc).\n3. Bộ điều khiển triển khai Amazon ECS tạo một bản sửa đổi dịch vụ mới với các tác vụ mới trong nhóm mục tiêu thay thế, sau đó ngay lập tức định tuyến lại lưu lượng truy cập đến nhóm mục tiêu này. Chờ cho quá trình hoàn tất, sau đó xác minh rằng dịch vụ đang hoạt động như mong đợi.\n4. Xóa tài nguyên CodeDeploy cho dịch vụ Amazon ECS này vì bạn hiện đang sử dụng triển khai ECS màu xanh lam/xanh lá cây.\nCập nhật tại chỗ là một hoạt động an toàn, nhưng bạn nên cẩn thận để (1) tự động hóa quy trình (đặc biệt là khi thay đổi cấu hình trình nghe) để giảm thiểu khả năng xảy ra lỗi thủ công và (2) kiểm tra quy trình này kỹ lưỡng trong môi trường nhà phát triển và/hoặc UAT. Bạn cũng cần lưu ý rằng lưu lượng truy cập sẽ được định tuyến lại ngay lập tức sau khi bộ điều khiển Amazon ECS hoàn tất việc tạo bản sửa đổi dịch vụ ban đầu. Hơn nữa, không có tùy chọn để kiểm tra bản sửa đổi này trước khi định tuyến lại (mặc dù các tác vụ phải giống với các tác vụ đang chạy trong bộ tác vụ CodeDeploy).\nTùy chọn 2: Dịch vụ mới và cân bằng tải hiện có\nCách tiếp cận này sử dụng chiến lược xanh lam / xanh lá cây cho việc di chuyển (nói cách khác, di chuyển màu xanh lam / xanh lá cây của giải pháp xanh lam / xanh lá cây). Bạn tạo một thiết lập song song màu xanh lam/xanh lục mới bằng cách sử dụng triển khai ECS màu xanh lam/xanh lá cây, xác minh, chuyển từ thiết lập CodeDeploy sang thiết lập triển khai ECS xanh/xanh lục mới, sau đó xóa tài nguyên CodeDeploy.\n1. Giữ nguyên trình nghe, nhóm mục tiêu và dịch vụ Amazon ECS cho thiết lập CodeDeploy để bạn có thể quay lại thiết lập này nếu cần.\n2. Tạo các nhóm mục tiêu mới và trình nghe mới (với các cổng khác với trình nghe ban đầu) trong cân bằng tải hiện có. Sau đó, tạo một dịch vụ Amazon ECS mới khớp với dịch vụ Amazon ECS hiện có, ngoại trừ việc bạn sử dụng ECS làm bộ điều khiển triển khai BLUE_GREEN làm chiến lược triển khai và chuyển ARN cho vai trò IAM, nhóm mục tiêu mới và quy tắc trình nghe mới.\n3. Xác minh thiết lập mới (sử dụng các cổng của trình nghe mới). Nếu mọi thứ suôn sẻ, hãy thay đổi các cổng của trình nghe ban đầu thành các số cổng khác nhau (để giải phóng các cổng ban đầu) và chuyển các cổng trên trình nghe mới sang các cổng gốc, do đó định tuyến lưu lượng truy cập đến thiết lập mới.\n4. Quan sát thiết lập mới và nếu mọi thứ tiếp tục hoạt động như mong đợi, bạn có thể xóa thiết lập CodeDeploy.\nHình 4 mô tả cách tiếp cận này.\nHình 4: Phương án 2 – Dịch vụ mới và cân bằng tải hiện có\nTùy chọn 3: Dịch vụ mới và cân bằng tải mới\nGiống như cách tiếp cận trước, cách tiếp cận này sử dụng chiến lược xanh lam / xanh lá cây cho việc di chuyển. Sự khác biệt chính là việc chuyển từ thiết lập CodeDeploy sang thiết lập triển khai màu xanh lam/xanh lá cây ECS xảy ra ở một lớp định tuyến khác phía trên cân bằng tải (như trong Hình 5). Các triển khai có thể cho lớp này bao gồm Amazon Route 53, Amazon API Gateway và Amazon CloudFront.\nCách tiếp cận này phù hợp với người dùng đã có lớp định tuyến này và nếu tất cả giao tiếp với dịch vụ Amazon ECS đang diễn ra thông qua nó (nói cách khác là không có giao tiếp trực tiếp ở cấp cân bằng tải). Khi so sánh với Tùy chọn 2, tùy chọn này có lợi ích là không có thời gian chết nhưng đắt hơn một chút.\nHình 5: Tùy chọn 3 – Dịch vụ mới và cân bằng tải mới\nSự so sánh\nBảng dưới đây so sánh ba phương pháp di chuyển này trên một số yếu tố có thể có mức độ quan trọng khác nhau đối với bạn. Bạn có thể sử dụng bảng này để đánh giá tùy chọn nào phù hợp nhất với hoàn cảnh và ưu tiên cụ thể của riêng bạn.\nTùy chọn 1: Cập nhật tại chỗ Tùy chọn 2: Dịch vụ mới và cân bằng tải hiện có Tùy chọn 3: Dịch vụ mới và cân bằng tải mới Độ phức tạp của quá trình di chuyển Cập nhật đơn giản\u000b: Chiến lược triển khai và bộ điều khiển triển khai dịch vụ Amazon ECS hiện có Phức tạp hơnTạo dịch vụ Amazon ECS mới, nhóm mục tiêu và trình nghe cũng như hoán đổi cổng Phức tạp hơnTạo dịch vụ Amazon ECS mới, nhóm đích, cân bằng tải và trình nghe cũng như thay đổi cấu hình lớp định tuyến Các lựa chọn giảm thiểu rủi ro Trung bìnhKhông có thiết lập song song màu xanh lam / xanh lá cây để thử nghiệm. Tập trung vào tự động hóa quy trình và kiểm tra Thiết lập xanh lam / xanh lá cây StrongParallel, hãy kiểm tra thiết lập mới trước khi định tuyến lại lưu lượng truy cập Thiết lập xanh lam / xanh lá cây StrongParallel, hãy kiểm tra thiết lập mới trước khi định tuyến lại lưu lượng truy cập Khôi phục bộ điều khiển triển khai Đơn giảnThay đổi bộ điều khiển triển khai dịch vụ trở lại CODE_DEPLOY SimpleĐảo ngược hoán đổi cổng SimpleRollback các thay đổi cấu hình lớp định tuyến Downtime Không có thời gian ngừng hoạt động Giảm thiểu gián đoạn trong quá trình hoán đổi cổng Không có thời gian ngừng hoạt động Ứng dụng Không có ràng buộc Không có ràng buộc Yêu cầu lớp định tuyến bổ sung Chi phí Không phát sinh thêm chi phí Chi phí bổ sungHai dịch vụ Amazon ECS cùng tồn tại với các tác vụ liên quan Chi phí bổ sungHai dịch vụ Amazon ECS cùng tồn tại với các tác vụ liên quan và cân bằng tải bổ sung Kết thúc\nTrong bài đăng này, chúng tôi đã thảo luận về việc di chuyển từ AWS CodeDeploy sang Amazon ECS để triển khai xanh/xanh. Cuộc thảo luận này bao gồm những nội dung sau:\n· Các yếu tố cần xem xét trước khi quyết định di chuyển,\n· sự khác biệt chính về kiến trúc và các cân nhắc triển khai liên quan,\n· Ba cách khác nhau để tiếp cận di cư.\nNếu bạn hiện đang sử dụng CodeDeploy và đang cân nhắc chuyển sang triển khai ECS xanh/xanh lá cây, thì bạn có thể sử dụng bài đăng này làm hướng dẫn để đánh giá tính khả thi và lập kế hoạch di chuyển của mình. Để biết thêm thông tin về triển khai ECS xanh/xanh, hãy xem hướng dẫn dành cho nhà phát triển Amazon ECS.\nAbout the authors Mike Rizzo Mike Rizzo là Kiến trúc sư Giải pháp Chính (Principal Solutions Architect) trong nhóm Dịch vụ Tài chính tại AWS Vương quốc Anh. Anh đặc biệt quan tâm đến việc hiện đại hóa ứng dụng, đặc biệt là sử dụng container, serverless và trí tuệ nhân tạo để hỗ trợ triển khai trên nền tảng đám mây. Trong thời gian rảnh, bạn sẽ thấy anh chạy bộ và đạp xe quanh vùng nông thôn Suffolk, nấu món ăn Malta, và chơi Fortnite!\nIslam Mahgoub Islam Mahgoub là Kiến trúc sư Giải pháp Cấp cao (Senior Solutions Architect) tại AWS với hơn 15 năm kinh nghiệm trong lĩnh vực kiến trúc ứng dụng, tích hợp và công nghệ. Tại AWS, anh giúp khách hàng xây dựng các giải pháp tập trung vào đám mây mới và hiện đại hóa các ứng dụng kế thừa bằng cách sử dụng các dịch vụ AWS. Ngoài công việc, Islam thích đi bộ, xem phim và nghe nhạc.\nOlly Pomeroy Olly Pomeroy là Kiến trúc sư Giải pháp Chuyên gia về Container Cấp cao (Senior Container Specialist Solution Architect) tại AWS.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Phá vỡ các silo dữ liệu và truy vấn liền mạch các bảng Iceberg trong Amazon SageMaker từ Snowflake bởi Nidhi Gupta và Andries Engelbrecht vào ngày 15 tháng 9 năm 2025 trong Nâng cao (300), Amazon SageMaker Lakehouse, Amazon Simple Storage Service (S3), AWS Glue, AWS Lake Formation, Giải pháp đối tác, S3 Select, Hướng dẫn kỹ thuật Permalink Chia sẻ nhận xét\nCác tổ chức thường gặp khó khăn trong việc thống nhất hệ sinh thái dữ liệu của họ trên nhiều nền tảng và dịch vụ. Khả năng kết nối giữa Amazon SageMaker và Đám mây dữ liệu AI của Snowflake cung cấp một giải pháp mạnh mẽ cho thách thức này, vì vậy các doanh nghiệp có thể tận dụng thế mạnh của cả hai môi trường trong khi vẫn duy trì chiến lược dữ liệu gắn kết.\nTrong bài đăng này, chúng tôi trình bày cách bạn có thể phá vỡ các silo dữ liệu và nâng cao khả năng phân tích của mình bằng cách truy vấn các bảng Apache Iceberg trongkiến trúc lakehouse của SageMakertrực tiếp từ Snowflake. Với khả năng này, bạn có thể truy cập và phân tích dữ liệu được lưu trữ trongDịch vụ lưu trữ đơn giản của Amazon(Amazon S3) đếnDanh mục dữ liệu AWS Gluesử dụngĐiểm cuối AWS Glue Iceberg REST, tất cả đều được bảo mật bởiAWS Lake Formation, mà không cần các quy trình trích xuất, chuyển đổi và tải (ETL) phức tạp hoặc sao chép dữ liệu. Bạn cũng có thể tự động khám phá và làm mới bảng bằng cách sử dụngCơ sở dữ liệu liên kết với danh mục bông tuyết cho Iceberg. Trong các phần sau, chúng tôi hướng dẫn cách thiết lập tích hợp này để người dùng Snowflake có thể truy vấn và phân tích dữ liệu được lưu trữ trong AWS một cách liền mạch, từ đó cải thiện khả năng truy cập dữ liệu, giảm dư thừa và cho phép phân tích toàn diện hơn trên toàn bộ hệ sinh thái dữ liệu của bạn.\nCác trường hợp sử dụng kinh doanh và lợi ích chính\nKhả năng truy vấn các bảng Iceberg trong SageMaker từ Snowflake mang lại giá trị đáng kể trong nhiều ngành:\n· Dịch vụ tài chính – Tăng cường phát hiện gian lận thông qua phân tích thống nhất dữ liệu giao dịch và mẫu hành vi của khách hàng\n· Chăm sóc sức khỏe - Cải thiện kết quả của bệnh nhân thông qua quyền truy cập tích hợp vào dữ liệu lâm sàng, yêu cầu bồi thường và nghiên cứu\n· Bán lẻ – Tăng tỷ lệ giữ chân khách hàng bằng cách kết nối dữ liệu bán hàng, hàng tồn kho và hành vi của khách hàng để có trải nghiệm được cá nhân hóa\n· Sản xuất – Tăng hiệu quả sản xuất thông qua cảm biến thống nhất và phân tích dữ liệu hoạt động\n· Viễn thông – Giảm tỷ lệ khách hàng rời bỏ với phân tích toàn diện về hiệu suất mạng và dữ liệu sử dụng của khách hàng\nLợi ích chính của khả năng này bao gồm:\n· Đẩy nhanh quá trình ra quyết định – Giảm thời gian thông tin chi tiết thông qua quyền truy cập dữ liệu tích hợp trên các nền tảng\n· Tối ưu hóa chi phí – Đẩy nhanh thời gian thông tin chi tiết bằng cách truy vấn dữ liệu trực tiếp trong bộ nhớ mà không cần nhập\n· Cải thiện độ trung thực của dữ liệu – Giảm sự không nhất quán của dữ liệu bằng cách thiết lập một nguồn tin cậy duy nhất\n· Tăng cường cộng tác – Tăng năng suất đa chức năng thông qua việc chia sẻ dữ liệu đơn giản giữa các nhà khoa học dữ liệu và nhà phân tích\nBằng cách sử dụng kiến trúc lakehouse của SageMaker với sức mạnh tính toán phi máy chủ và không điều chỉnh của Snowflake, bạn có thể phá vỡ các silo dữ liệu, cho phép phân tích toàn diện và dân chủ hóa quyền truy cập dữ liệu. Tích hợp này hỗ trợ kiến trúc dữ liệu hiện đại ưu tiên tính linh hoạt, bảo mật và hiệu suất phân tích, cuối cùng thúc đẩy việc ra quyết định nhanh hơn, sáng suốt hơn trong toàn doanh nghiệp.\nTổng quan về giải pháp\nSơ đồ sau đây cho thấy kiến trúc để tích hợp danh mục giữa bảng Snowflake và Iceberg trong nhà hồ.\nQuy trình làm việc bao gồm các thành phần sau:\n· Lưu trữ và quản lý dữ liệu:\no Amazon S3 đóng vai trò là lớp lưu trữ chính, lưu trữ dữ liệu bảng Iceberg\no Danh mục dữ liệu duy trì siêu dữ liệu cho các bảng này\no Lake Formation cung cấp dịch vụ bán hàng tự động thông tin xác thực\n· Quy trình xác thực:\no Snowflake bắt đầu truy vấn bằng cấu hình tích hợp danh mục\no Lake Formation cung cấp thông tin xác thực tạm thời thông qua AWS Security Token Service (AWS STS)\no Các thông tin đăng nhập này được tự động làm mới dựa trên khoảng thời gian làm mới đã đặt cấu hình\n· Luồng truy vấn:\no Người dùng Snowflake gửi truy vấn đối với các bảng Iceberg được gắn kết\no Điểm cuối AWS Glue Iceberg REST xử lý các yêu cầu này\no Thực thi truy vấn sử dụng tài nguyên điện toán của Snowflake trong khi đọc trực tiếp từ Amazon S3\no Kết quả được trả về cho người dùng Snowflake trong khi vẫn duy trì tất cả các biện pháp kiểm soát bảo mật\nCó bốn mẫu để truy vấn bảng Iceberg trong SageMaker từ Snowflake:\n· Bảng Iceberg trong vùng lưu trữ S3 sử dụng điểm cuối AWS Glue Iceberg REST và tích hợp danh mục Snowflake Iceberg REST, với dịch vụ bán thông tin xác thực từ Lake Formation\n· Bảng Iceberg trong vùng lưu trữ S3 sử dụng điểm cuối AWS Glue Iceberg REST và tích hợp danh mục Snowflake Iceberg REST, sử dụng ổ đĩa ngoài Snowflake để lưu trữ dữ liệu Amazon S3\n· Bảng Iceberg trong vùng lưu trữ S3 sử dụng tích hợp danh mục API AWS Glue, cũng sử dụng ổ đĩa ngoài Snowflake vào Amazon S3\n· Bảng Amazon S3 sử dụng tích hợp danh mục Iceberg REST với bán thông tin xác thực từ Lake Formation\nTrong bài đăng này, chúng tôi triển khai mẫu truy cập đầu tiên trong số bốn mẫu truy cập này bằng cách sử dụng tích hợp danh mục cho điểm cuối AWS Glue Iceberg REST với xác thực Signature Phiên bản 4 (SigV4) trong Snowflake.\nĐiều kiện tiên quyết\nBạn phải có các điều kiện tiên quyết sau:\n· Một tài khoản Bông tuyết.\n· Vai trò AWS Identity and Access Management (IAM) là quản trị viên hồ dữ liệu Lake Formation trong tài khoản AWS của bạn. Quản trị viên hồ dữ liệu là người chính IAM có thể đăng ký vị trí Amazon S3, truy cập Danh mục dữ liệu, cấp quyền Lake Formation cho người dùng khác và xem AWS CloudTrail. Xem Tạo quản trị viên hồ dữ liệu để biết thêm thông tin.\n· Một cơ sở dữ liệu AWS Glue hiện có có tên iceberg_db và bảng Iceberg được đặt tên là khách hàng với dữ liệu được lưu trữ trong vùng lưu trữ đa năng S3 với một tên duy nhất. Để tạo bảng, hãy tham khảo lược đồ và tập dữ liệu bảng.\n· Vai trò IAM do người dùng xác định mà Lake Formation đảm nhận khi truy cập dữ liệu ở vị trí S3 nói trên để cung cấp thông tin xác thực có phạm vi (xem Yêu cầu đối với vai trò được sử dụng để đăng ký vị trí). Đối với bài đăng này, chúng tôi sử dụng vai trò IAM LakeFormationLocationRegistrationRole.\nGiải pháp mất khoảng 30–45 phút để thiết lập. Chi phí thay đổi dựa trên khối lượng dữ liệu và tần suất truy vấn. Sử dụng Công cụ tính giá AWS để biết các ước tính cụ thể.\nTạo vai trò IAM cho Snowflake\nĐể tạo vai trò IAM cho Snowflake, trước tiên bạn tạo một chính sách cho vai trò:\n1. Trên bảng điều khiển IAM, chọn Chính sách trong ngăn điều hướng.\n2. Chọn Tạo chính sách.\n3. Chọn trình chỉnh sửa JSON và nhập chính sách sau (cung cấp Khu vực AWS và ID tài khoản của bạn), sau đó chọn Tiếp theo.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGlueCatalogTableAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:GetCatalog\u0026#34;, \u0026#34;glue:GetCatalogs\u0026#34;, \u0026#34;glue:GetPartitions\u0026#34;, \u0026#34;glue:GetPartition\u0026#34;, \u0026#34;glue:GetDatabase\u0026#34;, \u0026#34;glue:GetDatabases\u0026#34;, \u0026#34;glue:GetTable\u0026#34;, \u0026#34;glue:GetTables\u0026#34;, \u0026#34;glue:UpdateTable\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:glue:\u0026lt;region\\\u0026gt;:\u0026lt;account-id\\\u0026gt;:catalog\u0026#34;, \u0026#34;arn:aws:glue:\u0026lt;region\\\u0026gt;:\u0026lt;account-id\\\u0026gt;:database/iceberg_db\u0026#34;, \u0026#34;arn:aws:glue:\u0026lt;region\\\u0026gt;:\u0026lt;account-id\\\u0026gt;:table/iceberg_db/\\*\u0026#34;, ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lakeformation:GetDataAccess\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } 4. Nhập iceberg-table-access làm tên chính sách.\n5. Chọn Tạo chính sách.\nBây giờ bạn có thể tạo vai trò và đính kèm chính sách bạn đã tạo.\n6. Chọn Vai trò trong ngăn điều hướng.\n7. Chọn Tạo vai trò.\n8. Chọn tài khoản AWS.\n9. Trong Tùy chọn, chọn Yêu cầu ID bên ngoài và nhập ID bên ngoài mà bạn chọn.\n10. Chọn Tiếp theo.\n11. Chọn chính sách bạn đã tạo (chính sách iceberg-table-access).\n12. Nhập snowflake_access_role làm tên vai trò.\n13. Chọn Tạo vai trò.\nĐịnh cấu hình kiểm soát truy cập Lake Formation\nĐể định cấu hình kiểm soát truy cập Lake Formation của bạn, trước tiên hãy thiết lập tích hợp ứng dụng:\n1. Đăng nhập vào bảng điều khiển Lake Formation với tư cách quản trị viên hồ dữ liệu.\n2. Chọn Quản trị trong ngăn điều hướng.\n3. Chọn Cài đặt tích hợp ứng dụng.\n4. Bật Cho phép công cụ bên ngoài truy cập dữ liệu trong các vị trí Amazon S3 với quyền truy cập bảng đầy đủ.\n5. Chọn Lưu.\nGiờ đây, bạn có thể cấp quyền cho vai trò IAM.\n6. Chọn Quyền dữ liệu trong ngăn điều hướng.\n7. Chọn Grant.\n8. Định cấu hình các cài đặt sau:\na. Đối với Hiệu trưởng, chọn Người dùng và vai trò IAM rồi chọn snowflake_access_role.\nb.\tĐối với Tài nguyên, hãy chọn Tài nguyên Danh mục dữ liệu được đặt tên.\nc. Đối với Danh mục, hãy chọn ID tài khoản AWS của bạn.\nd.\tĐối với Cơ sở dữ liệu, chọn iceberg_db.\ne. Đối với Bảng, chọn customer.\nf. Đối với Quyền, hãy chọn SUPER.\n9. Chọn Grant.\nCần có quyền truy cập SUPER để gắn bảng Iceberg trong Amazon S3 dưới dạng bảng Bông tuyết.\nĐăng ký vị trí hồ dữ liệu S3\nHoàn thành các bước sau để đăng ký vị trí hồ dữ liệu S3:\n1. Với tư cách là quản trị viên hồ dữ liệu trên bảng điều khiển Lake Formation, hãy chọn Vị trí hồ dữ liệu trong ngăn điều hướng.\n2. Chọn Đăng ký địa điểm.\n3. Định cấu hình như sau:\na. Đối với đường dẫn S3, hãy nhập đường dẫn S3 đến vùng lưu trữ nơi bạn sẽ lưu trữ dữ liệu của mình.\nb.\tĐối với vai trò IAM, hãy chọn LakeFormationLocationRegistrationRole.\nc. Đối với Chế độ Quyền, chọn Thành tạo hồ.\n4. Chọn Đăng ký địa điểm.\nThiết lập tích hợp Iceberg REST trong Snowflake\nHoàn thành các bước sau để thiết lập tích hợp Iceberg REST trong Snowflake:\n1. Đăng nhập vào Snowflake với tư cách là người dùng quản trị.\n2. Thực hiện lệnh SQL sau (cung cấp Khu vực, ID tài khoản và ID bên ngoài mà bạn đã cung cấp trong quá trình tạo vai trò IAM):\nCREATE OR REPLACE CATALOG INTEGRATION glue_irc_catalog_int CATALOG_SOURCE = ICEBERG_REST TABLE_FORMAT = ICEBERG CATALOG_NAMESPACE = \u0026#39;iceberg_db\u0026#39; REST_CONFIG = ( CATALOG_URI = \u0026#39;https://glue.\u0026lt;region\u0026gt;.amazonaws.com/iceberg\u0026#39; CATALOG_API_TYPE = AWS_GLUE CATALOG_NAME = \u0026#39;\u0026lt;account-id\u0026gt;\u0026#39; ACCESS_DELEGATION_MODE = VENDED_CREDENTIALS ) REST_AUTHENTICATION = ( TYPE = SIGV4 SIGV4_IAM_ROLE = \u0026#39;arn:aws:iam::\u0026lt;account-id\u0026gt;:role/snowflake_access_role\u0026#39; SIGV4_SIGNING_REGION = \u0026#39;\u0026lt;region\u0026gt;\u0026#39; SIGV4_EXTERNAL_ID = \u0026#39;\u0026lt;external-id\u0026gt;\u0026#39; ) REFRESH_INTERVAL_SECONDS = 120 ENABLED = TRUE; 3. Thực hiện lệnh SQL sau và truy xuất giá trị cho API_AWS_IAM_USER_ARN:\nDESCRIBE CATALOG INTEGRATION glue_irc_catalog_int; 4. Trên bảng điều khiển IAM, hãy cập nhật mối quan hệ tin cậy cho snowflake_access_role với giá trị cho API_AWS_IAM_USER_ARN:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;\u0026lt;API_AWS_IAM_USER_ARN\u0026gt;\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;sts:ExternalId\u0026#34;: [ \u0026#34;\u0026lt;external-id\u0026gt;\u0026#34; ] } } } ] } 5. Xác minh việc tích hợp danh mục:\nSELECT SYSTEM$VERIFY_CATALOG_INTEGRATION(\u0026#39;glue_irc_catalog_int\u0026#39;); 6. Gắn bảng S3 làm bàn Bông tuyết:\nCREATE OR REPLACE ICEBERG TABLE s3iceberg_customer CATALOG = \u0026#39;glue_irc_catalog_int\u0026#39; CATALOG_NAMESPACE = \u0026#39;iceberg_db\u0026#39; CATALOG_TABLE_NAME = \u0026#39;customer\u0026#39; AUTO_REFRESH = TRUE; Truy vấn bảng Iceberg từ Snowflake\nĐể kiểm tra cấu hình, hãy đăng nhập vào Snowflake với tư cách là người dùng quản trị và chạy truy vấn mẫu sau:\nSELECT * FROM s3iceberg_customer LIMIT 10; Quét dọn\nĐể dọn dẹp tài nguyên của bạn, hãy hoàn thành các bước sau:\n1. Xóa cơ sở dữ liệu và bảng trong AWS Glue.\n2. Thả bảng Iceberg, tích hợp danh mục và cơ sở dữ liệu trong Snowflake:\nDROP ICEBERG TABLE iceberg_customer; DROP CATALOG INTEGRATION glue_irc_catalog_int; Đảm bảo rằng tất cả các tài nguyên được dọn dẹp đúng cách để tránh các khoản phí không mong muốn.\nKết thúc\nTrong bài đăng này, chúng tôi đã trình bày cách thiết lập kết nối an toàn và hiệu quả giữa môi trường Snowflake của bạn và SageMaker để truy vấn các bảng Iceberg trong Amazon S3. Khả năng này có thể giúp tổ chức của bạn duy trì một nguồn tin cậy duy nhất đồng thời cho phép các nhóm sử dụng các công cụ phân tích ưa thích của họ, cuối cùng phá vỡ các silo dữ liệu và nâng cao khả năng phân tích cộng tác.\nĐể khám phá thêm và triển khai giải pháp này trong môi trường của bạn, hãy xem xét các tài nguyên sau:\n· Tài liệu kỹ thuật:\no Xem lại Hướng dẫn sử dụng Amazon SageMaker Lakehouse\no Khám phá Bảo mật trong AWS Lake Formation để biết các biện pháp thực hành tốt nhất nhằm tối ưu hóa các biện pháp kiểm soát bảo mật của bạn\no Tìm hiểu thêm về định dạng bảng Iceberg và lợi ích của nó đối với hồ dữ liệu\no Tham khảo Cấu hình truy cập an toàn từ Snowflake sang Amazon S3\n· Các bài đăng trên blog liên quan:\no Xây dựng hồ dữ liệu theo thời gian thực với Bảng Snowflake và Amazon S3\no Đơn giản hóa quyền truy cập dữ liệu cho doanh nghiệp của bạn bằng cách sử dụng Amazon SageMaker Lakehouse\nNhững tài nguyên này có thể giúp bạn triển khai và tối ưu hóa mẫu tích hợp này cho trường hợp sử dụng cụ thể của bạn. Khi bạn bắt đầu hành trình này, hãy nhớ bắt đầu từ quy mô nhỏ, xác thực kiến trúc của bạn với dữ liệu thử nghiệm và dần dần mở rộng quy mô triển khai dựa trên nhu cầu của tổ chức bạn.\nVề các tác giả Nidhi Gupta Nidhi là Kiến trúc sư Giải pháp Đối tác Cấp cao tại AWS, chuyên về dữ liệu và phân tích. Cô hỗ trợ khách hàng và đối tác xây dựng và tối ưu hóa các khối công việc Snowflake trên AWS. Nidhi có nhiều kinh nghiệm trong việc dẫn dắt các lần phát hành và triển khai sản phẩm, với trọng tâm về Dữ liệu, Trí tuệ nhân tạo (AI), Học máy (ML), Trí tuệ nhân tạo tạo sinh (Generative AI), và Phân tích nâng cao (Advanced Analytics).\nAndries Engelbrecht Andries là Kỹ sư Giải pháp Đối tác Cấp cao tại Snowflake, làm việc cùng AWS. Anh hỗ trợ việc tích hợp sản phẩm và dịch vụ, cũng như phát triển các giải pháp chung với AWS. Andries có hơn 25 năm kinh nghiệm trong lĩnh vực dữ liệu và phân tích.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Điều hướng các gói bảo vệ Amazon GuardDuty và Phát hiện mối đe dọa mở rộng by Nisha Amthul, Shachar Hirshberg và Sujay Doshi on 15 SEP 2025 in Amazon GuardDuty, Intermediate (200), Security, Identity, \u0026amp; Compliance Permalink Comments Chia sẻ\nCác tổ chức đang đổi mới và phát triển sự hiện diện trên đám mây của họ để mang lại trải nghiệm khách hàng tốt hơn và thúc đẩy giá trị kinh doanh. Để hỗ trợ và bảo vệ sự tăng trưởng này, các tổ chức có thể sử dụng Amazon GuardDuty, một dịch vụ phát hiện mối đe dọa liên tục giám sát hoạt động độc hại và hành vi trái phép trên môi trường AWS của bạn. GuardDuty sử dụng trí tuệ nhân tạo (AI), máy học (ML) và phát hiện bất thường bằng cách sử dụng cả AWS và thông tin về mối đe dọa hàng đầu trong ngành để giúp bảo vệ tài khoản, khối lượng công việc và dữ liệu AWS của bạn. Dựa trên các khả năng cơ bản này, GuardDuty cung cấp một bộ kế hoạch bảo vệ toàn diện và tính năng Phát hiện mối đe dọa mở rộng.\nTrong bài đăng này, chúng tôi khám phá cách sử dụng các tính năng này để cung cấp phạm vi bảo mật mạnh mẽ cho khối lượng công việc AWS của bạn, giúp bạn phát hiện các mối đe dọa tinh vi trên môi trường AWS của mình.\nTìm hiểu về các gói bảo vệ GuardDuty\nGuardDuty bắt đầu với tính năng giám sát bảo mật cơ bản, phân tích các sự kiện quản lý AWS CloudTrail, Nhật ký luồng Amazon Virtual Private Cloud (Amazon VPC) và nhật ký DNS. Dựa trên nền tảng này, GuardDuty cung cấp một số gói bảo vệ giúp mở rộng khả năng phát hiện mối đe dọa sang các nguồn dữ liệu và dịch vụ AWS bổ sung. Các gói bảo vệ này là các tính năng tùy chọn phân tích dữ liệu từ các dịch vụ AWS cụ thể trong môi trường của bạn để cung cấp phạm vi bảo mật nâng cao. GuardDuty cung cấp sự linh hoạt để tùy chỉnh cách các tài khoản mới kế thừa các kế hoạch bảo vệ, vì vậy bạn có thể thêm bảo hiểm cho các tài khoản của mình hoặc chọn các tài khoản cụ thể dựa trên nhu cầu bảo mật của mình. Bạn có thể bật hoặc tắt các gói bảo vệ này bất kỳ lúc nào để phù hợp với các yêu cầu về khối lượng công việc đang phát triển của mình.\nDưới đây là các gói bảo vệ GuardDuty có sẵn và khả năng của chúng:\nGói bảo vệ GuardDuty Sự mô tả Bảo vệ S3 Xác định các rủi ro bảo mật tiềm ẩn như nỗ lực lấy cắp và phá hủy dữ liệu trong vùng lưu trữ Amazon Simple Storage Service (Amazon S3) của bạn. Bảo vệ EKS Giám sát nhật ký kiểm tra EKS phân tích nhật ký kiểm tra Kubernetes từ các cụm Amazon Elastic Kubernetes Service (Amazon EKS) của bạn để tìm các hoạt động đáng ngờ và độc hại tiềm ẩn. Giám sát thời gian chạy Giám sát và phân tích các sự kiện cấp hệ điều hành trên Amazon EKS, Amazon Elastic Compute Cloud (Amazon EC2) và Amazon Elastic Container Service (Amazon ECS) (bao gồm AWS Fargate) để phát hiện các mối đe dọa tiềm ẩn trong thời gian chạy. Bảo vệ phần mềm độc hại cho EC2 Phát hiện sự hiện diện tiềm ẩn của phần mềm độc hại bằng cách quét ổ đĩa Amazon Elastic Block Store (Amazon EBS) được liên kết với các phiên bản EC2 của bạn. Có một tùy chọn để sử dụng tính năng này theo yêu cầu. Bảo vệ phần mềm độc hại cho S3 Phát hiện sự hiện diện tiềm ẩn của phần mềm độc hại trong các đối tượng mới tải lên trong vùng lưu trữ S3 của bạn. Bảo vệ RDS Phân tích và lập hồ sơ hoạt động đăng nhập RDS của bạn để tìm các mối đe dọa truy cập tiềm ẩn đối với cơ sở dữ liệu Amazon Aurora và Amazon Relational Database Service (Amazon RDS) được hỗ trợ. Bảo vệ Lambda Giám sát nhật ký hoạt động mạng AWS Lambda, bắt đầu với Nhật ký luồng VPC, để phát hiện các mối đe dọa đối với các hàm Lambda của bạn. Ví dụ về các mối đe dọa tiềm ẩn này bao gồm khai thác tiền điện tử và giao tiếp với các máy chủ độc hại. Hãy cùng khám phá cách các gói bảo vệ này giúp bảo mật các khía cạnh khác nhau của môi trường AWS của bạn.\nBảo vệ S3\nS3 Protection mở rộng khả năng phát hiện mối đe dọa của GuardDuty cho vùng lưu trữ S3 của bạn bằng cách giám sát các hoạt động API cấp đối tượng. Ngoài giám sát cơ bản, nó phân tích các mẫu hành vi để phát hiện các mối đe dọa tinh vi. Khi tác nhân đe dọa cố gắng lấy cắp dữ liệu, GuardDuty có thể phát hiện các chuỗi lệnh gọi API bất thường, chẳng hạn như các hoạt động ListBucket, sau đó là các yêu cầu GetObject đáng ngờ từ các vị trí bất thường. Nó cũng xác định các rủi ro bảo mật tiềm ẩn như nỗ lực vô hiệu hóa ghi nhật ký truy cập máy chủ S3 hoặc các thay đổi trái phép đối với chính sách vùng lưu trữ có thể cho thấy nỗ lực đặt vùng lưu trữ ở chế độ công khai. Ví dụ: GuardDuty sẽ tạo kết quả truy cập trái phép nếu phát hiện các lệnh gọi API đáng ngờ này bắt nguồn từ các địa chỉ IP độc hại đã biết.\nBảo vệ EKS\nĐối với khối lượng công việc trong bộ chứa, EKS Protection giám sát nhật ký kiểm tra mặt phẳng điều khiển của cụm Amazon EKS để tìm các mối đe dọa bảo mật. Nó được thiết kế đặc biệt để phát hiện khai thác dựa trên bộ chứa bằng cách phân tích nhật ký kiểm tra Kubernetes từ các cụm EKS của bạn. GuardDuty phát hiện các tình huống như bộ chứa được triển khai với các đặc điểm đáng ngờ (như hình ảnh độc hại đã biết), cố gắng leo thang đặc quyền thông qua các sửa đổi liên kết vai trò và các hoạt động tài khoản dịch vụ đáng ngờ có thể cho thấy môi trường Kubernetes của bạn bị xâm phạm. Khi phát hiện các hoạt động như vậy, GuardDuty sẽ tạo kết quả PrivilegeEscalation, cảnh báo bạn về các nỗ lực truy cập trái phép tiềm ẩn trong các cụm của bạn. Để hiểu toàn diện về chiến thuật, kỹ thuật và quy trình (TTP), hãy xem Danh mục kỹ thuật về mối đe dọa của AWS.\nGiám sát thời gian chạy\nGiám sát thời gian chạy cung cấp khả năng hiển thị sâu hơn về các mối đe dọa tiềm ẩn bằng cách phân tích hành vi thời gian chạy trong các phiên bản EC2, cụm EKS và khối lượng công việc bộ chứa. Khả năng này phát hiện các mối đe dọa biểu hiện ở cấp hệ điều hành bằng cách giám sát việc thực thi quy trình, thay đổi hệ thống tệp và kết nối mạng. GuardDuty có thể xác định các chiến thuật trốn tránh phòng thủ, thực hiện các quy trình đáng ngờ và các mẫu truy cập tệp cho thấy hoạt động phần mềm độc hại tiềm ẩn. Ví dụ: nếu một phiên bản bị xâm nhập cố gắng vô hiệu hóa tính năng giám sát bảo mật hoặc tạo ra các quy trình bất thường, GuardDuty sẽ tạo kết quả Thời gian chạy cho biết hoạt động độc hại tiềm ẩn ở cấp hệ điều hành.\nBảo vệ phần mềm độc hại\nBảo vệ chống phần mềm độc hại cung cấp hai khả năng riêng biệt: quét ổ đĩa EBS được gắn vào phiên bản EC2 và quét các đối tượng được tải lên vùng lưu trữ S3. Đối với các phiên bản EC2, GuardDuty có thể thực hiện cả quét theo yêu cầu không tác nhân và quét liên tục ổ đĩa EBS, phát hiện cả phần mềm độc hại đã biết và các tệp độc hại tiềm ẩn bằng phương pháp phỏng đoán nâng cao. Đối với S3, nó tự động quét các đối tượng mới tải lên, giúp bảo vệ chống lại sự phân tán phần mềm độc hại thông qua vùng lưu trữ S3 của bạn. Khi phát hiện phần mềm độc hại, GuardDuty sẽ tạo ra phát hiện phần mềm độc hại, chỉ định xem mối đe dọa được tìm thấy trong phiên bản EC2 hay vùng lưu trữ S3, giúp bạn nhanh chóng xác định và ứng phó với mối đe dọa.\nBảo vệ RDS\nRDS Protection tập trung vào bảo mật cơ sở dữ liệu bằng cách phân tích hoạt động đăng nhập cho cơ sở dữ liệu Amazon Aurora được hỗ trợ. Nó tạo ra các đường cơ sở hành vi của các mẫu truy cập cơ sở dữ liệu thông thường và có thể phát hiện các nỗ lực đăng nhập bất thường có thể cho thấy các nỗ lực truy cập trái phép. Điều này bao gồm phát hiện các mẫu đăng nhập bất thường, truy cập từ các vị trí không mong muốn và các nỗ lực xâm phạm cơ sở dữ liệu tiềm ẩn. Khi phát hiện truy cập cơ sở dữ liệu đáng ngờ, GuardDuty sẽ tạo kết quả RDS, cảnh báo bạn về khả năng truy cập trái phép hoặc xâm phạm thông tin đăng nhập.\nBảo vệ Lambda\nLambda Protection giám sát các ứng dụng phi máy chủ của bạn bằng cách phân tích hoạt động của hàm Lambda thông qua Nhật ký luồng VPC. Nó có thể phát hiện các mối đe dọa cụ thể đối với môi trường phi máy chủ, chẳng hạn như khi các hàm Lambda có dấu hiệu bị xâm phạm thông qua các kết nối mạng không mong muốn hoặc hoạt động khai thác tiền điện tử tiềm ẩn. Nếu hàm Lambda cố gắng giao tiếp với các địa chỉ IP độc hại đã biết hoặc có dấu hiệu cryptojacking, GuardDuty sẽ tạo kết quả Lambda, vì vậy bạn có thể nhanh chóng xác định và khắc phục các hàm bị xâm phạm.\nMỗi gói bảo vệ bổ sung các khả năng phát hiện chuyên biệt được thiết kế cho các loại khối lượng công việc cụ thể, phối hợp với nhau để cung cấp khả năng phát hiện mối đe dọa toàn diện trên môi trường AWS của bạn. Bằng cách bật các gói bảo vệ liên quan đến khối lượng công việc của mình, bạn có thể giúp đảm bảo rằng GuardDuty cung cấp khả năng giám sát bảo mật có mục tiêu cho các trường hợp sử dụng cụ thể của mình\nĐiều chỉnh các kế hoạch bảo vệ GuardDuty cho phù hợp với loại khối lượng công việc của bạn\nĐể tối đa hóa phạm vi phát hiện mối đe dọa, hãy cân nhắc bật tất cả các gói bảo vệ GuardDuty hiện hành trên môi trường AWS của bạn. Cách tiếp cận này giúp cung cấp phạm vi bảo vệ toàn diện trong khi vẫn duy trì hiệu quả chi phí vì bạn chỉ bị tính phí cho các biện pháp bảo vệ đang hoạt động đối với các tài nguyên tồn tại trong tài khoản của mình. Ví dụ: nếu bạn không sử dụng Amazon EKS, bạn sẽ không phải trả phí cho Bảo vệ EKS ngay cả khi nó được bật. Chiến lược này cũng giúp tạo điều kiện bảo mật tự động nếu các nhóm triển khai dịch vụ mới mà không yêu cầu sự can thiệp của nhóm bảo mật ngay lập tức. Bạn có thể linh hoạt điều chỉnh các kế hoạch bảo vệ của mình bất cứ lúc nào khi yêu cầu khối lượng công việc của bạn phát triển.\nDựa trên các biện pháp thực hành tốt nhất về bảo mật của AWS, chúng tôi đưa ra các đề xuất cho các kết hợp gói bảo vệ khác nhau phù hợp với hồ sơ khối lượng công việc phổ biến. Những đề xuất này giúp bạn hiểu cách các gói bảo vệ khác nhau hoạt động cùng nhau để bảo mật các kiến trúc cụ thể của bạn. Đối với khối lượng công việc Amazon EC2 và Amazon S3, GuardDuty khuyến nghị Foundational, Amazon S3 Protection và Amazon GuardDuty Malware Protection cho Amazon EC2 để phát hiện các mối đe dọa đối với các phiên bản điện toán, lưu trữ dữ liệu và lạm dụng AWS Identity and Access Management (IAM).\nCác môi trường sử dụng nhiều bộ chứa sử dụng Amazon EKS và Amazon ECS được hưởng lợi từ Foundational, Amazon EKS Protection, Amazon GuardDuty Runtime Monitoring và Amazon GuardDuty Malware Protection for Amazon EC2. Các kế hoạch này hoạt động cùng nhau để giám sát mặt phẳng điều khiển bộ chứa và thời gian chạy để tìm các mối đe dọa và phần mềm độc hại.\nĐối với các kiến trúc ưu tiên phi máy chủ được xây dựng trên Lambda, GuardDuty đề xuất Foundational, AWS Lambda Protection và Amazon S3 Protection (nếu sử dụng trình kích hoạt Amazon S3) để xác định hành vi chức năng bất thường và các mẫu lưu lượng truy cập đáng ngờ.\nCác hệ thống dữ liệu sử dụng Amazon Aurora hoặc Amazon RDS nên xem xét Foundational, Amazon RDS Protection, Amazon S3 Protection và Amazon GuardDuty Malware Protection for Amazon S3. Sự kết hợp này giúp phát hiện đăng nhập cơ sở dữ liệu bất thường và khả năng sử dụng sai vùng lưu trữ S3.\nĐối với các môi trường được quản lý hoặc những môi trường triển khai kiến trúc không tin cậy, việc bật tất cả các gói bảo vệ GuardDuty giúp cung cấp phạm vi phát hiện mối đe dọa toàn diện có thể hỗ trợ các yêu cầu chương trình tuân thủ và giám sát bảo mật rộng hơn của bạn.\nĐể tham khảo nhanh, đây là những gói bảo vệ bạn nên sử dụng để chủ động theo dõi các loại khối lượng công việc khác nhau của mình:\nHồ sơ khối lượng công việc Kết quả bảo mật dự kiến Các gói GuardDuty được đề xuất Amazon EC2 và Amazon S3 Phát hiện các mối đe dọa đối với phiên bản điện toán, lưu trữ dữ liệu và lạm dụng IAM Bảo vệ nền tảng, Amazon S3 Protection và Bảo vệ phần mềm độc hại Amazon GuardDuty cho Amazon EC2 Nặng bộ chứa (Amazon EKS, Amazon ECS) Giám sát mặt phẳng điều khiển bộ chứa và thời gian chạy để phát hiện các mối đe dọa và phần mềm độc hại Nền tảng, Bảo vệ Amazon EKS, Giám sát thời gian chạy của Amazon GuardDuty và Bảo vệ chống phần mềm độc hại của Amazon GuardDuty cho Amazon EC2 Ưu tiên phi máy chủ (AWS Lambda) Xác định hành vi chức năng bất thường và các mẫu lưu lượng đáng ngờ Nền tảng, GuardDuty Lambda Protection, GuardDuty S3 Protection (nếu sử dụng trình kích hoạt Amazon S3) và GuardDuty Runtime Monitoring cho ECS trên Fargate Hệ thống dữ liệu (Amazon Aurora hoặc Amazon RDS) Phát hiện đăng nhập cơ sở dữ liệu bất thường và khả năng sử dụng sai vùng lưu trữ S3 Nền tảng, Bảo vệ Amazon RDS, Bảo vệ GuardDuty S3 và Bảo vệ chống phần mềm độc hại của Amazon GuardDuty cho Amazon S3 Được quản lý và không tin cậy Phát hiện mối đe dọa toàn diện để hỗ trợ các yêu cầu tuân thủ Tất cả các gói bảo vệ Amazon GuardDuty Sức mạnh của GuardDuty Phát hiện mối đe dọa mở rộng\nDựa trên các kế hoạch bảo vệ này, GuardDuty cung cấp tính năng Phát hiện mối đe dọa mở rộng theo mặc định mà không mất thêm phí, sử dụng các chức năng AI/ML để cải thiện khả năng phát hiện mối đe dọa cho các ứng dụng, khối lượng công việc và dữ liệu của bạn. Khả năng này tương quan các tín hiệu bảo mật để xác định chuỗi mối đe dọa đang hoạt động, cung cấp cách tiếp cận toàn diện hơn đối với bảo mật đám mây.\nPhát hiện mối đe dọa mở rộng bao gồm mức độ nghiêm trọng nghiêm trọng đối với các mối đe dọa khẩn cấp và có độ tin cậy cao nhất dựa trên nhiều bước tương quan do đối thủ thực hiện, chẳng hạn như khám phá đặc quyền, thao túng API, hoạt động liên tục và đánh cắp dữ liệu. Tích hợp với khung MITRE ATT\u0026amp;CK® cho phép GuardDuty ánh xạ các hoạt động quan sát được với các chiến thuật và kỹ thuật, cung cấp bối cảnh cho các nhóm bảo mật. Để giúp các nhóm phản ứng nhanh chóng, GuardDuty cung cấp các đề xuất khắc phục cụ thể dựa trên các biện pháp thực hành tốt nhất của AWS cho từng mối đe dọa đã xác định.\nBảo vệ trong thế giới thực: Phát hiện mối đe dọa mở rộng đang hoạt động\nĐể hiểu cách các kế hoạch bảo vệ GuardDuty và Phát hiện mối đe dọa mở rộng hoạt động cùng nhau trong thực tế, chúng ta hãy xem xét hai tình huống đe dọa phức tạp mà các nhóm bảo mật thường gặp phải: xâm phạm dữ liệu và xâm phạm cụm container.\nPhát hiện xâm phạm dữ liệu\nPhát hiện mối đe dọa mở rộng của GuardDuty liên tục phân tích và tương quan các sự kiện trên nhiều gói bảo vệ, cung cấp khả năng hiển thị toàn diện khi xảy ra nỗ lực xâm phạm dữ liệu trong Amazon S3. Ví dụ: trong một sự cố gần đây, GuardDuty đã xác định một chuỗi tấn công nghiêm trọng kéo dài 24 giờ. Trình tự bắt đầu với các hành động khám phá thông qua các lệnh gọi API S3 bất thường, tiến triển đến việc trốn tránh phòng thủ thông qua các sửa đổi CloudTrail và lên đến đỉnh điểm là các nỗ lực lấy cắp dữ liệu tiềm năng.\nTrong giai đoạn khám phá, S3 Protection đã phát hiện một vai trò IAM thực hiện các lệnh gọi API ListBucket và GetObject bất thường trên nhiều vùng lưu trữ—một sai lệch đáng kể so với mô hình thông thường của họ là chỉ truy cập vào các vùng lưu trữ được chỉ định cụ thể. Sau đó, Phát hiện mối đe dọa mở rộng tương quan hoạt động đáng ngờ này với các hành động tiếp theo từ cùng một vai trò IAM: cố gắng tắt tính năng ghi nhật ký CloudTrail và sửa đổi chính sách vùng lưu trữ (dấu hiệu ẩn tránh phòng thủ cổ điển), sau đó là tạo khóa truy cập mới. Chuỗi sự kiện được kết nối này, tất cả đều từ cùng một danh tính, cho thấy một khai thác tiến triển chuyển từ khám phá ban đầu đến thiết lập sự bền bỉ thông qua việc tạo thông tin xác thực.\nXâm phạm môi trường container\nBảo vệ môi trường trong bộ chứa đòi hỏi khả năng hiển thị trên nhiều lớp cơ sở hạ tầng Amazon EKS của bạn. GuardDuty kết hợp các tín hiệu từ mặt phẳng điều khiển EKS (thông qua EKS Protection), hành vi thời gian chạy của bộ chứa (thông qua Giám sát thời gian chạy) và nhật ký cơ sở hạ tầng cơ bản để phát hiện mối đe dọa toàn diện cho các cụm Kubernetes của bạn. Ví dụ: Bảo vệ EKS phát hiện các hoạt động đáng ngờ ở cấp mặt phẳng điều khiển Kubernetes, chẳng hạn như các nỗ lực xác thực máy chủ API Kubernetes bất thường hoặc tạo tài khoản dịch vụ có quyền nâng cao. Giám sát thời gian chạy cung cấp khả năng hiển thị hành vi của bộ chứa, xác định các lệnh đặc quyền không mong muốn hoặc truy cập hệ thống tệp đáng ngờ. Cùng với nhật ký cơ bản, các thành phần này cung cấp khả năng phát hiện mối đe dọa nhiều lớp cho khối lượng công việc bộ chứa của bạn.\nDưới đây là cách các thành phần này hoạt động cùng nhau trong việc phát hiện chuỗi tấn công: Khai thác bắt đầu khi EKS Protection phát hiện các nỗ lực xác thực máy chủ API Kubernetes bất thường từ một vùng chứa trong cụm. Giám sát thời gian chạy đồng thời quan sát các lệnh sai lệch so với hành vi cơ bản của bộ chứa, chẳng hạn như nỗ lực leo thang đặc quyền và lệnh gọi hệ thống trái phép. Khi quá trình khai thác diễn ra, GuardDuty đã phát hiện việc tạo tài khoản dịch vụ Kubernetes với các quyền nâng cao, sau đó là các nỗ lực gắn các đường dẫn máy chủ nhạy cảm vào các vùng chứa.\nKịch bản sau đó leo thang khi Kubernetes Pod bị xâm nhập thiết lập kết nối với các Pod khác trên các không gian tên, gợi ý chuyển động ngang. Phát hiện mối đe dọa mở rộng của GuardDuty tương quan các sự kiện này với Pod truy cập bí mật Kubernetes nhạy cảm và thông tin xác thực AWS được lưu trữ trong Kubernetes ConfigMaps. Giai đoạn cuối cùng cho thấy Pod bị xâm nhập thực hiện các lệnh gọi API AWS bằng cách sử dụng thông tin xác thực bị đánh cắp, nhắm mục tiêu các tài nguyên nằm ngoài phạm vi hoạt động bình thường của cụm.\nViệc phát hiện cuộc tấn công nhiều giai đoạn này, bao gồm khai thác vùng chứa, leo thang đặc quyền và đánh cắp thông tin đăng nhập, thể hiện sức mạnh của khả năng tương quan của Phát hiện mối đe dọa mở rộng. Các nhóm bảo mật đã nhận được một phát hiện quan trọng duy nhất ánh xạ toàn bộ trình tự khai thác với chiến thuật MITRE ATT\u0026amp;CK®, cung cấp khả năng hiển thị rõ ràng về tiến trình khai thác và các bước khắc phục cụ thể.\nCác tình huống thực tế này minh họa cách các kế hoạch bảo vệ GuardDuty hoạt động phối hợp với Phát hiện mối đe dọa mở rộng để cung cấp thông tin chuyên sâu về bảo mật. Sự kết hợp giữa các kế hoạch bảo vệ có mục tiêu và mối tương quan do AI cung cấp giúp các nhóm bảo mật xác định và ứng phó với các mối đe dọa tinh vi có thể không được chú ý hoặc khó ghép lại với nhau theo cách thủ công.\nKết thúc\nCác gói bảo vệ GuardDuty, cùng với tính năng Phát hiện mối đe dọa mở rộng tích hợp, cung cấp một bộ phát hiện được quản lý mạnh mẽ để bảo mật môi trường AWS của bạn. Bằng cách điều chỉnh chiến lược bảo mật cho phù hợp với các loại khối lượng công việc cụ thể và sử dụng thông tin chi tiết do AI cung cấp, bạn có thể nâng cao đáng kể khả năng phát hiện và ứng phó với các mối đe dọa tinh vi. Để bắt đầu với các gói bảo vệ GuardDuty và Phát hiện mối đe dọa mở rộng, hãy truy cập bảng điều khiển GuardDuty. Mỗi gói bảo vệ bao gồm bản dùng thử 30 ngày miễn phí cho mỗi tài khoản AWS và Khu vực AWS, cho phép bạn đánh giá phạm vi bảo mật cho các nhu cầu cụ thể của mình. Hãy nhớ rằng bạn có thể điều chỉnh các gói đã bật của mình bất kỳ lúc nào để phù hợp với các yêu cầu bảo mật đang phát triển và thay đổi khối lượng công việc. Bằng cách sử dụng các chức năng này, bạn có thể tăng cường khả năng phát hiện và ứng phó với mối đe dọa của tổ chức khi đối mặt với các rủi ro bảo mật ngày càng phát triển.\nNisha Amthul Nisha là Giám đốc Tiếp thị Sản phẩm Cấp cao tại AWS Security, chuyên về các giải pháp phát hiện và phản ứng sự cố. Cô có nền tảng vững chắc trong quản lý sản phẩm và tiếp thị sản phẩm trong các lĩnh vực an ninh thông tin và bảo vệ dữ liệu. Khi không làm việc, Nisha thích trang trí bánh, tập luyện sức mạnh, và chăm sóc hai đứa con năng động của mình.\nSujay Doshi Sujay là Giám đốc Sản phẩm Cấp cao tại AWS, tập trung vào các dịch vụ bảo mật. Với hơn 10 năm kinh nghiệm trong lĩnh vực quản lý sản phẩm và phát triển phần mềm, anh dẫn dắt chiến lược sản phẩm cho Amazon GuardDuty. Trước khi gia nhập AWS, Sujay từng đảm nhiệm các vị trí lãnh đạo tại nhiều công ty công nghệ khác nhau. Anh đam mê bảo mật đám mây và tự mô tả mình là “một người yêu dữ liệu với sở thích tìm kim trong đống cỏ mạng.”\nShachar Hirshberg Shachar từng là Giám đốc Sản phẩm Cấp cao cho Amazon GuardDuty với hơn một thập kỷ kinh nghiệm trong việc xây dựng, thiết kế, ra mắt và mở rộng phần mềm doanh nghiệp. Anh đam mê việc giúp khách hàng khai thác tối đa các dịch vụ AWS để thúc đẩy đổi mới và nâng cao bảo mật cho môi trường đám mây của họ. Ngoài công việc, Shachar là người đam mê du lịch và trượt tuyết.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về Amazon Bedrock và Converse API Amazon Bedrock là nền tảng AI fully managed của AWS, cung cấp nhiều mô hình ngôn ngữ lớn (LLM) như Claude, Llama, Mistral và Titan. Các mô hình này có thể được gọi trực tiếp qua API mà không cần triển khai hay quản lý hạ tầng.\nWorkshop này sử dụng Converse API, giao diện thống nhất cho các mô hình Bedrock có hỗ trợ Converse. Với Converse API:\nBạn có thể dùng chung một cấu trúc request/response cho nhiều mô hình. Việc chuyển đổi mô hình chỉ cần đổi modelId. Toàn bộ logic conversation được đơn giản hóa và nhất quán. Converse API giúp bạn dễ dàng xây dựng dịch vụ AI trên kiến trúc serverless mà không phụ thuộc vào từng mô hình cụ thể.\nTổng quan về workshop Trong workshop này, bạn sẽ triển khai một API Hỏi–Đáp AI đơn giản. Ứng dụng sẽ nhận câu hỏi từ người dùng, gửi đến mô hình Bedrock thông qua Lambda, và trả về câu trả lời dưới dạng văn bản.\nKiến trúc gồm ba thành phần chính:\nAWS Lambda – xử lý request và gọi Bedrock bằng Converse API. Amazon Bedrock Runtime – thực thi suy luận với mô hình được cấu hình. Amazon API Gateway – cung cấp HTTP endpoint để client gửi câu hỏi. Luồng hoạt động:\nNgười dùng gửi request đến API Gateway. API Gateway chuyển request đến Lambda. Lambda gửi prompt đến Bedrock qua Converse API. Bedrock thực thi suy luận và trả về kết quả. Lambda trả kết quả cho client. Sơ đồ kiến trúc workshop:\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.1-week1/1.1.1-day01-2025-09-08/","title":"Ngày 01 - Giới thiệu về Điện toán Đám mây","tags":[],"description":"","content":"Ngày: 2025-09-08 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Điện toán Đám mây là gì? Hình thức cung cấp tài nguyên CNTT theo nhu cầu thông qua Internet với mô hình trả phí theo mức sử dụng. Lợi ích của Điện toán Đám mây Chỉ trả tiền cho phần tài nguyên thực tế sử dụng, tối ưu chi phí. Tăng tốc phát triển nhờ dịch vụ quản lý và tự động hóa. Mở rộng/thu hẹp tài nguyên linh hoạt theo nhu cầu. Triển khai ứng dụng toàn cầu chỉ trong vài phút. Vì sao chọn AWS? AWS giữ vị trí dẫn đầu thị trường cloud toàn cầu 13 năm liên tiếp (tính đến 2023). Văn hóa, tầm nhìn và sự ám ảnh khách hàng rất khác biệt. Triết lý giá: khách hàng nên trả ít hơn theo thời gian cho cùng một lượng tài nguyên. Mọi Nguyên tắc Lãnh đạo của AWS đều hướng đến giá trị thực cho khách hàng. Bắt đầu với AWS như thế nào? Có nhiều lộ trình học – tự học hoàn toàn khả thi. Đăng ký tài khoản AWS Free Tier để khám phá dịch vụ. Gợi ý nền tảng khóa học: Udemy A Cloud Guru Tham khảo thêm các lộ trình chính thức của AWS: AWS Learning Paths "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.2-week2/1.2.1-day06-2025-09-15/","title":"Ngày 06 - Kiến thức Cơ bản về Amazon VPC","tags":[],"description":"","content":"Ngày: 2025-09-15 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Dịch vụ mạng trên AWS Amazon Virtual Private Cloud (VPC) Amazon VPC cho phép triển khai tài nguyên AWS vào một mạng ảo do chính bạn định nghĩa. Mỗi VPC tồn tại trong phạm vi một Region. Khi tạo VPC, cần định nghĩa dải IPv4 CIDR (bắt buộc) và có thể thêm IPv6. Giới hạn mặc định: 5 VPC mỗi Region cho mỗi tài khoản. Thường dùng để tách biệt môi trường Production, Development, Staging. Muốn cô lập hoàn toàn tài nguyên, nên dùng các AWS Account khác nhau thay vì nhiều VPC cùng tài khoản. Subnet Mỗi subnet nằm trong một Availability Zone. CIDR của subnet phải là tập con của CIDR VPC cha. AWS dành sẵn 5 địa chỉ IP trong mỗi subnet: network, broadcast, router, DNS và một địa chỉ dự phòng. Ví dụ các IP được dành trước (10.0.0.0/24):\n10.0.0.0 – Địa chỉ mạng 10.0.0.1 – Router của VPC 10.0.0.2 – Máy chủ DNS 10.0.0.3 – Dành cho sử dụng trong tương lai 10.0.0.255 – Địa chỉ broadcast Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking Basics Tạo VPC → 03-03.1 Tạo Subnet → 03-03.2 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.3-week3/1.3.1-day11-2025-09-22/","title":"Ngày 11 - Kiến thức cơ bản về Amazon EC2","tags":[],"description":"","content":"Ngày: 2025-09-22 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Compute trên AWS Amazon Elastic Compute Cloud (EC2) Amazon EC2 cung cấp năng lực tính toán có thể co giãn trên cloud, tương tự máy chủ ảo hoặc vật lý. Phù hợp cho các workload như web hosting, ứng dụng, cơ sở dữ liệu, dịch vụ xác thực và nhiều tác vụ máy chủ tổng quát khác. Instance Type\nCấu hình EC2 được xác định bởi instance type, không phải phần cứng tự chọn. Mỗi loại quy định: CPU (Intel, AMD, ARM – Graviton 1/2/3) / GPU Bộ nhớ Kết nối mạng Lưu trữ Nhóm instance tiêu biểu:\nGeneral Purpose: T3, T4g, M5, M6i (cân bằng giữa compute, memory, network). Compute Optimized: C5, C6i, C7g (hiệu năng xử lý cao). Memory Optimized: R5, R6i, X2 (tối ưu cho workload dùng nhiều RAM). Storage Optimized: I3, D2, H1 (tốc độ đọc/ghi tuần tự cao trên storage cục bộ). Accelerated Computing: P4, G5, Inf1 (GPU/FPGA cho ML, đồ họa). Amazon Machine Image (AMI) AMI (Amazon Machine Image) là mẫu chứa cấu hình phần mềm của instance, gồm hệ điều hành, ứng dụng và thiết lập. Các loại AMI: AMI do AWS cung cấp (Amazon Linux, Windows, Ubuntu, v.v.). AMI trên AWS Marketplace. AMI tùy chỉnh do người dùng tạo. Lợi ích của AMI tùy chỉnh\nLaunch và cấu hình instance nhanh hơn. Đơn giản hóa sao lưu và khôi phục. Đảm bảo môi trường nhất quán trên nhiều instance. Thành phần AMI:\nMẫu ổ đĩa gốc (OS và ứng dụng). Quyền launch. Ánh xạ thiết bị khối (block device mapping). Hands-On Labs Lab 01 – AWS Account \u0026amp; IAM Setup Tạo tài khoản AWS → 01-01 Cấu hình thiết bị MFA ảo → 01-02 Tạo nhóm Admin và người dùng Admin → 01-03 Cập nhật hỗ trợ xác thực tài khoản → 01-04 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.4-week4/1.4.1-day16-2025-09-29/","title":"Ngày 16 - Kiến thức cơ bản về Amazon S3","tags":[],"description":"","content":"Ngày: 2025-09-29 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Dịch vụ lưu trữ trên AWS Amazon Simple Storage Service (S3) Amazon S3 là dịch vụ lưu trữ đối tượng, cho phép lưu và truy xuất dữ liệu với quy mô gần như không giới hạn, độ sẵn sàng cao, bảo mật mạnh và hiệu năng tốt.\nTính năng cốt lõi của S3 Bucket và Object: Dữ liệu được lưu dưới dạng object trong bucket. Mỗi object tối đa 5 TB. Availability \u0026amp; Durability: Thiết kế đạt 99,99% availability và 99,999999999% (11 số 9) durability. Bảo mật: Nhiều lớp bảo vệ như IAM, bucket policy, ACL, mã hóa. Khả năng mở rộng: Tự động scale dung lượng và throughput mà không giảm hiệu năng. Cấu trúc object S3:\nKey: Tên/đường dẫn object. Value: Dữ liệu object. Version ID: Dùng khi bật versioning. Metadata: Metadata hệ thống và người dùng. Access Control: Quyền truy cập. S3 Access Points Access Point giúp đơn giản hóa việc quản lý truy cập cho dataset dùng chung.\nKiểm soát theo ứng dụng: Mỗi access point có policy riêng. Đơn giản vận hành: Dễ quản lý quyền cho dataset dùng chung nhiều ứng dụng. Kiểm soát mạng: Có thể cấu hình chỉ cho phép truy cập từ các VPC cụ thể. Các lớp lưu trữ S3 Chọn storage class phù hợp với mô hình truy cập và chi phí:\nS3 Standard: Dữ liệu truy cập thường xuyên; availability và hiệu năng cao nhất. S3 Intelligent-Tiering: Tự động di chuyển object giữa các tier để tối ưu chi phí. S3 Standard-IA: Dữ liệu ít truy cập, vẫn truy xuất mili-giây. S3 One Zone-IA: Tương tự Standard-IA nhưng lưu ở một AZ. S3 Glacier Flexible Retrieval: Lưu trữ chi phí thấp, truy xuất phút–giờ. S3 Glacier Deep Archive: Chi phí thấp nhất, truy xuất ~12 giờ. So sánh storage class:\nClass Độ bền Availability Lưu tối thiểu Thời gian truy xuất Standard 11 số 9 99,99% Không Tức thời Intelligent-Tiering 11 số 9 99,9% Không Tức thời Standard-IA 11 số 9 99,9% 30 ngày Tức thời One Zone-IA 11 số 9 99,5% 30 ngày Tức thời Glacier Flexible 11 số 9 99,99% 90 ngày Phút-giờ Glacier Deep Archive 11 số 9 99,99% 180 ngày 12 giờ Hands-On Labs Lab 57 – Amazon S3 \u0026amp; CloudFront (Phần 1) Tạo S3 Bucket → 57-2.1 Tải dữ liệu lên → 57-2.2 Bật Static Website → 57-3 Cấu hình Public Access Block → 57-4 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.5-week5/1.5.1-day21-2025-10-06/","title":"Ngày 21 - Shared Responsibility &amp; Kiến thức IAM cơ bản","tags":[],"description":"","content":"Ngày: 2025-10-06 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bảo mật Mô hình Trách nhiệm chia sẻ (Shared Responsibility Model) Trên môi trường cloud, bảo mật là trách nhiệm được chia sẻ giữa nhà cung cấp và khách hàng. Khách hàng cần cấu hình dịch vụ an toàn, áp dụng best practice và triển khai các kiểm soát bảo mật từ lớp hypervisor trở lên (ứng dụng/dữ liệu). Phạm vi trách nhiệm thay đổi tùy mô hình dịch vụ: Dịch vụ cấp hạ tầng Dịch vụ được quản lý một phần Dịch vụ fully-managed Trách nhiệm của AWS (Security OF the Cloud):\nBảo mật vật lý trung tâm dữ liệu. Hạ tầng phần cứng và mạng. Lớp ảo hóa. Vận hành các dịch vụ managed. Trách nhiệm của khách hàng (Security IN the Cloud):\nMã hóa dữ liệu. Cấu hình mạng. Quản lý truy cập. Bảo mật ứng dụng. Vá OS (đối với EC2). AWS Identity and Access Management (IAM) Root Account Có quyền không giới hạn với mọi dịch vụ/tài nguyên AWS và có thể gỡ mọi quyền đã cấp. Best practice: Tạo và dùng IAM Administrator cho tác vụ hằng ngày. Lưu trữ thông tin root an toàn (dual control). Duy trì email và domain của root hợp lệ, được gia hạn. Bật MFA cho tài khoản root. Tổng quan IAM IAM kiểm soát quyền truy cập dịch vụ/tài nguyên trong tài khoản. Principal bao gồm: root user, IAM user, federated user, IAM role, phiên assumed-role, dịch vụ AWS và người dùng ẩn danh. Ghi nhớ: IAM user không phải là tài khoản AWS riêng. Người dùng mới tạo không có quyền mặc định. Cấp quyền bằng cách gắn policy vào user, group hoặc role. Dùng IAM group để quản lý nhiều user (group không lồng nhau được). Hands-On Labs Lab 48 – IAM Access Keys \u0026amp; Roles (Phần 1) Tạo EC2 Instance → 48-1.1 Tạo S3 Bucket → 48-1.2 Tạo IAM User và Access Key → 48-2.1 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.6-week6/1.6.1-day26-2025-10-13/","title":"Ngày 26 - Kiến thức Cơ bản về Cơ sở dữ liệu","tags":[],"description":"","content":"Ngày: 2025-10-13 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Ôn tập khái niệm cơ sở dữ liệu Một cơ sở dữ liệu là tập hợp dữ liệu có tổ chức (hoặc bán cấu trúc) được lưu trên thiết bị lưu trữ, cho phép nhiều người dùng/chương trình truy cập đồng thời cho các mục đích khác nhau. Phiên làm việc (Session) Phiên bắt đầu khi client kết nối tới DBMS và kết thúc khi đóng kết nối. Khóa chính (Primary Key) Primary key dùng để định danh duy nhất từng dòng trong bảng quan hệ. Khóa ngoại (Foreign Key) Foreign key ở một bảng sẽ trỏ đến primary key của bảng khác để tạo quan hệ dữ liệu. Chỉ mục (Index) Index giúp truy vấn nhanh hơn nhưng phải trả giá bằng ghi chép bổ sung và dung lượng lưu trữ để duy trì cấu trúc chỉ mục. Nhờ index, hệ quản trị có thể tìm bản ghi mà không phải quét toàn bộ bảng; có thể định nghĩa trên một hoặc nhiều cột. Các loại chỉ mục phổ biến:\nB-Tree: Cây cân bằng dùng cho hầu hết tình huống. Hash: Truy vấn theo giá trị chính xác cực nhanh. Bitmap: Hợp lý với cột có số lượng giá trị ít. Full-Text: Tối ưu cho tìm kiếm văn bản. Phân vùng (Partitioning) Partitioning chia một bảng lớn thành nhiều phần nhỏ độc lập (partition) và có thể đặt trên nhiều thiết bị lưu trữ khác nhau. Lợi ích: tăng tốc truy vấn, dễ bảo trì và mở rộng. Các kiểu thông dụng: Range (ví dụ theo ngày/tháng) List Hash Composite (kết hợp nhiều tiêu chí) Ví dụ partition theo range:\n-- Partition theo năm CREATE TABLE orders ( order_id INT, order_date DATE, amount DECIMAL ) PARTITION BY RANGE (YEAR(order_date)) ( PARTITION p2023 VALUES LESS THAN (2024), PARTITION p2024 VALUES LESS THAN (2025), PARTITION p2025 VALUES LESS THAN (2026) ); Execution Plan / Query Plan Query plan mô tả cách DBMS thực thi câu lệnh SQL (đường truy cập, kiểu join, sort\u0026hellip;). Có hai dạng: Estimated plan: ước lượng trước khi chạy. Actual plan: sinh ra sau khi thực thi. Thành phần chính: table scan, index seek/scan, nested loop, hash/merge join, sort, aggregate, filter. Database Logs Database log ghi lại mọi thay đổi (INSERT/UPDATE/DELETE) và thao tác hệ thống. Thông dụng: log giao dịch, redo, undo, binary log\u0026hellip; Công dụng: khôi phục dữ liệu, đảm bảo toàn vẹn (ACID), hỗ trợ replicate, phân tích hiệu năng. Bộ đệm (Buffer) Buffer pool lưu các trang dữ liệu được đọc từ đĩa nhằm giảm I/O. Chiến lược quản lý: Thu hồi trang: LRU, FIFO, Clock\u0026hellip; Chính sách ghi: ghi ngay hay trì hoãn. Prefetching để sưởi ấm bộ đệm trước. Labs thực hành Lab 05 – Amazon RDS \u0026amp; EC2 Integration (Phần 1) Tạo VPC → 05-2.1 Tạo Security Group cho EC2 → 05-2.2 Tạo Security Group cho RDS → 05-2.3 Tạo DB Subnet Group → 05-2.4 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.7-week7/1.7.1-day31-2025-10-20/","title":"Ngày 31 - Khởi động Vertical Slice","tags":[],"description":"","content":"Ngày: 2025-10-20 (Thứ Hai)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bối cảnh dự án Ebook Demo – Vertical Slice 0 Mục tiêu: demo trọn vẹn luồng xem chi tiết sách end-to-end trước khi xây toàn bộ hệ thống. Cách tiếp cận: Vertical Slice Architecture để phát triển từng lát cắt hoàn chỉnh thay vì chia theo tầng kỹ thuật. Lợi ích: trình diễn sớm, phát hiện lỗi sớm, tạo nhịp phối hợp giữa frontend/backend. Kiến trúc slice User → Frontend → API → Database → Response → UI Mỗi slice bao gồm UI, contract API, logic backend và dữ liệu giả phục vụ demo. Có thể thay thế từng thành phần độc lập mà không ảnh hưởng toàn bộ hệ thống. Vertical Slice Architecture Nguyên tắc chính Phát triển theo flow người dùng thay vì bóc tách theo tầng. Giữ scope nhỏ để demo nhanh và nhận feedback liên tục. Xác định rõ trách nhiệm của từng slice để dễ mở rộng. Lợi ích Tăng tốc đóng gói giá trị: có thể show cho stakeholder ngay. Giảm rủi ro tích hợp vì mỗi slice tự kiểm chứng được. Cho phép nhiều slice phát triển song song. Insight chính Vertical slice là nền tảng trước khi mở rộng feature khác. Mỗi slice cần checklist rõ (UI hoàn thiện, contract chuẩn, backend trả dữ liệu đúng). Xem slice như “mini product” với vòng đời riêng giúp giữ được chất lượng. Labs thực hành Xác định phạm vi slice 0 (luồng xem chi tiết sách, dữ liệu tối thiểu). Vẽ sơ đồ dòng dữ liệu và ranh giới giữa frontend/backend. Chuẩn hóa checklist demo (contract, mock, UI, backend). "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.8-week8/1.8.1-day36-2025-10-27/","title":"Ngày 36 - Nền Tảng NLP &amp; Ứng Dụng","tags":[],"description":"","content":"Ngày: 2025-10-27 (Thứ Hai)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nXử Lý Ngôn Ngữ Tự Nhiên là gì? Xử Lý Ngôn Ngữ Tự Nhiên (NLP) là một lĩnh vực của Trí Tuệ Nhân Tạo tập trung vào việc giúp máy tính có thể hiểu, giải thích, tạo ra và tương tác với ngôn ngữ con người.\nNLP kết hợp ngôn ngữ học tính toán, học máy và học sâu để xử lý dữ liệu văn bản và lời nói quy mô lớn.\nCác Tác Vụ NLP Điển Hình: Phân loại văn bản Phân tích cảm xúc Nhận dạng thực thể (NER) Dịch máy Gắn nhãn từ loại (POS tagging) Nhận dạng giọng nói Các Thành Phần Ngôn Ngữ Cốt Lõi trong NLP Âm Vị Học – Những Âm Thanh của Lời Nói Con Người Âm Vị Học nghiên cứu các đặc tính vật lý của những âm thanh lời nói.\nBa Nhánh Chính: Âm vị học phát âm: cách những âm thanh được tạo ra (lưỡi, môi, dây thanh…) Âm vị học âm học: các đặc tính vật lý của âm thanh (tần số, biên độ, thời lượng) Âm vị học thính giác: con người cảm nhận âm thanh như thế nào Liên Quan NLP: Được sử dụng trong nhận dạng giọng nói, tổng hợp giọng nói (TTS), mô hình âm thanh.\nÂm Vị Học – Hệ Thống Âm Thanh của Ngôn Ngữ Âm Vị Học nghiên cứu cách những âm thanh hoạt động trong một ngôn ngữ cụ thể. Nó đề cập đến phonemes, mô hình nhấn mạnh, các tổ hợp âm thanh được phép.\nLiên Quan NLP: Chuyển đổi grapheme sang phoneme, mô hình phát âm.\nHình Thái Học – Cấu Trúc của Từ Hình Thái Học nghiên cứu cách những từ được hình thành từ những đơn vị nhỏ hơn gọi là morphemes.\nVí Dụ: Tiền tố: un-, re-, pre- Hậu tố: -ing, -ed, -ness Gốc/thân từ: run, happy, form Liên Quan NLP:\nStemming Lemmatization Tokenization Xây dựng từ vựng cho mô hình BoW Các Ứng Dụng NLP Công Cụ Tìm Kiếm Những tìm kiếm hàng ngày của bạn trên các công cụ tìm kiếm được tạo thuận lợi bởi NLP để hiểu truy vấn và xếp hạng kết quả.\nVí Dụ Nhận Dạng Ý Định Tìm Kiếm Khi ai đó tìm kiếm \u0026ldquo;glass coffee tables\u0026rdquo; (bàn cà phê mặt kính), công cụ nhận dạng ý định xác định rằng từ \u0026ldquo;glass\u0026rdquo; có khả năng đề cập đến giá trị của thuộc tính \u0026lsquo;Top Material\u0026rsquo; (Chất Liệu Bề Mặt) trong bàn cà phê. Sau đó, nó chỉ dẫn công cụ tìm kiếm hiển thị danh mục bàn cà phê với thuộc tính \u0026lsquo;Top Material\u0026rsquo; được đặt thành \u0026lsquo;glass\u0026rsquo;.\nQuảng Cáo Trực Tuyến NLP cho phép quảng cáo được nhắm mục tiêu bằng cách phân tích hành vi trực tuyến thông qua nhiều thành phần:\n1. Nhận Dạng Thực Thể (NER) Xác định các yếu tố thông tin được chọn gọi là Thực Thể. Do không có dữ liệu được gắn nhãn, các phương pháp bán giám sát được áp dụng để phát hiện các thực thể cụ thể cho từng trường hợp sử dụng.\n2. Trích Xuất Mối Quan Hệ Một trong những tác vụ NLP cổ điển nhằm trích xuất các mối quan hệ ngữ nghĩa từ các tài liệu văn bản không có cấu trúc hoặc bán cấu trúc.\n3. Nhận Dạng Khoảnh Khắc (MoRec) Cho phép các nhà phân tích hiểu các cuộc thảo luận trên diễn đàn trong giai đoạn khám phá kiến thức bằng cách xử lý văn bản thảo luận không có cấu trúc và trích xuất kiến thức dưới dạng sự kiện. Các sự kiện có thể được xác định và cấu hình tùy thuộc vào trường hợp sử dụng đang được điều tra.\nTrợ Lý Giọng Nói Siri, Alexa và Google Assistant sử dụng NLP để hiểu và trả lời các lệnh giọng nói của bạn.\nDịch Máy Các dịch vụ như Google Translate dựa vào NLP để chuyển đổi văn bản từ một ngôn ngữ sang ngôn ngữ khác.\nChatbot Chatbot dịch vụ khách hàng sử dụng NLP để tương tác với người dùng và cung cấp hỗ trợ.\nTóm Tắt Văn Bản Các thuật toán NLP có thể nén các bài viết dài thành những bản tóm tắt ngắn gọn.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/1.9.1-day41-2025-11-03/","title":"Ngày 41 - Vấn Đề RNN &amp; Tại Sao Cần Transformers","tags":[],"description":"","content":"Ngày: 2025-11-03 (Thứ Hai)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nVấn Đề với RNNs: Thắt Cổ Chai Xử Lý Tuần Tự RNNs đã thống trị NLP trong những năm qua, nhưng chúng có những hạn chế cơ bản mà transformers giải quyết. Hãy khám phá những vấn đề này.\nVấn Đề 1: Tính Toán Tuần Tự Cách RNNs Xử Lý Thông Tin RNNs phải xử lý đầu vào từng bước một, theo tuần tự:\nVí Dụ Dịch (Tiếng Anh → Tiếng Pháp):\nĐầu vào: \u0026#34;I am happy\u0026#34; Bước Thời Gian 1: Xử lý \u0026#34;I\u0026#34; Bước Thời Gian 2: Xử lý \u0026#34;am\u0026#34; Bước Thời Gian 3: Xử lý \u0026#34;happy\u0026#34; Tác Động:\nNếu câu của bạn có 5 từ → cần 5 bước tuần tự Nếu câu của bạn có 1000 từ → cần 1000 bước tuần tự Không thể song song hóa! Phải đợi bước t-1 trước khi tính bước t Tại Sao Điều Này Quan Trọng GPU và TPU hiện đại được thiết kế cho tính toán song song RNNs tuần tự không thể tận dụng song song hóa này Huấn luyện trở nên chậm hơn nhiều so với cần thiết Chuỗi dài hơn = thời gian huấn luyện dài hơn theo hàm mũ Vấn Đề 2: Vanishing Gradient Problem Nguyên Nhân Gốc Rễ Khi RNNs backpropagate qua nhiều time step, gradients được nhân lặp đi lặp lại:\nLuồng Gradient Qua T Bước:\n∂Loss/∂h₀ = ∂Loss/∂hₜ × (∂hₜ/∂hₜ₋₁) × (∂hₜ₋₁/∂hₜ₋₂) × ... × (∂h₁/∂h₀) Nếu mỗi ∂hᵢ/∂hᵢ₋₁ \u0026lt; 1 (điều này thường xảy ra):\nSau T phép nhân: gradient ≈ 0.5^100 ≈ 0 (với T=100) Gradient biến mất thành không Mô hình không thể học các phụ thuộc dài hạn Ví Dụ Cụ Thể Câu: \u0026ldquo;The students who studied hard\u0026hellip; passed the exam\u0026rdquo;\nTừ đầu \u0026ldquo;students\u0026rdquo; cần ảnh hưởng đến dự đoán \u0026ldquo;passed\u0026rdquo; Nhưng gradient đã biến mất khi tiếp cận \u0026ldquo;students\u0026rdquo; Mô hình không học được mối quan hệ này! Giải Pháp Hiện Tại LSTMs và GRUs giúp một chút với gates, nhưng:\nVẫn có vấn đề với chuỗi rất dài (\u0026gt;100-200 từ) Không thể hoàn toàn giải quyết vấn đề Vẫn yêu cầu xử lý tuần tự Vấn Đề 3: Thắt Cổ Chai Thông Tin Vấn Đề Nén Dữ Liệu Kiến Trúc Sequence-to-Sequence:\nEncoder: Word₁ → h₁ → h₂ → h₃ → hₜ (hidden state cuối cùng) Decoder: hₜ → Word₁\u0026#39; → Word₂\u0026#39; → Word₃\u0026#39; → ... Thắt Cổ Chai: Tất cả thông tin từ toàn bộ chuỗi đầu vào được nén vào một vector duy nhất hₜ (hidden state cuối cùng).\nTại Sao Điều Này Không Hoạt Động Ví Dụ Câu: \u0026ldquo;The government of the United States of America announced\u0026hellip;\u0026rdquo;\nKhi mã hóa câu 8 từ này:\nTừ đầu tiên \u0026ldquo;The\u0026rdquo; được xử lý Thông tin chảy qua các state: h₁ → h₂ → h₃ → \u0026hellip; → h₈ Bởi h₈, thông tin về \u0026ldquo;The\u0026rdquo; đã bị pha loãng/mất Chỉ h₈ được truyền đến decoder Decoder có thông tin ngữ cảnh hạn chế về các từ đầu Hậu Quả Chuỗi dài mất thông tin Ngữ cảnh quan trọng ở đầu bị pha loãng Mô hình gặp khó khăn với tài liệu dài Chất lượng dịch giảm cho các câu dài Tóm Tắt: Tại Sao RNNs Có Những Vấn Đề Cơ Bản Vấn Đề Tác Động Giải Pháp Hiện Tại Xử Lý Tuần Tự Không thể song song hóa, đào tạo chậm N/A - Cơ bản của thiết kế RNN Vanishing Gradients Không thể học phụ thuộc dài hạn LSTM/GRU gates (sửa chữa một phần) Thắt Cổ Chai Thông Tin Thông tin sớm bị mất Cơ chế Attention (sửa chữa một phần) Giải Pháp Transformer: \u0026ldquo;Attention is All You Need\u0026rdquo; Giới thiệu năm 2017 bởi các nhà nghiên cứu Google (Vaswani et al.), transformers hoàn toàn thay thế RNNs bằng các cơ chế attention.\nNhững Khác Biệt Chính Khía Cạnh RNNs Transformers Xử Lý Tuần tự (từng từ một lần) Song Song (tất cả từ cùng lúc) Phụ Thuộc Mỗi từ phụ thuộc vào state trước Tất cả từ attend tới tất cả từ Tốc Độ Huấn Luyện Chậm (tuần tự) Nhanh (song song) Chuỗi Dài Vanishing gradients Không thắt cổ chai tuần tự Phụ Thuộc Dài Hạn Khó khăn Dễ dàng (attention trực tiếp) Cách Transformers Hoạt Động (Tóm Tắt Ngắn) Không RNN: Loại bỏ hoàn toàn các hidden state tuần tự Attention Thuần: Để mỗi từ \u0026ldquo;attend tới\u0026rdquo; tất cả các từ khác Positional Encoding: Thêm thông tin vị trí vì chúng ta không có thứ tự tuần tự Xử Lý Song Song: Xử lý toàn bộ chuỗi cùng lúc Ví Dụ:\nCâu: \u0026#34;I am happy\u0026#34; Thay vì: Bước 1: Xử lý \u0026#34;I\u0026#34; → h₁ Bước 2: Xử lý \u0026#34;am\u0026#34; với h₁ → h₂ Bước 3: Xử lý \u0026#34;happy\u0026#34; với h₂ → h₃ Transformer Làm: Song Song: \u0026#34;I\u0026#34; attend tới {\u0026#34;I\u0026#34;, \u0026#34;am\u0026#34;, \u0026#34;happy\u0026#34;} Song Song: \u0026#34;am\u0026#34; attend tới {\u0026#34;I\u0026#34;, \u0026#34;am\u0026#34;, \u0026#34;happy\u0026#34;} Song Song: \u0026#34;happy\u0026#34; attend tới {\u0026#34;I\u0026#34;, \u0026#34;am\u0026#34;, \u0026#34;happy\u0026#34;} Tất cả cùng lúc! Tại Sao Mọi Người Nói Về Transformers Tốc Độ: Có thể huấn luyện nhanh hơn trên GPU/TPU (song parallel) Khả Năng Mở Rộng: Có thể xử lý chuỗi rất dài (không thắt cổ chai) Dài Hạn: Attention trực tiếp giải quyết các vấn đề gradient Tính Linh Hoạt: Hoạt động cho dịch, phân loại, QA, tóm tắt, chatbots\u0026hellip; Hiệu Năng: Đạt kết quả tiên tiến trên gần như mọi tác vụ NLP\nỨng Dụng của Transformers Transformers được sử dụng cho:\nDịch (Neural Machine Translation) - Chất lượng cao, nhanh Tóm Tắt Văn Bản (Abstractive \u0026amp; Extractive) Named Entity Recognition (NER) - Nhận dạng thực thể tốt hơn Hỏi Đáp - Hiểu ngữ cảnh tốt hơn Chatbots \u0026amp; Trợ Lý Thoại Phân Tích Cảm Xúc - Hiểu cảm xúc/ý kiến Tự Động Hoàn Thành - Đề xuất thông minh Phân Loại - Phân loại văn bản vào các danh mục Trí Tuệ Thị Trường - Phân tích cảm xúc thị trường Các Mô Hình Transformer Tiên Tiến Nhất GPT-2 (Generative Pre-trained Transformer) Tạo bởi: OpenAI Loại: Decoder-only transformer Chuyên môn: Tạo văn bản Nổi tiếng vì: Tạo văn bản giống con người (thậm chí đánh lừa các nhà báo năm 2019!) BERT (Bidirectional Encoder Representations from Transformers) Tạo bởi: Google AI Loại: Encoder-only transformer Chuyên môn: Hiểu văn bản \u0026amp; đại diện Sử dụng: Phân loại, NER, QA T5 (Text-to-Text Transfer Transformer) Tạo bởi: Google Loại: Full encoder-decoder (giống transformer gốc) Chuyên môn: Học đa tác vụ Rất linh hoạt: Một mô hình xử lý dịch, phân loại, QA, tóm tắt, hồi quy "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.10-week10/1.10.1-day46-2025-11-10/","title":"Ngày 46 - Nền tảng Transfer Learning","tags":[],"description":"","content":"Ngày: 2025-11-10 (Thứ Hai)\nTrạng Thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTransfer Learning: Vì sao quan trọng Huấn luyện truyền thống bắt đầu từ đầu cho mọi tác vụ. Transfer learning tái dùng mô hình đã tiền huấn luyện để hội tụ nhanh hơn, chính xác hơn và cần ít dữ liệu gán nhãn hơn.\nSo sánh quy trình Truyền thống: dữ liệu -\u0026gt; mô hình khởi tạo ngẫu nhiên -\u0026gt; train -\u0026gt; dự đoán Transfer: tiền huấn luyện trên corpora lớn -\u0026gt; tái dùng trọng số -\u0026gt; fine-tune trên tác vụ đích -\u0026gt; dự đoán [Dữ liệu lớn (không/ có nhãn)] --pre-train--\u0026gt; [Trọng số gốc] \\ fine-tune trên dữ liệu tác vụ --\u0026gt; deploy Hai cách tiếp cận Feature-based: dùng embedding đã huấn luyện như đặc trưng cố định; train head mới. Fine-tuning: cập nhật (một phần) trọng số gốc trên dữ liệu downstream. Lợi ích Hội tụ nhanh nhờ khởi động nóng. Dự đoán tốt hơn từ biểu diễn giàu ngữ cảnh. Cần ít dữ liệu gán nhãn; tận dụng tiền huấn luyện trên dữ liệu thô. Lưu ý chính Lệch miền: chọn dữ liệu tiền huấn luyện gần với miền đích nếu có thể. Quên thảm họa: dùng learning rate nhỏ hoặc đóng băng lớp đầu. Đánh giá: so sánh đóng băng vs. fine-tune toàn bộ để tránh overfit. Việc thực hành hôm nay Phác quy trình transfer cho bài QA của bạn (dữ liệu, model base, head, metric). Quyết định lớp nào đóng băng và lớp nào fine-tune. Lên plan thử nhanh: feature-based vs. fine-tune và so sánh kết quả. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.11-week11/1.11.1-day51-2025-11-17/","title":"Ngày 51 - Tổng quan Lambda Managed Instances","tags":[],"description":"","content":"Ngày: 2025-11-17 (Thứ Hai)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nVì sao dùng LMI LMI giữ trải nghiệm Lambda nhưng cho chọn họ máy EC2, tận dụng SP/RI, bỏ cold start và cho phép multi-concurrency trên mỗi instance.\nKhi nên dùng Lưu lượng cao, ổn định cần chi phí dự báo Nhu cầu compute/memory/network đặc thù Muốn áp dụng pricing EC2 cho hàm Lambda Khi ở lại Lambda mặc định Traffic đột biến, khó dự đoán Hàm ngắn, thưa cần scale-to-zero Lợi ích nhanh Giữ cách đóng gói/runtimes Lambda Không cold start, công suất ổn định Kiểm soát chi phí qua SP/RI Ghi chú từ CNS382 Instance do AWS quản lý: thấy nhưng không SSH/chỉnh Lambda lo vòng đời, patch, routing Multi-concurrency thay đổi profile giá/hiệu năng "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.12-week12/1.12.1-day56-2025-11-24/","title":"Ngày 56 - Dòng Nova &amp; Agent","tags":[],"description":"","content":"Ngày: 2025-11-24 (Thứ Hai)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nĐiểm nhấn Nova 2 Sonic: speech-to-speech đa ngôn ngữ, giữ ngữ cảnh, điều khiển giọng nói Lite: reasoning nhanh/giá rẻ với context dài Omni (preview): đa phương thức (text/image/video/speech input) xuất text/image Forge: chương trình huấn luyện frontier model tùy biến trên hạ tầng Nova Agent cho UI \u0026amp; workflow Nova Act GA: agent trình duyệt (form, search, booking) hướng tới \u0026gt;90% độ tin cậy Việc cần làm Chọn một modality Nova để pilot (speech, đa phương thức, hoặc Lite) Định bộ đánh giá (độ trễ, chất lượng, chi phí) và kiểm tra an toàn/policy Kiểm tra quota/khu vực khả dụng "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/4-eventparticipated/4.1-event1/","title":"Sự Kiện 1 - Vietnam Cloud Day 2025","tags":[],"description":"","content":"Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders Ngày \u0026amp; Giờ: Thứ Năm, 18 tháng 9 năm 2025 | 9:00 – 17:00 VNT\nĐịa Điểm: Amazon Web Services Vietnam, Tầng 36, 2 Đường Hai Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nTrạng Thái Đăng Ký: Đã Đóng\nTổng Quan Sự Kiện Vietnam Cloud Day 2025 là một hội nghị AWS quy mô lớn được thiết kế dành cho các nhà phát triển và lãnh đạo doanh nghiệp, với các bài phát biểu quan trọng từ quan chức chính phủ, lãnh đạo AWS và các nhà tiên phong trong ngành. Sự kiện làm nổi bật các dịch vụ mới nhất của AWS và các chiến lược tiên tiến cho sự phát triển AI và chuyển đổi đám mây thông qua hai track: phiên phát sóng trực tiếp và các buổi thuyết trình breakout tại chỗ.\nChương Trình Track Phát Sóng Trực Tiếp Giờ (VNT) Phiên Diễn Giả 7:35 - 9:00 Đăng Ký - 9:00 - 9:20 Khai Mạc Nhà Lãnh Đạo Chính Phủ 9:20 - 9:40 Bài Phát Biểu Chính Eric Yeo, Giám Đốc Quốc Gia, Việt Nam, Campuchia, Lào \u0026amp; Myanmar, AWS 9:40 - 10:00 Bài Phát Biểu Khách Hàng 1 Tiến Sĩ Jens Lottner, CEO, Techcombank 10:00 - 10:20 Bài Phát Biểu Khách Hàng 2 Bà Trang Phùng, CEO \u0026amp; Đồng Sáng Lập, U2U Network 10:20 - 10:50 Bài Phát Biểu AWS Jaime Valles, Phó Chủ Tịch, Giám Đốc Tổng Quát Khu Vực Châu Á Thái Bình Dương và Nhật Bản, AWS 11:00 – 11:40 Tọa Đàm: Định Hướng Cuộc Cách Mạng GenAI Điều Phối Viên: Jeff Johnson, Giám Đốc Quản Lý, ASEAN, AWS Chi Tiết Tọa Đàm: Định Hướng Cuộc Cách Mạng GenAI: Chiến Lược Lãnh Đạo Cấp Cao Cuộc trò chuyện này nghiên cứu cách các nhà lãnh đạo cấp cao có thể dẫn dắt thành công tổ chức của họ vượt qua những phát triển nhanh chóng trong AI tạo sinh. Các thành viên ban điều hành đã chia sẻ quan điểm và kinh nghiệm cá nhân của họ về:\nXây dựng văn hóa định hướng đổi mới Kết nối các dự án AI với mục tiêu kinh doanh Xử lý các chuyển đổi tổ chức đi kèm với tích hợp AI Các Thành Viên Ban:\nVũ Văn, Đồng Sáng Lập \u0026amp; CEO, ELSA Corp Nguyễn Hòa Bình, Chủ Tịch, Nexttech Group Dieter Botha, CEO, TymeX Các Track Breakout (Phiên Trực Tiếp) Track 1: Tập Trung vào AI \u0026amp; Phân Tích Giờ (VNT) Phiên Diễn Giả 13:15 - 13:30 Khai Mạc \u0026amp; Giới Thiệu Track Jun Kai Loke, Chuyên Gia AI/ML SA, AWS 13:30 - 14:00 Xây Dựng Nền Tảng Dữ Liệu Hợp Nhất trên AWS cho Khối Lượng Công Việc AI và Phân Tích Kiên Nguyễn, Kiến Trúc Sư Giải Pháp, AWS 14:00 - 14:30 Xây Dựng Tương Lai: Áp Dụng Gen AI và Lộ Trình trên AWS Jun Kai Loke, Chuyên Gia AI/ML SA, AWS; Tamelly Lim, Chuyên Gia Lưu Trữ SA, AWS 14:30 - 15:00 Vòng Đời Phát Triển Dựa trên AI (AI-DLC) - Định Hình Tương Lai của Triển Khai Phần Mềm Bình Trần, Kiến Trúc Sư Giải Pháp Cao Cấp, AWS 15:00 - 15:30 Giải Lao Uống Trà - 15:30 - 16:00 Bảo Mật Các Ứng Dụng AI Tạo Sinh với AWS: Nguyên Tắc Cơ Bản và Thực Hành Tốt Nhất Taiki Dang, Kiến Trúc Sư Giải Pháp, AWS 16:00 - 16:30 Vượt Ra Ngoài Tự Động Hóa: Các Tác Nhân AI - Bộ Nhân Năng Suất Tối Ưu của Bạn Michael Armentano, Chuyên Gia GTM Toàn Cầu Chính, AWS Chi Tiết Phiên Xây Dựng Nền Tảng Dữ Liệu Hợp Nhất trên AWS cho Khối Lượng Công Việc AI và Phân Tích\nBuổi thuyết trình này khám phá các phương pháp và thực hành được đề xuất để thiết lập nền tảng dữ liệu hợp nhất, có khả năng mở rộng trên AWS. Người tham dự đã khám phá cách sử dụng các dịch vụ AWS để phát triển hạ tầng dữ liệu vững chắc có thể đáp ứng các yêu cầu của các ứng dụng hướng dữ liệu đương đại. Các lĩnh vực chính được đề cập:\nThu thập, lưu trữ, xử lý và giám sát dữ liệu Quản lý và ứng dụng dữ liệu hiệu quả cho phân tích tinh vi và các dự án AI Xây Dựng Tương Lai: Áp Dụng Gen AI và Lộ Trình trên AWS\nAWS đã chia sẻ tầm nhìn toàn diện, các xu hướng phát triển và lộ trình chiến thuật để áp dụng các công nghệ AI Tạo Sinh (GenAI). Buổi thuyết trình đề cập đến các dịch vụ AWS thiết yếu và các chương trình được thiết kế để hỗ trợ các tổ chức khai thác GenAI nhằm thúc đẩy đổi mới và hiệu quả hoạt động.\nVòng Đời Phát Triển Dựa trên AI (AI-DLC) - Định Hình Tương Lai của Triển Khai Phần Mềm\nVòng Đời Phát Triển Dựa trên AI (AI-DLC) đại diện cho một phương pháp mang tính cách mạng, tập trung vào AI, tái định nghĩa việc triển khai phần mềm bằng cách tích hợp hoàn toàn AI như một cộng tác viên cốt lõi trong toàn bộ quy trình phát triển phần mềm. Khác với các phương pháp truyền thống bổ sung AI như một trợ lý cho các quy trình hiện có do con người dẫn dắt, AI-DLC kết hợp thực thi dựa trên AI với giám sát của con người và hợp tác nhóm linh hoạt để:\nTăng tốc đáng kể tốc độ phát triển phần mềm Nâng cao chất lượng mã Khuyến khích đổi mới Bảo Mật Các Ứng Dụng AI Tạo Sinh với AWS: Nguyên Tắc Cơ Bản và Thực Hành Tốt Nhất\nBuổi thuyết trình này điều tra các thách thức bảo mật riêng biệt ở mỗi tầng của ngăn xếp AI tạo sinh—hạ tầng, mô hình và ứng dụng. Người tham dự đã khám phá cách AWS tích hợp các tính năng bảo mật tích hợp sẵn bao gồm:\nMã hóa Khung không tin tưởng Giám sát liên tục Kiểm soát truy cập chi tiết Các tính năng này bảo vệ khối lượng công việc AI tạo sinh, duy trì quyền riêng tư và toàn vẹn dữ liệu trong suốt vòng đời AI.\nVượt Ra Ngoài Tự Động Hóa: Các Tác Nhân AI - Bộ Nhân Năng Suất Tối Ưu của Bạn\nBuổi thuyết trình này giới thiệu một sự thay đổi mô hình nơi các tác nhân AI hoạt động không chỉ như công cụ, mà như những đối tác thông minh chủ động thúc đẩy tăng trưởng kinh doanh. Các khái niệm thiết yếu được đề cập:\nCác tác nhân AI học hỏi, thích ứng và thực hiện các tác vụ phức tạp một cách độc lập Sự tiến hóa của hoạt động từ quy trình thủ công sang hiệu quả đáng chú ý Tăng trưởng năng suất theo cấp số nhân thông qua khả năng AI Track 2: Tập Trung vào Di Chuyển Đám Mây \u0026amp; Hiện Đại Hóa Giờ (VNT) Phiên Diễn Giả 13:15 - 13:30 Khai Mạc \u0026amp; Giới Thiệu Track Hùng Nguyễn Gia, Trưởng Kiến Trúc Sư Giải Pháp, AWS 13:30 - 14:00 Hoàn Thành Di Chuyển và Hiện Đại Hóa Quy Mô Lớn với AWS Sơn Đỗ, Quản Lý Tài Khoản Kỹ Thuật, AWS; Nguyễn Văn Hải, Giám Đốc Kỹ Thuật Phần Mềm, Techcombank 14:00 - 14:30 Hiện Đại Hóa Ứng Dụng với Công Cụ Được Hỗ Trợ bởi AI Tạo Sinh Phúc Nguyễn, Kiến Trúc Sư Giải Pháp, AWS; Alex Trần, Giám Đốc AI, OCB 14:30 - 15:00 Tọa Đàm: Hiện Đại Hóa Ứng Dụng - Đẩy Nhanh Chuyển Đổi Kinh Doanh Điều Phối Viên: Hùng Nguyễn Gia, Trưởng Kiến Trúc Sư Giải Pháp, AWS 15:00 - 15:30 Giải Lao - 15:30 - 16:00 Chuyển Đổi VMware với Hiện Đại Hóa Đám Mây Dựa trên AI Hùng Hoàng, Quản Lý Giải Pháp Khách Hàng, AWS 16:00 - 16:30 Bảo Mật AWS Ở Quy Mô: Từ Phát Triển đến Sản Xuất Taiki Dang, Kiến Trúc Sư Giải Pháp, AWS Chi Tiết Phiên Hoàn Thành Di Chuyển và Hiện Đại Hóa Quy Mô Lớn với AWS\nBuổi thuyết trình này tập trung vào các bài học quan trọng từ nhiều doanh nghiệp đã di chuyển và hiện đại hóa khối lượng công việc tại chỗ của họ bằng AWS. Các chủ đề được đề cập:\nCác khung khái niệm đã được xác thực và thực hành kỹ thuật được đề xuất Các phương pháp hiện đại hóa hỗ trợ các tổ chức nâng cấp trong khi di chuyển Các bộ tăng tốc di chuyển AWS và các công cụ di chuyển và hiện đại hóa hiện tại Nghiên cứu tình huống minh họa cách các tổ chức đã xây dựng nền tảng vững chắc và lộ trình chiến thuật sử dụng các khả năng đám mây AWS để đạt được các mục tiêu chuyển đổi số Hiện Đại Hóa Ứng Dụng với Công Cụ Được Hỗ Trợ bởi AI Tạo Sinh\nBuổi thuyết trình này xem xét cách Amazon Q Developer cách mạng hóa vòng đời phát triển phần mềm (SDLC) thông qua các khả năng tự chủ của nó trên:\nAWS Console IDE CLI Các nền tảng DevSecOps Các tính năng chính được trình diễn:\nCác tác nhân của Q đẩy nhanh tốc độ tạo mã và nâng cao chất lượng mã Tích hợp mượt mà với các quy trình làm việc hiện tại Tạo tự động tài liệu chi tiết và bài kiểm tra đơn vị Tăng cường khả năng bảo trì mã và độ tin cậy Hiểu các cơ sở mã phức tạp và đề xuất tối ưu hóa Tự động hóa các tác vụ lặp lại trong suốt vòng đời phát triển Tọa Đàm: Hiện Đại Hóa Ứng Dụng - Đẩy Nhanh Chuyển Đổi Kinh Doanh\nCác Thành Viên Ban:\nNguyễn Minh Ngân, Chuyên Gia AI, OCB Nguyễn Mạnh Tuyền, Trưởng Ứng Dụng Dữ Liệu, LPBank Securities Vinh Nguyễn, Đồng Sáng Lập \u0026amp; CTO, Ninety Eight Chuyển Đổi VMware với Hiện Đại Hóa Đám Mây Dựa trên AI\nBuổi thuyết trình này minh họa cách các tổ chức Việt Nam đang đẩy nhanh việc áp dụng đám mây với các môi trường VMware. Các chủ đề chính:\nCách AWS Transform hỗ trợ di chuyển nhanh, an toàn và hiệu quả về chi phí Hướng dẫn từng bước và các mô hình nhận thức về thời gian chết Lộ trình để hiện đại hóa lên EKS, RDS và serverless sau khi triển khai ban đầu Lý tưởng cho các nhà lãnh đạo CNTT, kiến trúc sư và các nhóm vận hành chuẩn bị cho các chuyển đổi VMware-to-AWS quy mô lớn Bảo Mật AWS Ở Quy Mô: Từ Phát Triển đến Sản Xuất\nBuổi thuyết trình này xem xét cách tăng cường tư thế bảo mật đám mây trong suốt vòng đời phát triển và sản xuất hoàn chỉnh. Các chủ đề được đề cập:\nPhương pháp bảo mật toàn diện của AWS: xác định, phòng ngừa, phát hiện, phản ứng và khắc phục Các nguyên tắc bảo mật theo thiết kế được tích hợp trong suốt quá trình phát triển Các khả năng phát hiện và phản ứng nâng cao Cách AI tạo sinh cải thiện phân tích bảo mật và tự động hóa hoạt động Phát triển các kiến trúc có khả năng phục hồi tiến hóa theo các mối đe dọa mới nổi Xây dựng các môi trường đám mây an toàn hơn, có khả năng mở rộng Những Điểm Chính Rút Ra Hiểu biết toàn diện về phương pháp AI và hiện đại hóa đám mây của AWS Những hiểu biết thực tế về áp dụng AI cấp doanh nghiệp và triển khai Các thực hành được đề xuất cho nền tảng dữ liệu, bảo mật và hiện đại hóa ứng dụng Các nghiên cứu tình huống thực tế và bài học từ các lãnh đạo ngành Kiến thức thực hành về các dịch vụ AWS cho GenAI, di chuyển và hiện đại hóa "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.4-api-gateway-integration/5.4.1-create-http-api/","title":"Tạo HTTP API","tags":[],"description":"","content":"Tạo HTTP API Trong bước này, bạn sẽ tạo một HTTP API dùng làm endpoint để client gửi câu hỏi đến Lambda.\n🔹 Bước 1 — Vào trang API Gateway và nhấn Create API Mở Amazon API Gateway Console và chọn Create API.\n🔹 Bước 2 — Chọn Build của HTTP API Chọn:\nBuild → HTTP API\n🔹 Bước 3 — Đổi tên API Đặt tên API:\nAPI name: bedrock-chatbot-api Nhấn Next, sau đó Create để tạo API.\n🎯 Kết quả Bạn đã tạo thành công một HTTP API và sẵn sàng gắn nó với Lambda ở bước tiếp theo.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.1-create-lambda/","title":"Tạo Lambda Function","tags":[],"description":"","content":"Tạo Lambda Function Trong bước này, bạn sẽ tạo một hàm AWS Lambda mới dùng để xử lý yêu cầu từ client và gửi prompt đến Amazon Bedrock thông qua Converse API.\n🔹 Bước 1 — Mở giao diện tạo Lambda Vào AWS Lambda Console Chọn Functions Chọn Create function 🔹 Bước 2 — Đặt tên và chọn cấu hình cho Lambda Trong phần cấu hình:\nFunction name: bedrock-chatbot-lambda Runtime: Python 3.12 (phiên bản ổn định và được khuyến nghị cho workshop) Architecture: x86_64 hoặc arm64 (cả hai đều hỗ trợ) Permissions → Use an existing role Chọn role bạn đã tạo ở phần Prerequisites, ví dụ:\nlambda-bedrock-role Sau đó bấm Create function để tạo Lambda.\n🎯 Kết quả mong đợi Bạn sẽ có một Lambda Function rỗng nhưng đã:\nSẵn sàng để thêm mã gọi Converse API Có Execution Role với quyền Bedrock + quyền ghi log CloudWatch Có thể được test trực tiếp trong Lambda Console Ở phần tiếp theo, bạn sẽ cấu hình chi tiết IAM Role và chuẩn bị mã nguồn cho việc gọi mô hình.\nTiếp tục xem phần 5.3.2 – Thêm code gọi Converse API.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.1-week1/","title":"Tuần 1 - Kiến thức Nền tảng Cloud Computing","tags":[],"description":"","content":"Tuần: 2025-09-08 đến 2025-09-12\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 1 Tuần này tập trung củng cố những khái niệm cơ bản về Cloud Computing, hạ tầng AWS và các công cụ quản trị.\nNội dung chính Giới thiệu Cloud Computing và lợi ích. AWS Global Infrastructure (Region, AZ, Edge Location). Bộ công cụ quản lý AWS (Console, CLI, SDK). Chiến lược tối ưu chi phí. AWS Well-Architected Framework. Labs thực hành Lab 01: Thiết lập tài khoản AWS \u0026amp; IAM. Lab 07: AWS Budgets \u0026amp; Cost Management. Lab 09: AWS Support Plans. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Worklog Tổng quan Đây là nhật ký học tập ghi lại hành trình học AWS bắt đầu từ ngày 8/9/2025.\nCấu trúc Worklog được tổ chức theo tuần, mỗi tuần gồm 5 ngày làm việc (Thứ Hai đến Thứ Sáu).\nNội dung chính Nền tảng Điện toán Đám mây\nKiến thức cơ bản về AWS, hạ tầng toàn cầu, công cụ quản lý Tối ưu chi phí, các gói hỗ trợ Bộ khung Well-Architected Framework Mạng (Networking)\nVPC, subnet, security group, NACL Cân bằng tải (ALB, NLB, GWLB) VPC Peering, Transit Gateway VPN, Direct Connect Tính toán (Compute)\nEC2, AMI, EBS, Instance Store Auto Scaling, mô hình định giá Lightsail, EFS, FSx Lưu trữ (Storage)\nS3, các lớp lưu trữ, Glacier Snow Family, Storage Gateway Khôi phục thảm họa, AWS Backup Bảo mật \u0026amp; Danh tính (Security \u0026amp; Identity)\nIAM, Cognito, Organizations KMS, Security Hub Identity Center (SSO) Cơ sở dữ liệu (Database)\nRDS, Aurora, Redshift ElastiCache, DMS Thực hành tốt trong quản lý cơ sở dữ liệu Chủ đề Nâng cao (Advanced Topics)\nServerless (Lambda) Containers (ECS, EKS, ECR) Giám sát hệ thống (CloudWatch, X-Ray, CloudTrail) "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"FitAI Challenge Ứng dụng hỗ trợ người dùng giảm cân dựa trên các thử thách về bài tập thể dục, tích hợp AI để theo dõi, đánh giá 1. Tóm tắt điều hành FitAI Challenge là website được phát triển dành cho người Việt Nam, nhằm thúc đẩy phong trào tập luyện thể dục thể hình thông qua các thử thách thể thao có yếu tố gamification và trí tuệ nhân tạo (AI). Website sử dụng AI Camera để nhận diện và đếm động tác tập luyện như push-up, squat, plank, jumping jack,\u0026hellip; đồng thời phân tích tư thế nhằm đưa ra đánh giá chính xác. Người dùng có thể tham gia thử thách cá nhân để nhận điểm thưởng FitPoints khi hoàn thành nhiệm vụ, và quy đổi chúng thành voucher, quà tặng, hoặc ưu đãi từ các đối tác thương mại. FitAI Challenge hướng đến đối tượng sinh viên, giới trẻ, và người đi làm - những người cần động lực duy trì thói quen tập luyện trong cuộc sống bận rộn.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nTại Việt Nam, các ứng dụng tập luyện hiện có phần lớn tập trung vào hướng dẫn hoặc đếm bước cơ bản, chưa có nền tảng nào kết hợp giữa AI nhận diện động tác, gamification và cộng đồng thử thách thể thao online. Người dùng thường thiếu động lực để tập đều đặn, không có công cụ đánh giá chính xác hiệu suất tập luyện. Ngoài ra, các phòng gym hoặc thương hiệu thể thao cũng thiếu kênh tương tác sáng tạo với nhóm khách hàng trẻ năng động.\nGiải pháp\nFitAI Challenge sử dụng AI Camera để nhận diện, đếm và đánh giá độ chính xác của động tác tập luyện thông qua Computer Vision. Toàn bộ dữ liệu tập luyện của người dùng được lưu trữ và xử lý qua AWS Cloud với kiến trúc serverless:\nAWS Lambda: xử lý dữ liệu AI và yêu cầu backend. AWS S3: lưu trữ video, hình ảnh, và kết quả tạm thời. Website được phát triển bằng React Native với giao diện thân thiện, trực quan. Người dùng có thể: Tham gia thử thách cá nhân, nhóm hoặc toàn quốc. Nhận FitPoints khi hoàn thành bài tập. Đổi FitPoints lấy voucher hoặc quà từ đối tác (Shopee, Grab, CGV,…). Theo dõi bảng xếp hạng và chia sẻ thành tích lên mạng xã hội.\nLợi ích và hoàn vốn đầu tư (ROI)\nĐối với người dùng: Tạo động lực luyện tập mỗi ngày thông qua cơ chế thử thách và phần thưởng. Được AI hỗ trợ đánh giá và ghi nhận thành tích minh bạch. Gắn kết cộng đồng tập luyện thông qua leaderboard và feed chia sẻ. Đối với doanh nghiệp đối tác: Kênh quảng bá thương hiệu gắn liền với lối sống lành mạnh. Tiếp cận tệp khách hàng trẻ – năng động – có ý thức về sức khỏe. Đối với đội ngũ phát triển: Mở ra mô hình kinh doanh “Fitness + Gamification + Thương mại điện tử” độc đáo tại Việt Nam. Cấu trúc cloud serverless giúp giảm chi phí vận hành và dễ mở rộng. MVP có thể phát triển trong 3 tháng đầu, với chi phí hạ tầng thấp (ước tính 0,80 USD/tháng trên AWS).\n3. Kiến trúc giải pháp FitAI Challenge là nền tảng huấn luyện thể thao thông minh áp dụng kiến trúc AWS Serverless kết hợp AI/ML pipeline trong một Private VPC.\nMục tiêu của hệ thống là:\nGhi nhận dữ liệu luyện tập (video, ảnh, thông số).\nPhân tích hiệu suất và tư thế bài tập.\nSinh phản hồi tự động bằng AI để huấn luyện người dùng một cách cá nhân hóa.\nDữ liệu từ ứng dụng web được gửi đến Amazon API Gateway, xử lý bởi AWS Lambda (Java) bên trong Private Subnet, lưu trữ trong Amazon RDS MySQL và Amazon S3.\nCác tác vụ phân tích AI được điều phối qua AWS Step Functions và Amazon SQS, gọi Amazon Bedrock thông qua Interface Endpoint. Kiến trúc bám sát sơ đồ mới của nhóm:\nDịch vụ AWS sử dụng:\nDịch vụ Vai trò Amazon Route 53 Quản lý tên miền và định tuyến lưu lượng đến CloudFront. AWS WAF Bảo vệ tầng frontend và API khỏi các tấn công phổ biến (DDoS, OWASP Top 10). Amazon CloudFront Phân phối nội dung tĩnh (web app build từ React/Next.js, HTML, CSS, JS) với độ trễ thấp. Amazon S3 Lưu trữ web tĩnh, video/ảnh bài tập, kết quả phân tích AI. Amazon API Gateway Tiếp nhận yêu cầu từ frontend và chuyển tiếp đến các Lambda backend. Amazon Cognito Xác thực người dùng, quản lý phiên đăng nhập và phân quyền. AWS Lambda (Java) Xử lý logic nghiệp vụ (đăng ký, đăng nhập, upload dữ liệu, scoring, kích hoạt AI pipeline). Amazon RDS MySQL Cơ sở dữ liệu quan hệ chính, lưu người dùng, thử thách, lịch sử luyện tập, FitPoints. VPC Gateway Endpoint (S3) Cho phép Lambda trong Private Subnet truy cập S3 nội bộ mà không ra Internet công cộng. Interface Endpoint (Bedrock) Kết nối riêng (PrivateLink) từ VPC đến Amazon Bedrock để gọi mô hình AI một cách bảo mật. Amazon SQS Hàng đợi lưu trữ nhiệm vụ phân tích AI từ Lambda. AWS Step Functions Điều phối workflow xử lý AI: trích xuất frame, phân tích, chấm điểm, gọi Bedrock. Amazon Bedrock Sinh phản hồi bằng ngôn ngữ tự nhiên: nhận xét tư thế, gợi ý cải thiện, tổng kết kết quả. Amazon SES Gửi email xác thực tài khoản, thông báo kết quả thử thách và tổng kết tuần/tháng. Amazon CloudWatch Theo dõi log, giám sát Lambda, API Gateway, chi phí và hiệu suất hệ thống. AWS IAM Quản lý quyền truy cập và bảo mật giữa các dịch vụ. AWS CodeCommit / CodeBuild / CodeDeploy / CodePipeline Thiết lập CI/CD để tự động build, test và deploy backend, frontend và Lambda. Thiết kế thành phần\nFrontend Layer:\nWeb app hiển thị giao diện người dùng (React/Next.js), kết nối đến API Gateway.\nNội dung được build và deploy lên S3, phân phối qua CloudFront.\nNgười dùng truy cập qua Route 53 → WAF → CloudFront → API Gateway.\nApplication Layer:\nAPI Gateway tiếp nhận yêu cầu từ frontend.\nLambda (Java) thực thi các chức năng nghiệp vụ chính:\nAuthLambda: đăng nhập / xác thực người dùng qua Cognito.\nUploadLambda: nhận metadata và thông tin file/video bài tập.\nAIPipelineLambda: gửi nhiệm vụ phân tích vào SQS và kích hoạt Step Functions.\nSaveResultLambda: ghi kết quả luyện tập và phản hồi AI vào RDS + S3.\nData \u0026amp; AI Layer:\nRDS MySQL lưu dữ liệu cấu trúc: tài khoản, lịch sử bài tập, FitPoints, leaderboard.\nS3 lưu trữ video/ảnh thô và kết quả phân tích.\nSQS + Step Functions điều phối pipeline AI.\nBedrock sinh phản hồi thông minh cho từng phiên luyện tập.\n4. Triển khai kỹ thuật Các giai đoạn triển khai\nGiai đoạn Mô tả Kết quả đạt được 1. Cấu hình hạ tầng AWS Triển khai VPC, Private Subnet, Route 53, WAF, S3, API Gateway, Lambda, Cognito, RDS MySQL, các VPC Endpoint (S3, Bedrock). Hạ tầng cơ bản sẵn sàng, bảo mật và tách biệt mạng. 2. CI/CD Pipeline Thiết lập CodeCommit + CodeBuild + CodeDeploy + CodePipeline cho backend Java và Lambda, build \u0026amp; deploy web lên S3/CloudFront. Tự động hóa triển khai backend và frontend. 3. Xây dựng Lambda Functions (Java) Tạo các Lambda cho Auth, Upload, AI Pipeline, Save Result; kết nối RDS MySQL và S3. Hoàn thiện backend serverless. 4. AI Pipeline Kết nối SQS, Step Functions, Bedrock; xây dựng workflow: nhận nhiệm vụ → phân tích dữ liệu → chấm điểm → sinh phản hồi AI. AI hoạt động trơn tru, phản hồi tự động cho người dùng. 5. Triển khai Web App Build web app → Deploy lên S3 + CloudFront → cấu hình domain với Route 53. Giao diện người dùng hoạt động online ổn định. 6. Giám sát \u0026amp; Tối ưu chi phí Dùng CloudWatch + Cost Explorer để theo dõi log, hiệu suất, chi phí; tinh chỉnh cấu hình Lambda, RDS, CloudFront. Hệ thống ổn định, chi phí thấp và được giám sát chặt chẽ. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0):\nThiết kế kiến trúc chi tiết dựa trên sơ đồ mới.\nThử nghiệm pipeline AI đơn giản với Bedrock (text feedback).\nThực tập (Tháng 1–3):\nTháng 1:\nThiết lập hạ tầng: VPC, Subnet, RDS MySQL, Cognito, API Gateway, Lambda, S3, CloudFront.\nCấu hình CI/CD (CodeCommit, CodeBuild, CodeDeploy, CodePipeline).\nTháng 2:\nPhát triển Java backend, Lambda functions.\nXây dựng AI pipeline với SQS, Step Functions, Bedrock.\nTháng 3:\nTích hợp frontend với backend.\nKiểm thử hiệu suất, chạy thử với 10–20 người dùng, chuẩn bị demo cuối kỳ.\nSau triển khai:\nTiếp tục tối ưu mô hình AI, bổ sung tính năng gamification trong vòng 1 năm.\n6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator hoặc tải tệp ước tính ngân sách đính kèm.\nChi phí hạ tầng (ước tính giai đoạn MVP)\nDịch vụ AWS: Amazon API Gateway: 0,38 USD / tháng (≈300 requests/tháng, 1 KB/request). Amazon Bedrock: 0,32 USD / tháng (1 req/phút, 350 input tokens, 70 output tokens). Amazon CloudFront: 1,20 USD / tháng (5 GB transfer, 500 000 HTTPS requests). Amazon CloudWatch: 1,85 USD / tháng (5 metrics, 0,5 GB logs). Amazon Cognito: 0,00 USD / tháng (≤100 MAU). Amazon Route 53: 0,51 USD / tháng (1 hosted zone). Amazon S3: 0,04 USD / tháng (1 GB storage, 1000 PUT/POST/LIST, 20 000 GET). Amazon SES: 0,30 USD / tháng (3 000 emails from EC2/Lambda). Amazon Simple Queue Service (SQS): ≈0,00 USD / tháng (0,005 triệu requests/tháng). AWS Lambda: 0,00 USD / tháng (≈300 000 requests/tháng, 512 MB ephemeral storage). AWS Step Functions: 0,00 USD / tháng (500 workflows, 5 state transitions/workflow). AWS Web Application Firewall (WAF): 6,12 USD / tháng (1 Web ACL, 1 rule). Amazon RDS MySQL (chế độ auto-stop): 0–3 USD / tháng (tùy thời gian hoạt động). Tổng: khoảng 10,7 – 12 USD / tháng tùy mức sử dụng RDS; tương đương 128 – 144 USD / 12 tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nKỹ thuật: AI nhận diện sai động tác hoặc lỗi xử lý dữ liệu ảnh/video; cấu hình VPC/Endpoint sai gây gián đoạn dịch vụ. Người dùng: Không duy trì thói quen luyện tập, tỷ lệ quay lại thấp. Thị trường \u0026amp; Đối tác: Khó mở rộng mạng lưới đối tác thưởng và thương hiệu đồng hành; thay đổi chính sách từ đối tác. Chi phí: Tăng chi phí bất ngờ khi lượng người dùng tăng đột biến (CloudFront, Bedrock). Chiến lược giảm thiểu\nTối ưu mô hình AI qua huấn luyện liên tục, theo dõi chất lượng qua log; thêm bước kiểm tra cơ bản trước khi chấm điểm. Triển khai gamification sâu hơn (chuỗi streak, nhóm bạn, thử thách theo mùa, phần thưởng hấp dẫn). Chuẩn bị đề xuất giá trị rõ ràng cho đối tác, đa dạng hóa nhóm đối tác (thể thao, đồ ăn healthy, giải trí). Thiết lập AWS Budget + Alarm cho từng dịch vụ (CloudFront, Bedrock, Lambda, RDS). Kế hoạch dự phòng\nKhi AI gặp lỗi → sử dụng fallback logic (chấm điểm đơn giản dựa trên thời gian/rep) và thông báo rõ cho người dùng. Khi lượng người dùng giảm → tung thử thách cộng đồng theo mùa, kết hợp chiến dịch social media. Khi đối tác thương mại rút lui → duy trì cơ chế FitPoints nội bộ đổi quà nhỏ (voucher nội bộ, huy hiệu trong app) trong khi tìm đối tác mới. 8. Kết quả kỳ vọng Cải tiến kỹ thuật:\nHoàn thiện hệ thống AI nhận diện động tác có độ chính xác \u0026gt; 90%. Ứng dụng ổn định, đáp ứng tới 10.000 người dùng hoạt động đồng thời trên kiến trúc serverless. Tối ưu kiến trúc giúp chi phí hạ tầng duy trì khoảng 10–12 USD/tháng ở giai đoạn đầu. Giá trị dài hạn:\nXây dựng cộng đồng người Việt yêu thích thể thao và sức khỏe bền vững, gắn kết qua các thử thách online. Trở thành nền tảng tiên phong \u0026ldquo;AI + Fitness + Gamification\u0026rdquo; tại Việt Nam. Tạo nền tảng dữ liệu luyện tập để mở rộng sang các bài toán phân tích sức khỏe, gợi ý chương trình tập cá nhân hóa và các dự án AI trong tương lai. 9. Tài liệu đính kèm Tài liệu đề xuất đầy đủ:\nFitAI Challenge Proposal (Bản tiếng Anh) FitAI Challenge Proposal (Bản tiếng Việt) "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.2-prerequisite/","title":"Chuẩn bị","tags":[],"description":"","content":"Các bước chuẩn bị trước khi bắt đầu Trước khi triển khai API AI bằng Lambda + Bedrock, bạn cần thiết lập một số tài nguyên và quyền truy cập trong AWS.\n1. Chọn AWS Region hỗ trợ Bedrock Amazon Bedrock hiện hỗ trợ tại nhiều region khác nhau.\nTrong workshop này, bạn có thể sử dụng:\nus-east-1 (N. Virginia) – region thường dùng trong tài liệu AWS ap-southeast-1 (Singapore) – cũng hỗ trợ Bedrock và có thể sử dụng bình thường Chỉ cần đảm bảo mô hình AI bạn định dùng (Claude, Llama, Mistral…) có mặt tại region đó.\n2. Tạo IAM Role cho Lambda Lambda cần một IAM Role để có quyền gọi mô hình Bedrock và ghi log.\nTrong phần này, bạn sẽ tạo policy trước, sau đó tạo role và gắn policy vào.\n🔹 Bước 1 — Tạo Policy mới Mở IAM Console → Policies → Create policy Ở bước \u0026ldquo;Specify permissions\u0026rdquo;, bấm chọn tab JSON →\nXóa toàn bộ nội dung cũ và thay bằng đoạn JSON sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;bedrock:InvokeModel\u0026#34;, \u0026#34;bedrock:InvokeModelWithResponseStream\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Chọn Next, đặt tên cho policy mới (ví dụ: lambda-bedrock) và bấm Create policy 🔹 Bước 2 — Tạo Role và gắn policy vừa tạo Quay lại IAM Console → Roles → Create role Chọn: Trusted entity type: AWS service Use case: Lambda Ở bước \u0026ldquo;Add permissions\u0026rdquo;, tìm policy bạn vừa tạo (lambda-bedrock) và tick chọn nó Đặt tên cho role, ví dụ: lambda-bedrock-role Sau đó bấm Create role\nVậy là bạn đã hoàn tất tạo IAM Role với quyền tối thiểu để Lambda có thể gọi Amazon Bedrock và ghi log CloudWatch.\n3. Kiểm tra mô hình với Bedrock Playground Trước khi viết mã gọi Converse API, bạn sẽ kiểm thử nhanh mô hình trong AWS Console.\n🔹 Bước 1 — Mở Model Catalog Mở Amazon Bedrock → Model catalog 🔹 Bước 2 — Chọn mô hình và mở Playground Chọn mô hình như Claude 3.5 Sonnet, Llama 3.1, hoặc Mistral 24.07 Bấm Open in playground để mở giao diện thử nghiệm mô hình 🔹 Bước 3 — Gửi thử một câu hỏi Nhập thử một câu hỏi để xác nhận rằng mô hình hoạt động bình thường trong region bạn đã chọn.\n🔹 Bước 4 — (Tuỳ chọn) Kiểm tra mô hình có hỗ trợ Converse API hay không Nếu bạn muốn kiểm tra mô hình có hỗ trợ Converse API, làm theo bước sau:\nTrở lại trang mô hình trong Model Catalog Cuộn xuống phần Code examples AWS sẽ mở một tab mới hiển thị ví dụ code. Nếu mô hình hỗ trợ Converse API, bạn sẽ thấy ví dụ có chứa lệnh:\nbedrock.converse(...) Như hình minh họa:\nNhư vậy là bạn đã kiểm tra xong khả năng hoạt động và hỗ trợ Converse API của mô hình trước khi bắt đầu tích hợp vào Lambda.\n4. Kiến thức cần có (không bắt buộc nhưng hữu ích) Hiểu cơ bản về AWS Lambda Biết cách tạo API Gateway dạng HTTP API Biết cách đọc log trong CloudWatch Workshop này vẫn phù hợp cho người mới, nên không yêu cầu kiến thức sâu.\nỞ bước tiếp theo, bạn sẽ tạo Lambda Function và viết đoạn mã đầu tiên để gọi Converse API của Bedrock.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.4-api-gateway-integration/5.4.2-integrate-lambda/","title":"Gắn API với Lambda","tags":[],"description":"","content":"Gắn API với Lambda Trong bước này, bạn sẽ cấu hình HTTP API để chuyển các request từ client đến Lambda Function.\nAPI Gateway sẽ đóng vai trò là lớp giao tiếp HTTP cho dịch vụ chatbot sử dụng Bedrock của bạn.\n🔹 Bước 1 — Mở API vừa tạo Vào API Gateway Console và chọn API:\nbedrock-chatbot-api\n🔹 Bước 2 — Tạo route Chọn mục Routes Nhấn Create Cấu hình: Method: POST Resource path: /chat Nhấn Create để tạo route.\n🔹 Bước 3 — Thêm Integration với Lambda Nhấn vào route vừa tạo /chat Ở phần Integration, chọn Attach integration Chọn Create and attach an integration: Integration type: Lambda function Region: Region bạn đang sử dụng Lambda function: lambda-bedrock-function (Tên lambda bạn mới tạo) Nhấn Create.\n🎯 Kết quả mong đợi Bạn đã:\nTạo route /chat Gắn route này với Lambda Function Deploy API và có endpoint HTTP sẵn sàng để test "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.1-week1/1.1.2-day02-2025-09-09/","title":"Ngày 02 - Hạ tầng Toàn cầu của AWS","tags":[],"description":"","content":"Ngày: 2025-09-09 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Hạ tầng AWS Trung tâm dữ liệu (Data Center) Mỗi trung tâm dữ liệu có thể chứa hàng chục nghìn máy chủ. AWS tự thiết kế và vận hành phần cứng riêng để tối ưu hiệu năng và độ tin cậy. Vùng khả dụng (Availability Zone - AZ) Một hoặc nhiều trung tâm dữ liệu tách biệt vật lý trong cùng một Region. Mỗi AZ được thiết kế cách ly lỗi. Kết nối với nhau bằng mạng riêng độ trễ thấp, băng thông cao. AWS khuyến nghị triển khai workload tối thiểu trên hai AZ. Region Mỗi Region chứa ít nhất ba AZ. Hiện có hơn 25 Region trên toàn thế giới. Các Region kết nối với nhau qua mạng backbone của AWS. Phần lớn dịch vụ mặc định ở phạm vi Region. Edge Location Mạng lưới edge toàn cầu giúp phân phối nội dung với độ trễ tối thiểu. Được sử dụng bởi các dịch vụ như: Amazon CloudFront (CDN) AWS WAF (Tường lửa ứng dụng web) Amazon Route 53 (Dịch vụ DNS) Hands-On Labs Lab 01 – Thiết lập Tài khoản AWS \u0026amp; IAM Tạo tài khoản AWS → 01-01 Cấu hình thiết bị MFA ảo → 01-02 Tạo nhóm Admin và người dùng Admin → 01-03 Cập nhật thông tin hỗ trợ xác thực tài khoản → 01-04 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.2-week2/1.2.2-day07-2025-09-16/","title":"Ngày 07 - Định tuyến VPC &amp; Network Interface","tags":[],"description":"","content":"Ngày: 2025-09-16 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Định tuyến VPC \u0026amp; ENI Route Table Route table xác định cách điều hướng lưu lượng mạng. Mỗi VPC có một route table mặc định chỉ chứa tuyến local để các subnet giao tiếp nội bộ. Có thể tạo thêm route table tùy chỉnh, nhưng tuyến local không thể xóa. Elastic Network Interface (ENI) ENI là card mạng ảo có thể gắn sang các EC2 instance khác nhau. Khi chuyển ENI, địa chỉ IP riêng, EIP và MAC được giữ nguyên. Elastic IP (EIP) là địa chỉ IPv4 công cộng tĩnh có thể gắn vào ENI. Bị tính phí nếu EIP không gắn cho tài nguyên nào. Tình huống sử dụng ENI:\nTách mạng quản trị khỏi mạng dữ liệu. Xây dựng thiết bị mạng/bảo mật (appliance). Instance hai cổng mạng chạy workload ở các subnet khác nhau. Giải pháp high availability chi phí thấp. VPC Endpoint VPC Endpoint cho phép kết nối riêng tư tới dịch vụ AWS qua AWS PrivateLink mà không đi Internet công cộng. Hai loại endpoint: Interface Endpoint: Tạo một ENI với IP riêng. Gateway Endpoint: Sử dụng route table (chỉ dành cho S3 và DynamoDB). Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking (tiếp tục) Tạo Internet Gateway (IGW) → 03-03.3 Tạo Route Table (Outbound qua IGW) → 03-03.4 Tạo Security Group → 03-03.5 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.3-week3/1.3.2-day12-2025-09-23/","title":"Ngày 12 - Lưu trữ &amp; Sao lưu cho EC2","tags":[],"description":"","content":"Ngày: 2025-09-23 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Lưu trữ \u0026amp; Bảo mật cho EC2 Sao lưu trong EC2 AWS Backup cung cấp giải pháp sao lưu tập trung cho nhiều dịch vụ, bao gồm EC2. EBS Snapshot sao lưu các volume EBS: Sao lưu theo thời điểm (point-in-time). Dạng incremental (chỉ lưu block thay đổi). Lưu trữ trong S3 (không truy cập trực tiếp). AMI Backup chụp toàn bộ cấu hình EC2 dưới dạng image. Best practices cho Snapshot:\nLên lịch snapshot định kỳ. Sao chép snapshot sang Region khác cho DR. Gắn thẻ (tag) để quản lý vòng đời. Sử dụng Amazon Data Lifecycle Manager (DLM). Key Pair Key Pair dùng để xác thực an toàn khi kết nối EC2: Public Key – lưu trên instance. Private Key – người dùng giữ để SSH (Linux) hoặc RDP (Windows). Thay thế mật khẩu, tăng cường bảo mật. Lưu ý: Nếu mất private key, AWS không thể khôi phục. Quản lý Key Pair:\nTạo key pair trên AWS hoặc import key sẵn có. Lưu trữ private key an toàn. Dùng key pair khác nhau cho từng môi trường. Luân phiên (rotate) định kỳ. Elastic Block Store (EBS) Amazon EBS cung cấp lưu trữ dạng block bền vững cho EC2. Các loại volume: General Purpose SSD (gp2/gp3) – cân bằng hiệu năng và chi phí. Provisioned IOPS SSD (io1/io2) – cho workload cần IOPS cao. Throughput Optimized HDD (st1) – dữ liệu lớn, truy cập tuần tự. Cold HDD (sc1) – dữ liệu ít truy cập, chi phí thấp. Tính năng chính:\nGắn/Tháo volume với instance. Dữ liệu vẫn giữ khi instance tắt. Tạo snapshot để sao lưu hoặc copy sang Region khác. Tự động nhân bản trong phạm vi AZ. So sánh volume EBS:\nLoại Tình huống Max IOPS Max Throughput gp3 Mục đích tổng quát 16.000 1.000 MB/s io2 Hiệu năng cao 64.000 1.000 MB/s st1 Big data 500 500 MB/s sc1 Lưu trữ lạnh 250 250 MB/s "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.4-week4/1.4.2-day17-2025-09-30/","title":"Ngày 17 - Tính năng nâng cao của S3","tags":[],"description":"","content":"Ngày: 2025-09-30 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Hosting website tĩnh trên Amazon S3 Hosting trực tiếp website tĩnh (HTML, CSS, JS, hình ảnh) từ S3.\nKhả năng chính Thiết lập đơn giản: Chỉ vài bước để bật chế độ static website cho bucket. Chi phí thấp: Trả phí lưu trữ và băng thông tiêu chuẩn, không cần máy chủ web riêng. Scale linh hoạt: Tự động xử lý spike traffic. Tích hợp CDN: Dễ dàng kết hợp Amazon CloudFront để tăng hiệu năng toàn cầu. Cấu hình website tĩnh:\n{ \u0026#34;IndexDocument\u0026#34;: { \u0026#34;Suffix\u0026#34;: \u0026#34;index.html\u0026#34; }, \u0026#34;ErrorDocument\u0026#34;: { \u0026#34;Key\u0026#34;: \u0026#34;error.html\u0026#34; } } Cross-Origin Resource Sharing (CORS) CORS cho phép tài nguyên web (font, JavaScript, \u0026hellip;) trên một domain truy cập tài nguyên ở domain khác.\nCấu hình CORS trên S3 Định nghĩa policy: Chỉ rõ những origin nào được phép truy cập nội dung bucket. Kiểm soát method: Cho phép các HTTP method cụ thể (GET, PUT, POST, \u0026hellip;). Tăng cường bảo mật: Ngăn truy cập cross-origin trái phép. Ví dụ cấu hình CORS:\n[ { \u0026#34;AllowedHeaders\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;AllowedMethods\u0026#34;: [\u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34;], \u0026#34;AllowedOrigins\u0026#34;: [\u0026#34;https://example.com\u0026#34;], \u0026#34;ExposeHeaders\u0026#34;: [\u0026#34;ETag\u0026#34;], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] Hiệu năng \u0026amp; thiết kế khóa object Cách đặt tên object ảnh hưởng đáng kể tới hiệu năng S3:\nPrefix ngẫu nhiên: Phân tán key qua nhiều partition để tăng song song. Tránh prefix tuần tự: Không dùng tiền tố tăng dần (ví dụ timestamp) cho workload throughput cao. Truy cập song song: Thiết kế key hỗ trợ đọc/ghi đồng thời. Best practice đặt key:\n❌ Tệ: 2025-09-30-file1.jpg, 2025-09-30-file2.jpg ✅ Tốt: a1b2/2025-09-30-file1.jpg, c3d4/2025-09-30-file2.jpg S3 Glacier – Lưu trữ dài hạn Các lớp Glacier được tối ưu cho lưu trữ dài hạn chi phí thấp.\nTùy chọn truy xuất Expedited / Fast: Vài phút; chi phí cao. Standard: 3–5 giờ; cân bằng chi phí. Bulk: 5–12 giờ; rẻ nhất cho khôi phục khối lượng lớn. Glacier Deep Archive Lớp chi phí thấp nhất cho lưu trữ nhiều năm, thời gian truy xuất khoảng 12 giờ.\nHands-On Labs Lab 57 – Amazon S3 \u0026amp; CloudFront (Phần 2) Cấu hình object public → 57-5 Kiểm tra website → 57-6 Chặn toàn bộ public access → 57-7.1 Cấu hình CloudFront → 57-7.2 Kiểm tra CloudFront → 57-7.3 Bật Versioning cho bucket → 57-8 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.5-week5/1.5.2-day22-2025-10-07/","title":"Ngày 22 - IAM Policies &amp; Roles","tags":[],"description":"","content":"Ngày: 2025-10-07 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học IAM Policies Policy IAM là tài liệu JSON mô tả quyền. Các loại: Identity-based policy (gắn vào principal). Resource-based policy (gắn vào resource). Quy tắc đánh giá: mọi explicit Deny sẽ ghi đè Allow trên tất cả policy. Ví dụ ràng buộc admin S3:\nCho phép toàn bộ s3:* trên một bucket cụ thể. Explicit Deny mọi hành động không phải S3. Cấu trúc policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [{ \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-bucket/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIp\u0026#34;: \u0026#34;203.0.113.0/24\u0026#34; } } }] } Logic đánh giá policy:\nMặc định mọi request bị từ chối. Allow rõ ràng sẽ ghi đè deny mặc định. Deny rõ ràng ghi đè mọi Allow. Permissions boundary giới hạn quyền tối đa. IAM Roles Role cung cấp quyền tạm thời cho user, dịch vụ hoặc danh tính bên ngoài. Các tình huống phổ biến: Cho phép dịch vụ AWS hành động thay bạn (ví dụ EC2 ghi vào S3). Truy cập chéo tài khoản. Liên kết danh tính từ IdP ngoài (federation). Cấp credential cho ứng dụng trên EC2 mà không cần lưu access key. Lợi ích\nKhông có credential dài hạn, phiên ngắn, hỗ trợ nguyên tắc least privilege và quản lý truy cập quy mô lớn. Các loại role:\nService Role: Cho dịch vụ AWS (EC2, Lambda, \u0026hellip;). Cross-Account Role: Truy cập tài nguyên ở tài khoản khác. Identity Provider Role: Cho người dùng liên kết (federated). Instance Profile: Vỏ chứa role dành cho EC2 instance. Hands-On Labs Lab 48 – IAM Access Keys \u0026amp; Roles (Phần 2) Sử dụng Access Key → 48-2.2 Tạo IAM Role → 48-3.1 Gán IAM Role → 48-3.2 Dọn dẹp tài nguyên → 48-4 Lab 28 – IAM Cross-Region Role \u0026amp; Policy (Phần 1) Tạo IAM User → 28-2.1 Tạo IAM Policy → 28-3 Tạo IAM Role → 28-4 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.6-week6/1.6.2-day27-2025-10-14/","title":"Ngày 27 - Amazon RDS &amp; Aurora","tags":[],"description":"","content":"Ngày: 2025-10-14 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học RDBMS vs NoSQL RDBMS RDBMS lưu dữ liệu trong các bảng có quan hệ (hàng/cột), đảm bảo ràng buộc toàn vẹn, dùng SQL và cung cấp đầy đủ đặc tính ACID. Engine phổ biến: Oracle, MySQL, SQL Server, PostgreSQL, IBM Db2. Tổng quan NoSQL NoSQL hướng tới dữ liệu phi cấu trúc/bán cấu trúc, ưu tiên khả năng mở rộng và hiệu năng cao. Các loại chính: Document (MongoDB, CouchDB) Key–Value (Redis, DynamoDB) Column-Family (Cassandra, HBase) Graph (Neo4j, Amazon Neptune) Đặc điểm: schema linh hoạt, mở rộng ngang, xử lý big data tốt, thiết kế theo CAP. So sánh nhanh RDBMS vs NoSQL OLTP vs OLAP OLTP: nhiều giao dịch nhỏ, đồng thời; dữ liệu chuẩn hóa; truy vấn ngắn, phụ thuộc index. OLAP: phân tích phức tạp trên dữ liệu lịch sử; schema sao/tuyết; đọc nhiều, ghi ít. Amazon RDS \u0026amp; Aurora Amazon Relational Database Service (RDS) Dịch vụ CSDL quan hệ managed giúp đơn giản hóa triển khai, vá lỗi, backup và HA.\nEngine hỗ trợ: MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, Amazon Aurora. Tính năng chính: backup/patch tự động, mở rộng dễ dàng, Multi-AZ cho HA, bảo mật với VPC/IAM/SSL. Kiểu triển khai: Single-AZ Multi-AZ (standby đồng bộ ở AZ khác) Read Replica để scale đọc Tính năng RDS:\nAutomated Backups: khôi phục tới từng thời điểm trong 35 ngày. Manual Snapshots: backup thủ công do người dùng kích hoạt. Multi-AZ: tự động failover để duy trì HA. Read Replica: tối đa 15 replica (tùy engine) cho workload đọc. Parameter Groups: quản lý cấu hình database. Option Groups: bật tính năng bổ sung (ví dụ Oracle Advanced Security). Amazon Aurora Hệ CSDL tương thích MySQL/PostgreSQL được thiết kế lại cho cloud.\nĐiểm nổi bật: Hiệu năng ~5× MySQL / ~3× PostgreSQL (benchmark điển hình). Storage tự động mở rộng tới 128 TB. Sao chép 6 bản trên 3 AZ, tự chữa lành storage. Aurora Serverless mở rộng theo nhu cầu. Global Database cho độ trễ thấp đa vùng. Aurora Features:\nAurora Replicas: tối đa 15 read replica với độ trễ \u0026lt; 10 ms. Aurora Serverless: tự động scale compute. Aurora Global Database: replicate xuyên vùng \u0026lt; 1 giây. Aurora Backtrack: tua ngược DB về thời điểm cụ thể. Aurora Parallel Query: tăng tốc truy vấn phân tích trên dữ liệu hiện thời. Aurora Machine Learning: tích hợp ML native. Aurora vs RDS:\nTính năng Aurora RDS Hiệu năng ~5× MySQL, ~3× PostgreSQL Chuẩn Lưu trữ Tự mở rộng tới 128 TB Tăng thủ công Replica Tối đa 15 Tối đa 5 (MySQL) Failover \u0026lt; 30 giây 1–2 phút Backtrack Có Không Labs thực hành Lab 05 – Amazon RDS \u0026amp; EC2 Integration (Phần 2) Tạo EC2 Instance → 05-3 Tạo RDS Database Instance → 05-4 Triển khai ứng dụng → 05-5 Backup \u0026amp; Restore → 05-6 Dọn tài nguyên → 05-7 Lab 43 – AWS Database Migration Service (DMS) (Phần 1) EC2 Connect RDP Client → 43-01 EC2 Connect Fleet Manager → 43-02 Cấu hình nguồn SQL Server → 43-03 Oracle Connect Source DB → 43-04 Oracle Config Source DB → 43-05 Drop Constraint → 43-06 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.7-week7/1.7.2-day32-2025-10-21/","title":"Ngày 32 - Contract-First &amp; Mocking","tags":[],"description":"","content":"Ngày: 2025-10-21 (Thứ Ba)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Contract-First Development Quy trình 5 bước Viết OpenAPI spec để định nghĩa contract. Dùng spec làm Single Source of Truth cho cả frontend và backend. Frontend dựng UI với mock data dựa trên spec. Backend implement API bám sát schema (status code, payload). Chạy contract testing để chắc chắn backend tuân thủ spec. paths: /books/{id}: get: summary: Get book detail responses: \u0026#34;200\u0026#34;: $ref: \u0026#34;#/components/responses/BookDetail\u0026#34; Lợi ích Giảm mismatch API vì mọi người xem cùng một spec. Documentation, mock server, test script có thể sinh tự động. Dễ review và versioning trước khi triển khai thật. Insight Viết contract trước code giúp giảm ~80% lỗi integration khi frontend/backend phát triển song song.\nMock API với Prism Prism đọc OpenAPI để sinh response giả, cho phép frontend test UI sớm. Hỗ trợ nhiều scenario (200, 404, 500) bằng cách khai báo example trong spec. Giữ nhịp làm việc khi backend chưa xong hoặc đang refactor. Khi nên dùng Sprint đầu của vertical slice. Cần demo flow nhưng chưa có dữ liệu thật. Muốn viết test tự động cho UI dựa trên contract. Ghi chú vận hành Chạy Prism tại localhost:4010, cấu hình NEXT_PUBLIC_API_URL trỏ đến mock. Đảm bảo header CORS trong mock giống backend production. Luôn commit spec trước khi mock để mọi người dùng đúng version. Labs thực hành Tạo OpenAPI spec cho endpoint /books/{id}. Khởi chạy Prism mock server và test luồng UI. Viết checklist review contract (status code, schema, example data). "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.8-week8/1.8.2-day37-2025-10-28/","title":"Ngày 37 - Tìm Kiếm Giọng Nói &amp; Kiến Trúc Chatbot","tags":[],"description":"","content":"Ngày: 2025-10-28 (Thứ Ba)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nTìm Kiếm Giọng Nói (Cách Siri Hoạt Động) Hệ thống tìm kiếm giọng nói tuân theo một pipeline từ đầu vào giọng nói đến phản hồi có thể thực hiện được:\nCác Thành Phần Pipeline: 1. Chuyển Đổi Analog sang Digital Lời nói (phát âm) → Mô hình sóng âm thanh → Spectrogram (mô hình tần số) → Chuỗi các khung âm thanh sử dụng Fast Fourier Transform (FFT)\n2. Nhận Dạng Giọng Nói Tự Động (ASR) Phân tích đặc trưng: Trích xuất các đặc trưng âm thanh Hidden Markov Model (HMM): Nhận dạng mẫu cho chuyển giọng nói sang văn bản Thuật toán Viterbi: Tìm chuỗi trạng thái ẩn có khả năng nhất Từ điển ngữ âm: Ánh xạ âm thanh thành từ Mô hình ngôn ngữ: Đảm bảo tính chính xác ngữ pháp 3. Chú Thích NLP Tokenization Gắn nhãn POS Nhận dạng thực thể (NER) 4. Ánh Xạ Mẫu-Hành Động Ánh xạ các ý định được nhận dạng thành các hành động phù hợp\n5. Quản Lý Dịch Vụ API nội bộ \u0026amp; bên ngoài (email, SMS, bản đồ, thời tiết, cổ phiếu, v.v.) Thực hiện hành động được yêu cầu 6. Chuyển Văn Bản Thành Giọng Nói (TTS) Chuyển đổi phản hồi trở lại thành giọng nói\n7. Phản Hồi Người Dùng Hệ thống học từ các sửa chữa để cải thiện độ chính xác\nKiến Trúc Voicebot Pipeline xử lý voicebot bao gồm nhiều cấp độ ngôn ngữ:\nCác Lớp Xử Lý: Phân Tích Giọng Nói (Âm Vị Học) Nhận dạng và phiên âm giọng nói sử dụng Nhận Dạng Giọng Nói Tự Động (ASR)\nPhân Tích Hình Thái và Từ Vựng (Hình Thái Học) Phân tích cấu trúc và ý nghĩa của từ sử dụng các quy tắc hình thái và từ vựng\nPhân Tích Cú Pháp (Cú Pháp) Hiểu cấu trúc câu sử dụng từ vựng và quy tắc ngữ pháp\nSuy Luận Ngữ Cảnh (Ngữ Nghĩa) Hiểu ý nghĩa trong ngữ cảnh sử dụng ngữ cảnh diễn ngôn\nSuy Luận và Thực Thi Ứng Dụng (Lý Luận) Sử dụng kiến thức miền để quyết định hành động\nLập Kế Hoạch Phát Ngôn Lập kế hoạch những gì sẽ nói trong phản hồi\nHiện Thực Hóa Cú Pháp Tạo ra các câu chính xác ngữ pháp\nHiện Thực Hóa Hình Thái Áp dụng các dạng từ chính xác\nMô Hình Phát Âm Tạo ra phát âm phù hợp\nTổng Hợp Giọng Nói Chuyển đổi văn bản trở lại thành giọng nói\nQuy Trình Làm Việc Chatbot Quy Trình Từng Bước: 1. Người Dùng → Ứng Dụng Chat Người dùng gõ: \u0026ldquo;Tôi muốn kiểm tra số dư tài khoản.\u0026rdquo; Ứng Dụng Chat = giao diện nơi người dùng gõ (web, app, messenger)\n2. Ứng Dụng Chat → Chatbot Tin nhắn được gửi đến hệ thống chatbot\n3. Chatbot → NLP Engine Chatbot gửi tin nhắn đến NLP Engine để phân tích\nNLP Engine thực hiện hai tác vụ chính: (a) Phát Hiện Ý Định Xác định người dùng muốn làm gì\nVí dụ: kiểm_tra_số_dư (b) Trích Xuất Thực Thể Trích xuất dữ liệu quan trọng từ câu\nVí dụ: tài_khoản = thanh toán/tiết kiệm? 4. NLP Engine → Logic Nghiệp Vụ / Dịch Vụ Dữ Liệu Dựa trên ý định, chatbot gọi dịch vụ phù hợp:\nTruy vấn cơ sở dữ liệu Gọi API Thực thi quy tắc nghiệp vụ Xử lý logic backend Ví dụ: Gọi API để lấy số dư từ hệ thống ngân hàng\n5. Dịch Vụ Dữ Liệu → Chatbot Backend trả về kết quả:\n\u0026ldquo;Số dư tài khoản của bạn là 12.500.000₫\u0026rdquo;\n6. Chatbot → Ứng Dụng Chat Chatbot đóng gói thông tin thành phản hồi ngôn ngữ tự nhiên\n7. Hiển Thị Cho Người Dùng Người dùng nhìn thấy phản hồi\nChatbot = Lắng Nghe + Trò Chuyện Lắng Nghe (NLP - Hiểu) Nhận dạng ý định Trích xuất thực thể Hiểu ngữ cảnh Trò Chuyện (NLG - Tạo) Tạo ngôn ngữ tự nhiên Công thức hóa phản hồi Cá nhân hóa Đằng Sau Hậu Trường: Dữ liệu dựa trên kiến thức: Sự thật, quy tắc, FAQ Học máy: Học từ các tương tác Logic nghiệp vụ: Quy tắc cụ thể của ứng dụng Phân Biệt Quan Trọng: Từ Khóa vs Thực Thể Từ Khóa = các từ chỉ ra chủ đề hoặc đối tượng Thực Thể = các điểm dữ liệu cụ thể với loại và giá trị\nVí dụ: \u0026ldquo;Đặt chuyến bay đến Paris vào thứ Sáu\u0026rdquo;\nTừ khóa: đặt, chuyến bay Thực thể: điểm_đến = \u0026ldquo;Paris\u0026rdquo; (ĐỊA ĐIỂM) ngày = \u0026ldquo;thứ Sáu\u0026rdquo; (NGÀY THÁNG) Không phải tất cả từ khóa đều là thực thể, nhưng tất cả thực thể đều được trích xuất từ từ khóa!\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/1.9.2-day42-2025-11-04/","title":"Ngày 42 - Tổng Quan Kiến Trúc Transformer","tags":[],"description":"","content":"Ngày: 2025-11-04 (Thứ Ba)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nKiến Trúc Transformer: Bức Tranh Toàn Cảnh Mô hình transformer được giới thiệu trong bài báo \u0026ldquo;Attention is All You Need\u0026rdquo; đã cách mạng hóa NLP. Hãy hiểu cấu trúc hoàn chỉnh của nó.\nKiến Trúc Cấp Cao CỬA VÀO CHUỖI ↓ [Tokenization \u0026amp; Embedding] ↓ [Thêm Positional Encoding] ↓ ┌─────────────────────────────────┐ │ ENCODER (N layers) │ │ ├─ Multi-Head Attention │ │ ├─ Layer Normalization │ │ ├─ Feed-Forward Network │ │ └─ Residual Connections │ └─────────────────────────────────┘ ↓ [Context Vectors từ Encoder] ↓ ┌─────────────────────────────────┐ │ DECODER (N layers) │ │ ├─ Masked Multi-Head Attention │ │ ├─ Encoder-Decoder Attention │ │ ├─ Feed-Forward Network │ │ └─ Layer Normalization │ └─────────────────────────────────┘ ↓ [Linear Layer + Softmax] ↓ ĐẦU RA XÁC SUẤT Thành Phần 1: Word Embeddings Mỗi từ được chuyển đổi thành một vector dày đặc (thường là 512-1024 chiều).\nVí Dụ:\nTừ: \u0026#34;happy\u0026#34; Embedding: [0.2, -0.5, 0.8, ..., 0.1] // 512 giá trị Thành Phần 2: Positional Encoding Vấn Đề: Transformers không có thứ tự tuần tự được tích hợp sẵn (không giống RNNs). Vì vậy chúng ta phải thêm thông tin vị trí một cách rõ ràng.\nGiải Pháp: Thêm các vector positional encoding vào embeddings.\nCông Thức:\nPE(pos, 2i) = sin(pos / 10000^(2i/d_model)) PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model)) Trong đó: - pos = vị trí trong chuỗi (0, 1, 2, ...) - i = chỉ số chiều - d_model = chiều embedding (512, 1024, v.v.) Ý Tưởng:\nVị trí 0: \u0026ldquo;I\u0026rdquo; nhận PE₀ Vị trí 1: \u0026ldquo;am\u0026rdquo; nhận PE₁ Vị trí 2: \u0026ldquo;happy\u0026rdquo; nhận PE₂ Ví Dụ:\nEmbedding(\u0026#34;I\u0026#34;) = [0.2, -0.5, 0.8, ..., 0.1] PE(pos=0) = [0.0, 1.0, 0.0, 1.0, ..., 0.5] Final = [0.2, 0.5, 0.8, 1.0, ..., 0.6] Thành Phần 3: Multi-Head Attention Thay vì một cơ chế attention, chúng ta có h \u0026ldquo;đầu\u0026rdquo; khác nhau chạy song song.\nKhái Niệm:\nĐầu vào: Query (Q), Key (K), Value (V) matrices Đầu 1: ScaledDotProductAttention(Q₁, K₁, V₁) Đầu 2: ScaledDotProductAttention(Q₂, K₂, V₂) ... Đầu h: ScaledDotProductAttention(Qₕ, Kₕ, Vₕ) Đầu ra = Concatenate(Head₁, Head₂, ..., Headₕ) Tại Sao Nhiều Đầu?\nĐầu 1 có thể học mối quan hệ \u0026ldquo;chủ ngữ-động từ\u0026rdquo; Đầu 2 có thể học mối quan hệ \u0026ldquo;tính từ-danh từ\u0026rdquo; Đầu 3 có thể học mối quan hệ \u0026ldquo;đại từ-tham chiếu\u0026rdquo; Cùng nhau: Hiểu biết ngữ cảnh phong phú Cấu Hình Điển Hình:\nSố lượng đầu: 8-16 Chiều trên mỗi đầu: 64 (nếu tổng = 512, thì 512/8 = 64) Thành Phần 4: Residual Connections \u0026amp; Layer Normalization Residual Connections Đầu ra = Đầu vào + Attention(Đầu vào) Điều này giúp luồng gradient trong suốt huấn luyện và cho phép mạng lưới đi sâu hơn.\nLayer Normalization Normalized = (x - mean) / sqrt(variance + epsilon) Ổn định huấn luyện và tăng tốc độ hội tụ.\nThành Phần 5: Feed-Forward Network Sau attention, có một mạng feed-forward 2 lớp đơn giản:\nĐầu ra = ReLU(Linear₁(x)) → Linear₂ Các chiều điển hình:\nĐầu vào: [batch_size, seq_length, 512] ↓ Linear₁ (512 → 2048) [batch_size, seq_length, 2048] ↓ ReLU (non-linear) [batch_size, seq_length, 2048] ↓ Linear₂ (2048 → 512) [batch_size, seq_length, 512] Điều này mở rộng rồi co lại, cho phép các phép biến đổi phi tuyến.\nEncoder: Chế Độ Xem Chi Tiết Lớp Encoder Duy Nhất:\nĐầu vào (x) ↓ [Multi-Head Self-Attention] ↓ [+ Residual Connection với đầu vào] ↓ [Layer Normalization] ↓ [Feed-Forward Network] ↓ [+ Residual Connection] ↓ [Layer Normalization] ↓ Đầu ra Điểm Chính: Trong encoder, mỗi từ attend tới TẤT CẢ các từ (bao gồm cả chính nó) trong cùng một câu.\nEncoder cho: Đại diện ngữ cảnh của mỗi từ, xem xét tất cả các từ khác.\nDecoder: Chế Độ Xem Chi Tiết Decoder tương tự nhưng với masking:\nĐầu vào (shifted right by 1) ↓ [Masked Multi-Head Self-Attention] ← Chỉ có thể attend vào các vị trí trước ↓ [+ Residual + LayerNorm] ↓ [Encoder-Decoder Attention] ← Attend vào đầu ra encoder ↓ [+ Residual + LayerNorm] ↓ [Feed-Forward Network] ↓ [+ Residual + LayerNorm] ↓ Đầu ra Ba Cơ Chế Attention trong Decoder:\nMasked Self-Attention:\nQueries, Keys, Values từ decoder Mỗi vị trí chỉ có thể attend tới các vị trí trước đó Ngăn chặn rò rỉ thông tin (decoder không thấy các từ tương lai) Encoder-Decoder Attention:\nQueries từ decoder Keys, Values từ encoder Decoder có thể attend tới bất kỳ vị trí encoder nào Feed-Forward:\nMạng 2 lớp giống như encoder Kết Hợp Tất Cả: Transformer Đầy Đủ Giai Đoạn Huấn Luyện Đầu vào: \u0026#34;Je suis heureux\u0026#34; (Tiếng Pháp) Mục Tiêu: \u0026#34;I am happy\u0026#34; (Tiếng Anh) Đầu vào Encoder: - Tokenize: [Je, suis, heureux] - Embed mỗi token - Thêm positional encoding - Xử lý qua N lớp encoder → Đầu ra: C (context vectors) Đầu vào Decoder: - Mục tiêu shifted right: [\u0026lt;START\u0026gt;, I, am] - Embed mỗi token - Thêm positional encoding - Xử lý qua N lớp decoder - Sử dụng masked self-attention - Sử dụng encoder-decoder attention trên C → Đầu ra logits cho mỗi vị trí Mất mát: So sánh dự đoán \u0026#34;am happy\u0026#34; với thực tế \u0026#34;am happy\u0026#34; Backprop: Cập nhật tất cả các trọng số Giai Đoạn Suy Luận Đầu vào Encoder: [Je, suis, heureux] → Đầu ra: C (context vectors) Decoder: Bước 1: Bắt đầu với [\u0026lt;START\u0026gt;] Dự đoán từ tiếp theo: \u0026#34;I\u0026#34; Bước 2: [\u0026lt;START\u0026gt;, I] Dự đoán từ tiếp theo: \u0026#34;am\u0026#34; Bước 3: [\u0026lt;START\u0026gt;, I, am] Dự đoán từ tiếp theo: \u0026#34;happy\u0026#34; Bước 4: [\u0026lt;START\u0026gt;, I, am, happy] Dự đoán từ tiếp theo: \u0026lt;END\u0026gt; Đầu ra: \u0026#34;I am happy\u0026#34; Tóm Tắt: Tại Sao Kiến Trúc Này Hoạt Động Tính Năng Lợi Ích Không RNN Hoàn toàn có thể song song hóa - huấn luyện trên GPU hiệu quả Self-Attention trong Encoder Mỗi từ nhận ngữ cảnh từ TẤT CẢ các từ khác Masked Attention trong Decoder Không thể nhìn thấy tương lai - huấn luyện với tạo hình autoregressive Positional Encoding Bảo tồn thứ tự từ mà không xử lý tuần tự RNN Multi-Head Attention Học nhiều loại mối quan hệ đồng thời Residual Connections Luồng gradient - cho phép huấn luyện mạng sâu Layer Normalization Ổn định - hội tụ nhanh hơn Các Đổi Mới Chính Song Song Hóa: O(1) độ sâu thay vì O(n) cho RNNs Phụ Thuộc Dài Hạn: Attention có thể kết nối trực tiếp bất kỳ hai vị trí nào Khả Năng Mở Rộng: Có thể tăng kích thước mô hình với cải thiện dự đoán Transfer Learning: Các transformer được huấn luyện trước (BERT, GPT) hoạt động trên các tác vụ "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.10-week10/1.10.2-day47-2025-11-11/","title":"Ngày 47 - Hai chế độ Question Answering","tags":[],"description":"","content":"Ngày: 2025-11-11 (Thứ Ba)\nTrạng Thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nQA có ngữ cảnh vs. QA closed-book Cùng dùng transformer, nhưng khác ở dữ liệu đầu vào và cách đánh giá.\nCó ngữ cảnh (open book) Input: câu hỏi + đoạn văn hỗ trợ. Output: trích span hoặc sinh ngắn, bám sát ngữ cảnh. Train: span có nhãn (start/end) hoặc seq2seq kèm context. Lỗi thường gặp: sai span khi ngữ cảnh nhiễu. Closed-book Input: chỉ câu hỏi; model dựa vào kiến thức bên trong. Output: câu trả lời sinh ra không có context tường minh. Train: kiểu language modeling trên corpora lớn, fine-tune với QA pairs. Lỗi: bịa/hallucination; giảm bằng pre-train mạnh hoặc distillation. Chọn chế độ nào? Có thể cấp tài liệu lúc suy luận -\u0026gt; ưu tiên có ngữ cảnh (kiểm soát tốt, dễ trích dẫn). Bị giới hạn latency/lưu trữ -\u0026gt; closed-book nhẹ hơn nhưng rủi ro cao hơn. Đánh giá Có ngữ cảnh: Exact Match / F1 trên span; kiểm tra bám văn bản. Closed-book: BLEU/ROUGE + đánh giá factuality; cân nhắc thêm retrieval nếu lệch. Việc thực hành hôm nay Soạn ví dụ cho cả hai chế độ với dữ liệu miền của bạn. Định nghĩa metric theo chế độ (EM/F1 span vs. ROUGE/factuality). Liệt kê phương án retrieval để nâng closed-book lên open-book khi cần. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.11-week11/1.11.2-day52-2025-11-18/","title":"Ngày 52 - Thiết lập Capacity Provider","tags":[],"description":"","content":"Ngày: 2025-11-18 (Thứ Ba)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nXây capacity provider Bước 1 cho LMI: định nghĩa lớp instance (capacity provider) với VPC, role và lựa chọn loại máy.\nThông tin bắt buộc IAM role cho phép Lambda launch/manage instance VPC config (subnet + SG) nơi instance LMI chạy Chọn loại máy Hỗ trợ: họ C/M/R đời mới (x86/AMD/Graviton), kích cỡ large+ Tùy biến: allow/deny list loại máy; đặt kiến trúc ARM nếu cần EBS: mã hóa mặc định; có thể dùng KMS của bạn Lưu ý mạng Dàn subnet qua 3 AZ cho sẵn sàng Tất cả egress/log đi qua ENI của instance; không cấu hình VPC ở mức function Đóng inbound SG; đảm bảo đường ra tới dependency/CloudWatch Guardrail Giới hạn max vCPU để chặn bùng chi phí Có thêm tham số scale ở mức provider khi cần "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.12-week12/1.12.2-day57-2025-11-25/","title":"Ngày 57 - Bedrock &amp; AgentCore","tags":[],"description":"","content":"Ngày: 2025-11-25 (Thứ Ba)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nCập nhật Bedrock Thêm model open-weight managed (Mistral Large 3, Ministral 3 3B/8B/14B và đối tác khác) Reinforcement fine-tuning: tuning theo phản hồi, cải thiện độ chính xác lớn mà không cần bộ nhãn lớn AgentCore Thêm policy control và quality monitoring cho agent Cải thiện bộ nhớ và hội thoại tự nhiên để triển khai an toàn hơn Việc cần làm Chọn model để đánh giá (latency/chi phí/chất lượng so với hiện tại) Lên thử nghiệm RFT cho tác vụ mục tiêu; định nghĩa tín hiệu phản hồi Xác định guardrail/policy trước khi bật AgentCore production "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/4-eventparticipated/4.2-event2/","title":"Sự Kiện 2 - AWS GenAI Builder Club","tags":[],"description":"","content":"AWS GenAI Builder Club: Vòng Đời Phát Triển Dựa trên AI - Tái Định Hình Kỹ Thuật Phần Mềm Ngày \u0026amp; Giờ: Thứ Sáu, 3 tháng 10 năm 2025 | 14:00 (2:00 PM)\nĐịa Điểm: AWS Event Hall, L26 Tòa Nhà Bitexco, Thành phố Hồ Chí Minh\nGiảng Viên: Toàn Huỳnh \u0026amp; Mỹ Nguyễn\nĐiều Phối Viên: Diễm Mỹ, Đại Trương, Định Nguyễn\nTổng Quan Sự Kiện Buổi gặp mặt AWS GenAI Builder Club này điều tra Vòng Đời Phát Triển Dựa trên AI (AI-DLC), một phương pháp sáng tạo cho kỹ thuật phần mềm tích hợp AI như một cộng tác viên cốt lõi trong suốt hành trình phát triển hoàn chỉnh. Phiên làm việc bao gồm các bản trình diễn tương tác về Amazon Q Developer và Kiro, trình bày các ứng dụng AI thực tế trong phát triển phần mềm đương đại.\nChương Trình Giờ Phiên Giảng Viên 14:00 - 14:15 Chào Mừng - 14:15 - 15:30 Tổng Quan Vòng Đời Phát Triển Dựa trên AI \u0026amp; Bản Trình Diễn Amazon Q Developer Toàn Huỳnh 15:30 - 15:45 Giải Lao - 15:45 - 16:30 Bản Trình Diễn Kiro Mỹ Nguyễn Các Khái Niệm \u0026amp; Bài Học Chính 1. Tổng Quan Vòng Đời Phát Triển Dựa trên AI (AI-DLC) Triết Lý Cốt Lõi Vòng Đời Phát Triển Dựa trên AI biểu thị một sự chuyển đổi căn bản trong phương pháp xây dựng phần mềm. Thay vì coi AI như một tính năng phụ hoặc tiện ích hoàn thành mã cơ bản, AI-DLC định vị AI như một cộng tác viên thông minh trong suốt quy trình phát triển hoàn chỉnh.\nCác Nguyên Tắc Chính:\nBạn Duy Trì Quyền Kiểm Soát - AI phục vụ như trợ lý của bạn, không phải người giám sát của bạn. Bạn cần giữ quyền ra quyết định về hướng dự án và chi tiết triển khai.\nAI Là Đối Tác, Không Phải Thay Thế - AI nên đặt những câu hỏi quan trọng về nhu cầu dự án, kiến trúc và mục tiêu của bạn. Mối quan hệ đối tác nên chảy hai chiều, với bạn định hướng các khuyến nghị của AI.\nThiết Kế Trước Khi Xây Dựng - Luôn phát triển một kế hoạch toàn diện trước khi viết mã. AI có thể hỗ trợ trong việc tạo kế hoạch này, nhưng bạn phải kiểm tra, xác nhận và cải thiện nó.\nQuy Trình Phát Triển Bước 1: Phát Triển Kế Hoạch Dự Án\nThiết lập các yêu cầu và ranh giới dự án rõ ràng Yêu cầu AI tạo kế hoạch dựa trên các thông số kỹ thuật của bạn Đánh giá phê phán kế hoạch và yêu cầu điều chỉnh Xác nhận kế hoạch toàn diện và rõ ràng Bước 2: Phân Tách Thành User Stories\nChuyển đổi kế hoạch thành user stories với tiêu chí chấp nhận rõ ràng Chia phạm vi lớn thành các đơn vị nhỏ hơn, có thể xử lý được Mỗi đơn vị trở thành một dự án nhỏ có thể giao cho các thành viên nhóm Tính toán thời gian cho mỗi đơn vị (trong khi cẩn thận về ước tính quá cao) Bước 3: Thiết Lập Ngăn Xếp Công Nghệ\nNêu rõ các công nghệ, framework và công cụ sẽ được sử dụng Thay vì hướng dẫn AI \u0026ldquo;đừng triển khai cái này,\u0026rdquo; hãy nói \u0026ldquo;triển khai theo cách này\u0026rdquo; Hướng dẫn khẳng định tạo ra tỷ lệ thành công cao hơn các hạn chế tiêu cực Bước 4: Yêu Cầu \u0026amp; Thiết Kế Toàn Diện\nGhi lại yêu cầu với độ chính xác và rõ ràng Hợp tác với AI để phát triển các thông số kỹ thuật chi tiết Xác định các mô hình dữ liệu, hợp đồng API và kiến trúc hệ thống Tạo tài liệu thiết kế trước khi triển khai bắt đầu Bước 5: Triển Khai \u0026amp; Xác Nhận\nXây dựng các tính năng theo kế hoạch Áp dụng phương pháp phát triển mob (nhóm làm việc tập thể trên mã) Xác nhận tất cả mã được tạo ra như một nhóm Thực hiện đánh giá mã và kiểm tra chất lượng Bước 6: Kiểm Thử \u0026amp; Triển Khai\nTiến triển qua các môi trường: Development (Dev) → Testing (QA) → User Acceptance Testing (UAT) → Production (Prod) Duy trì các cổng chất lượng ở mỗi giai đoạn Xác nhận chức năng trước khi phát hành sản xuất Các Yếu Tố Thành Công Quan Trọng Phát Triển Kế Hoạch Trước - Đừng giả định AI sẽ quản lý mọi thứ. Luôn bắt đầu với một kế hoạch xác định. Xem Xét Liên Tục - Liên tục xem xét các khuyến nghị và đầu ra của AI. Tỷ lệ lỗi đáng kể là có thể. Bạn Là Người Chỉ Đạo - Giá trị của bạn nằm ở xác nhận mã và giám sát dự án, không phải viết từng dòng mã. Đặt Câu Hỏi Làm Rõ - Xác nhận AI nắm bắt ngữ cảnh dự án của bạn bằng cách đặt những câu hỏi quan trọng về yêu cầu, kiến trúc và mục tiêu. Áp Dụng Mẫu Prompt - Thiết kế các prompt có cấu trúc bao gồm ngữ cảnh người dùng, user stories và các yêu cầu cụ thể để có được phản hồi AI rõ ràng hơn. Lưu Kế Hoạch Thành Tệp - Yêu cầu AI tạo kế hoạch dưới dạng tệp bạn có thể lưu trữ, xem xét và điều chỉnh. Điều này tạo ra một tài liệu sống cho việc tham khảo trong tương lai. Lịch Sự Với AI - Duy trì giao tiếp tôn trọng với các công cụ AI. Mối quan hệ tích cực có thể có lợi cho các tương tác trong tương lai (và đó chỉ đơn giản là thực hành tốt!). 2. Bản Trình Diễn Amazon Q Developer Amazon Q Developer Là Gì? Amazon Q Developer là một trợ lý được hỗ trợ bởi AI cách mạng hóa vòng đời phát triển phần mềm (SDLC) thông qua các khả năng tự chủ trên nhiều nền tảng:\nAWS Console - Hỗ trợ cấu hình hạ tầng và dịch vụ IDE (Integrated Development Environment) - Cung cấp các khuyến nghị tạo mã và tối ưu hóa CLI (Command Line Interface) - Hỗ trợ tạo lệnh và tự động hóa Các Nền Tảng DevSecOps - Tích hợp các thực hành bảo mật vào quy trình phát triển Các Khả Năng Chính Tạo Mã \u0026amp; Chất Lượng\nĐẩy nhanh tốc độ tạo mã với các gợi ý được hỗ trợ bởi AI Nâng cao chất lượng mã thông qua các khuyến nghị thông minh Duy trì tích hợp mượt mà với các quy trình làm việc hiện tại Hiểu các cơ sở mã phức tạp và khuyến nghị tối ưu hóa Tài Liệu \u0026amp; Kiểm Thử\nTự động tạo tài liệu toàn diện Tạo bài kiểm tra đơn vị với nỗ lực thủ công tối thiểu Cải thiện đáng kể khả năng bảo trì mã và độ tin cậy Giảm thiểu boilerplate và các tác vụ mã lặp lại Quan Hệ Đối Tác Thông Minh\nHoạt động như một đối tác thông minh sử dụng các mô hình ngôn ngữ lớn Kết hợp kiến thức dịch vụ AWS sâu sắc với năng lực mã hóa Hỗ trợ các nhà phát triển đẩy nhanh các chu kỳ phát triển Cải thiện chất lượng mã và củng cố tư thế bảo mật Tự Động Hóa Trong Suốt Vòng Đời Phát Triển\nTự động hóa các tác vụ tiêu chuẩn trong suốt vòng đời phát triển hoàn chỉnh Giảm công việc thủ công, lặp lại Cho phép các nhà phát triển tập trung vào các tác vụ sáng tạo có giá trị cao hơn Nâng cao năng suất và hiệu quả tổng thể Thực Hành Tốt Nhất Khi Sử Dụng Amazon Q Developer Cung Cấp Ngữ Cảnh Rõ Ràng - Cung cấp cho Q thông tin toàn diện về dự án, kiến trúc và yêu cầu của bạn Áp Dụng Prompt Cụ Thể - Thay vì các yêu cầu mơ hồ, cung cấp các prompt cụ thể, chi tiết với các ví dụ Kiểm Tra Các Gợi Ý - Luôn kiểm tra các gợi ý của Q trước khi áp dụng chúng Lặp Lại \u0026amp; Cải Thiện - Nếu gợi ý ban đầu không lý tưởng, tinh chỉnh prompt của bạn và thử lại Tận Dụng Kiến Thức AWS - Hưởng lợi từ sự hiểu biết sâu sắc của Q về các dịch vụ AWS và thực hành tốt nhất 3. Bản Trình Diễn Kiro Kiro Là Gì? Kiro là một IDE tự chủ (Integrated Development Environment) được tạo ra bởi Amazon Web Services kết nối tạo prototype nhanh được hỗ trợ bởi AI và phát triển phần mềm sẵn sàng cho sản xuất. Nó hiện đang ở giai đoạn xem trước công khai.\nTriết Lý Cốt Lõi Kiro đại diện cho nguyên tắc rằng AI nên tăng năng suất của nhà phát triển trong khi duy trì các tiêu chuẩn chuyên nghiệp, tổ chức rõ ràng, kiểm thử toàn diện, tài liệu và khả năng bảo trì lâu dài.\nCác Tính Năng Chính Phát Triển Theo Đặc Tả\nKhi bạn cung cấp một yêu cầu (ví dụ: \u0026ldquo;thêm hệ thống đánh giá sản phẩm\u0026rdquo;), Kiro chuyển đổi nó thành: User stories với tiêu chí chấp nhận rõ ràng Tài liệu thiết kế Danh sách tác vụ và kế hoạch triển khai Thông số kỹ thuật có tổ chức trước khi tạo mã Agent Hooks \u0026amp; Tự Động Hóa\nTự động khởi tạo các tác vụ dựa trên các sự kiện: Lưu tệp khởi tạo cập nhật tài liệu Commit khởi tạo tạo bài kiểm tra Các hành động cụ thể khởi tạo tối ưu hóa hiệu năng Giảm thiểu công việc thủ công, lặp lại Steering \u0026amp; Ngữ Cảnh Dự Án\nPhát triển các tệp steering (markdown) để phác thảo: Cấu trúc và sắp xếp dự án Tiêu chuẩn mã hóa và quy ước Các mô hình kiến trúc được ưa thích Hướng dẫn nhóm và thực hành tốt nhất Hỗ trợ Kiro hiểu sâu sắc ngữ cảnh dự án của bạn Phân Tích Đa Tệp \u0026amp; Hiểu Ý Định\nKiểm tra nhiều tệp đồng thời Nắm bắt các mục tiêu chức năng trên toàn bộ cơ sở mã Triển khai các thay đổi phù hợp với các mục tiêu dự án tổng thể Mở rộng vượt ra ngoài hoàn thành mã cơ bản Tích Hợp VS Code\nĐược xây dựng dựa trên nền tảng mã nguồn mở của VS Code Nhập cài đặt, chủ đề và tiện ích mở rộng từ VS Code Giao diện quen thuộc cho người dùng VS Code hiện có Chuyển đổi dễ dàng cho các nhà phát triển Lựa Chọn Mô Hình AI Linh Hoạt\nHiện sử dụng Claude Sonnet 4 làm mặc định Chế độ \u0026ldquo;Auto\u0026rdquo; kết hợp nhiều mô hình dựa trên ngữ cảnh Cân bằng giữa chất lượng và chi phí Khả năng thích ứng để chọn các mô hình khác nhau cho các tác vụ khác nhau Ưu Điểm Của Việc Sử Dụng Kiro Tính Minh Bạch \u0026amp; Kiểm Soát Được Nâng Cao\nBắt đầu với các thông số kỹ thuật trước khi tạo mã Kiểm tra và xác nhận các thông số kỹ thuật trước khi triển khai Giảm mã \u0026ldquo;ảo tưởng\u0026rdquo; hoặc triển khai không phù hợp Duy trì khả năng truy xuất rõ ràng từ yêu cầu đến mã Giảm Boilerplate \u0026amp; Các Tác Vụ Lặp Lại\nAgent hooks tự động hóa tạo tài liệu Tạo bài kiểm tra đơn vị tự động Cập nhật thông tin tự động Giải phóng các nhà phát triển cho công việc có giá trị cao hơn Bảo Mật \u0026amp; Quyền Riêng Tư\nHầu hết các hoạt động mã xảy ra cục bộ Dữ liệu chỉ được truyền bên ngoài với sự cho phép rõ ràng Duy trì kiểm soát thông tin nhạy cảm Khả Năng Mở Rộng \u0026amp; Linh Hoạt\nKết nối các công cụ bên ngoài thông qua MCP (Model Context Protocol) Hỗ trợ nhiều mô hình AI Không bị giới hạn vào một môi trường AI duy nhất Có thể thích ứng với các quy trình làm việc nhóm khác nhau Hạn Chế \u0026amp; Cân Nhắc Trạng Thái Xem Trước - Vẫn ở giai đoạn xem trước công khai; tính ổn định và tính năng có thể thay đổi Các Dự Án Phức Tạp - Có thể gặp thách thức với hiểu biết ngữ cảnh sâu sắc trong các dự án rất phức tạp Cần Giám Sát - Người dùng vẫn cần giám sát và xác nhận các quyết định của AI Giá Cả Trong Tương Lai - Các tầng giá dự kiến: Miễn phí: ~50 tác vụ/tháng Pro: ~1.000 tác vụ/tháng Pro+: ~3.000 tác vụ/tháng Khi Nào Nên Sử Dụng Kiro Bạn mong muốn một quy trình làm việc AI + lập trình duy trì tính chuyên nghiệp và tổ chức rõ ràng Xây dựng prototype nhanh nhưng lo ngại về độ bền sản xuất Điều tra cách AI có thể trở thành một đồng nghiệp lập trình thực sự, không chỉ là công cụ gợi ý mã Bạn cần phát triển theo đặc tả với tài liệu và kiểm thử tự động Các Lỗi Thường Gặp Khi Sử Dụng AI Trong Phát Triển 1. Kỳ Vọng AI Quản Lý Mọi Thứ Vấn Đề: Nhiều nhà phát triển kỳ vọng AI hoàn thành toàn bộ dự án một cách tự chủ.\nGiải Pháp: Luôn phát triển kế hoạch trước và kiểm tra thường xuyên. AI là công cụ để tăng năng suất, không phải thay thế phán đoán của nhà phát triển.\n2. Tỷ Lệ Lỗi Cao Vấn Đề: AI có thể mắc lỗi, đặc biệt trong các tình huống phức tạp.\nGiải Pháp: Triển khai các chu kỳ kiểm tra thường xuyên. Xác nhận tất cả mã do AI tạo trước khi triển khai.\n3. Thiếu Yêu Cầu Rõ Ràng Vấn Đề: Yêu cầu mơ hồ hoặc không rõ ràng dẫn đến đầu ra AI mơ hồ.\nGiải Pháp: Ghi lại yêu cầu với độ chính xác. Hợp tác với AI để phát triển các thông số kỹ thuật chi tiết trước khi triển khai.\n4. Ràng Buộc Tiêu Cực Thay Vì Hướng Dẫn Khẳng Định Vấn Đề: Hướng dẫn AI \u0026ldquo;đừng làm cái này\u0026rdquo; kém hiệu quả hơn \u0026ldquo;làm cái này.\u0026rdquo;\nGiải Pháp: Áp dụng các hướng dẫn tích cực, cụ thể. Tỷ lệ thành công cao hơn đến từ hướng dẫn khẳng định rõ ràng.\n5. Ngữ Cảnh Dự Án Không Đủ Vấn Đề: AI không hiểu các yêu cầu và ràng buộc độc đáo của dự án của bạn.\nGiải Pháp: Phát triển các tệp steering, cung cấp ngữ cảnh chi tiết và đặt những câu hỏi quan trọng cho AI về dự án của bạn.\n6. Xem AI Là Người Chỉ Đạo Vấn Đề: Cho phép AI đưa ra tất cả các quyết định về hướng dự án và kiến trúc.\nGiải Pháp: Nhớ: Bạn là người chỉ đạo. Giá trị của bạn nằm ở xác nhận mã và giám sát dự án, không phải viết từng dòng mã.\nNhững Điểm Chính Rút Ra AI Là Trợ Lý Của Bạn - Duy trì quyền kiểm soát các quyết định dự án và hướng triển khai\nThiết Kế Trước, Mã Sau - Luôn phát triển kế hoạch toàn diện trước khi triển khai\nQuan Hệ Đối Tác Hơn Tự Động Hóa - AI nên đặt câu hỏi và hợp tác, không chỉ thực thi lệnh\nYêu Cầu Rõ Ràng Quan Trọng - Độ chính xác trong yêu cầu dẫn đến đầu ra AI tốt hơn\nKiểm Tra Thường Xuyên Là Cần Thiết - Đừng kỳ vọng AI hoàn hảo; kiểm tra và xác nhận liên tục\nBạn Là Người Chỉ Đạo Mã - Giá trị của bạn nằm ở xác nhận và giám sát, không phải viết từng dòng\nÁp Dụng Prompt Có Cấu Trúc - Các mẫu với ngữ cảnh, user stories và yêu cầu tạo ra kết quả tốt hơn\nLưu Kế Hoạch Thành Tệp - Phát triển các tài liệu sống bạn có thể tham khảo và điều chỉnh\nHướng Dẫn Khẳng Định Hiệu Quả Hơn - Hướng dẫn AI phải làm gì, không phải tránh làm gì\nKinh Nghiệm Quan Trọng - Áp dụng các công cụ này thực tế để hiểu khả năng và hạn chế của chúng\nCông Cụ \u0026amp; Tài Nguyên Được Đề Xuất Amazon Q Developer - Trợ lý phát triển được hỗ trợ bởi AI tích hợp với các dịch vụ AWS Kiro IDE - Môi trường phát triển theo đặc tả với quan hệ đối tác AI AWS CodeWhisperer - Công cụ tạo mã và tối ưu hóa MCP (Model Context Protocol) - Khung công tác để kết nối các công cụ và dịch vụ bên ngoài Kết Luận Vòng Đời Phát Triển Dựa trên AI thể hiện một mô hình mới trong kỹ thuật phần mềm nơi AI và con người hợp tác như những người bình đẳng. Thành công đòi hỏi lập kế hoạch rõ ràng, kiểm tra thường xuyên, yêu cầu chính xác và duy trì quyền kiểm soát của nhà phát triển đối với hướng dự án. Các công cụ như Amazon Q Developer và Kiro đang hỗ trợ quy trình làm việc mới này, nhưng chúng hoạt động tốt nhất khi các nhà phát triển hiểu khả năng và hạn chế của chúng, và duy trì vai trò của họ là người chỉ đạo dự án và xác nhận mã.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.2-call-bedrock-converse/","title":"Thêm code gọi Converse API","tags":[],"description":"","content":"Thêm code gọi Converse API Trong bước này, bạn sẽ thêm đoạn mã Python vào Lambda Function để gửi câu hỏi đến Amazon Bedrock thông qua Converse API và trả kết quả về cho client.\nHàm Lambda sẽ thực hiện các nhiệm vụ sau:\nNhận câu hỏi từ client hoặc từ test event Tạo request theo chuẩn Converse API Gửi prompt đến Amazon Bedrock Runtime Nhận kết quả sinh bởi mô hình Trả phản hồi dạng JSON 🔹 Bước 1 — Mở file mã nguồn của Lambda Mở hàm Lambda bạn đã tạo Cuộn đến phần Code source Mở file lambda_function.py 🔹 Bước 2 — Thay toàn bộ nội dung bằng đoạn mã sau import json import boto3 # Tạo client để gọi Bedrock Runtime bedrock = boto3.client(\u0026#34;bedrock-runtime\u0026#34;) # Chọn mô hình hỗ trợ Converse API MODEL_ID = \u0026#34;anthropic.claude-3-sonnet-20240229\u0026#34; def lambda_handler(event, context): # Nhận dữ liệu từ API Gateway hoặc test event body = json.loads(event.get(\u0026#34;body\u0026#34;, \u0026#34;{}\u0026#34;)) if isinstance(event.get(\u0026#34;body\u0026#34;), str) else event question = body.get(\u0026#34;question\u0026#34;, \u0026#34;Xin chào! Bạn muốn hỏi gì?\u0026#34;) # Gửi yêu cầu đến Bedrock bằng Converse API response = bedrock.converse( modelId=MODEL_ID, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;text\u0026#34;: question} ] } ] ) # Lấy nội dung trả lời từ output answer = response[\u0026#34;output\u0026#34;][\u0026#34;message\u0026#34;][\u0026#34;content\u0026#34;][0][\u0026#34;text\u0026#34;] # Trả kết quả cho client return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;headers\u0026#34;: {\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;}, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;answer\u0026#34;: answer}) } 🔹 Lưu ý quan trọng về MODEL_ID Biến MODEL_ID trong file lambda_function.py có thể được thay đổi tùy theo mô hình bạn muốn sử dụng.\nTuy nhiên, mô hình đó phải hỗ trợ Converse API.\nĐể xem model ID chính xác:\nMở Amazon Bedrock Console → Model catalog Chọn mô hình bạn muốn dùng Ở khung thông tin mô hình, bạn sẽ thấy phần Model ID Ví dụ minh họa:\nHãy copy đúng Model ID này và dán vào biến:\nMODEL_ID = \u0026#34;model-id-ban-chon-tu-bedrock\u0026#34; Nếu mô hình không hỗ trợ Converse API, bạn sẽ gặp lỗi khi Lambda gọi bedrock.converse().\n🔹 Bước 3 — Deploy Lambda Sau khi cập nhật mã:\nNhấn Deploy Lambda Function giờ đã sẵn sàng để thực hiện gọi mô hình Bedrock 🎯 Kết quả mong đợi Sau bước này, Lambda Function của bạn có thể:\nNhận câu hỏi từ người dùng Gửi prompt đến Bedrock qua Converse API Nhận phản hồi từ mô hình Trả kết quả dưới dạng JSON Bạn đã hoàn thành phần quan trọng nhất của dịch vụ AI Q\u0026amp;A.\nTiếp tục xem phần 5.3.3 – Kiểm thử Lambda Function.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.2-week2/","title":"Tuần 2 - Dịch vụ Mạng trên AWS","tags":[],"description":"","content":"Tuần: 2025-09-15 đến 2025-09-19\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 2 Tuần này đào sâu các dịch vụ mạng của AWS, từ VPC cơ bản đến giải pháp kết nối nâng cao và cân bằng tải.\nNội dung chính Amazon VPC và Subnet. Security Group và Network ACL. Internet Gateway, NAT Gateway. VPC Peering và AWS Transit Gateway. Elastic Load Balancing (ALB, NLB, GWLB). Labs thực hành Lab 03: Amazon VPC \u0026amp; Networking Basics. Lab 10: Hybrid DNS (Route 53 Resolver). Lab 19: VPC Peering. Lab 20: AWS Transit Gateway. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Migrating from AWS CodeDeploy to Amazon ECS for blue/green deployments Blog này giới thiệu cách di chuyển từ AWS CodeDeploy sang phương pháp triển khai blue/green của Amazon ECS. Nội dung giải thích rằng ECS hiện đã hỗ trợ triển khai blue/green một cách nguyên bản, giúp loại bỏ sự cần thiết của CodeDeploy. Các ưu điểm chính bao gồm hỗ trợ cho ECS ServiceConnect, dịch vụ không định danh (headless services), ổ đĩa Amazon EBS, và nhiều nhóm mục tiêu (multiple target groups).\nBài viết cũng trình bày chi tiết về sự khác biệt giữa API, CLI, và giao diện console, cách ánh xạ các hook vòng đời (lifecycle hook), và các biến thể trong luồng triển khai.\nBa Phương Án Di Chuyển 📝 Dưới đây là ba phương án di chuyển được đề xuất:\nCập nhật tại chỗ (In-place update) Mô tả: Đơn giản nhất, không có thời gian chết (downtime). Dịch vụ mới sử dụng bộ cân bằng tải hiện có (New service using existing load balancer) Mô tả: An toàn hơn, gián đoạn tối thiểu. Dịch vụ mới với bộ cân bằng tải mới (New service with new load balancer) Mô tả: Hoàn toàn không có thời gian chết, nhưng chi phí cao hơn. Blog 2 - Break down data silos and seamlessly query Iceberg tables in Amazon SageMaker from Snowflake Blog này hướng dẫn cách truy vấn trực tiếp các bảng Apache Iceberg trong lakehouse của Amazon SageMaker từ Snowflake, giúp bạn phân tích dữ liệu hợp nhất mà không cần sao chép hay thực hiện quy trình ETL (Extract, Transform, Load).\nCách Hoạt Động \u0026amp; Bảo Mật 🔐 Sử dụng AWS Glue Data Catalog, Lake Formation, và điểm cuối REST của Glue Iceberg, người dùng Snowflake có thể truy vấn an toàn dữ liệu được lưu trữ trong Amazon S3.\nCơ chế tích hợp này đảm bảo truy cập an toàn thông qua việc cấp phát thông tin xác thực qua Lake Formation và xác thực SigV4.\nLợi Ích \u0026amp; Các Bước Thực Hiện Giải pháp này cho phép phân tích liền mạch giữa các nền tảng, giúp cải thiện khả năng truy cập dữ liệu, tính nhất quán, và hiệu quả về chi phí.\nBài hướng dẫn cũng vạch ra các điều kiện tiên quyết, cách thiết lập IAM và Lake Formation, cùng các bước tích hợp catalog trong Snowflake. Mục tiêu cuối cùng là giúp các tổ chức phá vỡ các rào cản dữ liệu (data silos) và tăng cường khả năng ra quyết định trong toàn bộ hệ sinh thái dữ liệu của mình.\nBlog 3 - Navigating Amazon GuardDuty protection plans and Extended Threat Detection Blog này giới thiệu về Amazon GuardDuty, dịch vụ giám sát bảo mật của AWS nay đã được nâng cấp với một bộ Gói Bảo Vệ (Protection Plans) và tính năng Phát Hiện Mối Đe Dọa Mở Rộng (Extended Threat Detection - ETD).\nCác Gói Bảo Vệ Chuyên Sâu 🛡️ Các gói bảo vệ mở rộng phạm vi giám sát đến các dịch vụ cụ thể—bao gồm S3, EKS, EC2, ECS, Lambda, RDS, và nhiều dịch vụ khác—nhằm phát hiện các mối đe dọa như phần mềm độc hại (malware), leo thang đặc quyền, và trích xuất dữ liệu trái phép.\nGuardDuty cũng đưa ra đề xuất kết hợp các gói bảo vệ phù hợp nhất tùy theo loại workload (EC2, container, serverless, cơ sở dữ liệu, hoặc môi trường có quy định nghiêm ngặt).\nPhát Hiện Mối Đe Dọa Mở Rộng (ETD) 🧠 Tính năng ETD tận dụng AI/ML để tương quan các sự kiện trên nhiều dịch vụ, từ đó xác định các cuộc tấn công đa giai đoạn với độ tin cậy cao và ánh xạ chúng tới các chiến thuật của MITRE ATT\u0026amp;CK.\nLợi Ích Chính ✅ Sự kết hợp của các tính năng này mang lại khả năng phát hiện mối đe dọa toàn diện, tự động và cung cấp thông tin chi tiết có thể hành động (actionable insights), giúp bảo vệ các workload trên AWS với chi phí vận hành tối thiểu.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.3-create-lambda-and-bedrock-call/5.3.3-test-lambda/","title":"Kiểm thử Lambda Function","tags":[],"description":"","content":"Kiểm thử Lambda Function Sau khi đã tạo Lambda Function và thêm code gọi Amazon Bedrock bằng Converse API, bước tiếp theo là kiểm thử để đảm bảo hàm hoạt động đúng.\nTrong phần này, bạn sẽ:\nTạo một test event trong Lambda Console Gửi thử một câu hỏi đến mô hình Bedrock Xem kết quả trả về và kiểm tra log nếu có lỗi 🔹 Bước 1 — Mở Lambda và tạo test event Vào AWS Lambda Console Chọn hàm: bedrock-chatbot-lambda Nhấn nút Test Chọn Create new event nếu đây là lần đầu test Đặt tên event, ví dụ: Event name: test-bedrock-converse Tại mục cấu hình event, kéo xuống phần JSON và thay toàn bộ nội dung bằng:\n{ \u0026#34;question\u0026#34;: \u0026#34;Amazon Bedrock là gì?\u0026#34; } Ví dụ minh họa:\nNhấn Save để lưu test event.\n🔹 Bước 2 — Chạy test và xem kết quả Chọn event bạn vừa tạo Nhấn Test Nếu Lambda hoạt động đúng, bạn sẽ thấy phản hồi dạng:\n{ \u0026#34;answer\u0026#34;: \u0026#34;Amazon Bedrock is a fully managed service...\u0026#34; } Trường \u0026quot;answer\u0026quot; chính là nội dung mô hình Bedrock trả về.\n🔹 Bước 3 — Kiểm tra log nếu có lỗi Nếu Lambda trả về lỗi hoặc không chạy như mong đợi:\nChọn tab Monitor Nhấn View logs in CloudWatch Mở log stream mới nhất Một số lỗi phổ biến:\n❌ AccessDeniedException Nguyên nhân: Role Lambda thiếu quyền bedrock:InvokeModel Cách xử lý: Kiểm tra lại IAM Role ở phần Prerequisites ❌ Timeout Nguyên nhân: Lambda timeout mặc định 3 giây quá thấp Cách xử lý: Vào Configuration → General tăng timeout lên 10–20 giây ❌ KeyError hoặc rỗng input Nguyên nhân: Payload không chứa \u0026quot;question\u0026quot; Cách xử lý: Đảm bảo JSON gửi vào đúng format: { \u0026#34;question\u0026#34;: \u0026#34;Nội dung câu hỏi\u0026#34; } 🎯 Kết quả mong đợi Sau phần này, bạn sẽ:\nKiểm chứng được Lambda có thể gọi Bedrock thành công Nhận phản hồi từ mô hình qua Converse API Xác nhận IAM Role và MODEL_ID hoạt động đúng Sẵn sàng triển khai bước tiếp theo: tạo API endpoint "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.1-week1/1.1.3-day03-2025-09-10/","title":"Ngày 03 - Công cụ Quản lý AWS","tags":[],"description":"","content":"Ngày: 2025-09-10 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bộ công cụ quản trị AWS AWS Management Console Đăng nhập bằng Root User hoặc IAM User (cần ID tài khoản 12 chữ số). Tìm kiếm và mở dashboard của từng dịch vụ. Support Center cho phép tạo ticket hỗ trợ trực tiếp. AWS Command Line Interface (CLI) Công cụ dòng lệnh mã nguồn mở tương tác với dịch vụ AWS. Cung cấp tính năng tương đương Console. Đặc điểm chính:\nHỗ trợ đa nền tảng (Windows, macOS, Linux). Dễ script và tự động hóa. Truy cập trực tiếp API dịch vụ AWS. Quản lý nhiều tài khoản thông qua profiles. AWS SDK (Software Development Kit) Đơn giản hóa việc tích hợp dịch vụ AWS vào ứng dụng. Tự động xử lý xác thực, retry và tuần tự hóa dữ liệu. Ngôn ngữ hỗ trợ:\nPython (Boto3) JavaScript/Node.js Java .NET Ruby, PHP, Go và các ngôn ngữ khác "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.2-week2/1.2.3-day08-2025-09-17/","title":"Ngày 08 - Bảo mật VPC &amp; Flow Logs","tags":[],"description":"","content":"Ngày: 2025-09-17 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bảo mật VPC Security Group (SG) Tường lửa ảo stateful kiểm soát lưu lượng vào/ra tài nguyên AWS. Quy tắc dựa trên giao thức, cổng, nguồn hoặc security group khác. Chỉ hỗ trợ rule cho phép (allow). Áp dụng ở cấp độ Elastic Network Interface (ENI). Đặc điểm của Security Group:\nStateful: lưu lượng trả về được cho phép tự động. Chỉ có rule cho phép. Đánh giá toàn bộ rule trước khi quyết định. Áp dụng ở mức instance/ENI. Network Access Control List (NACL) Tường lửa ảo stateless hoạt động ở cấp subnet. Quy tắc điều khiển lưu lượng vào/ra theo giao thức, cổng và nguồn. NACL mặc định cho phép tất cả lưu lượng. Đặc điểm của NACL:\nStateless: phải cho phép rõ ràng lưu lượng chiều về. Hỗ trợ cả rule allow và deny. Các rule được xử lý theo thứ tự số. Áp dụng ở mức subnet. VPC Flow Logs Ghi nhận metadata về lưu lượng IP đi/đến các network interface trong VPC. Log có thể gửi tới Amazon CloudWatch Logs hoặc S3. Flow Logs không ghi phần payload của gói tin. Trường hợp sử dụng:\nKhắc phục sự cố kết nối. Theo dõi mẫu lưu lượng. Phân tích bảo mật. Đáp ứng yêu cầu tuân thủ. Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking (tiếp) Khởi chạy EC2 trong các subnet → 04-1 Kiểm tra kết nối giữa các instance → 04-2 Tạo NAT Gateway (Private ↔ Internet) → 04-3 EC2 Instance Connect Endpoint (không cần bastion) → 04-5 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.3-week3/1.3.3-day13-2025-09-24/","title":"Ngày 13 - Instance Store &amp; User Data","tags":[],"description":"","content":"Ngày: 2025-09-24 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Tính năng nâng cao của EC2 Instance Store Instance Store cung cấp lưu trữ block tạm thời gắn trực tiếp vào host EC2. Đặc điểm\nI/O và thông lượng rất cao. Dữ liệu mất khi instance dừng hoặc terminate. Không thể tách rời hoặc tạo snapshot. Tình huống sử dụng\nCache hoặc xử lý dữ liệu tạm. Ứng dụng đã có cơ chế nhân bản/replication riêng. So sánh Instance Store và EBS:\nTiêu chí Instance Store EBS Tính bền vững Tạm thời Bền vững Hiệu năng Rất cao Cao Snapshot Không Có Tháo rời Không Có Chi phí Đã bao gồm Tính riêng User Data Script User Data chạy tự động khi instance khởi tạo (mỗi lần provision AMI). Linux dùng bash script, Windows dùng PowerShell. Ví dụ User Data:\n#!/bin/bash yum update -y yum install -y httpd systemctl start httpd systemctl enable httpd echo \u0026#34;\u0026lt;h1\u0026gt;Hello from $(hostname -f)\u0026lt;/h1\u0026gt;\u0026#34; \u0026gt; /var/www/html/index.html Metadata EC2 Instance Metadata cung cấp thông tin về instance đang chạy như IP private/public, hostname, security group. Thường dùng trong User Data để cấu hình động. Truy cập Metadata:\n# Lấy instance ID curl http://169.254.169.254/latest/meta-data/instance-id # Lấy public IP curl http://169.254.169.254/latest/meta-data/public-ipv4 # Lấy credential IAM role curl http://169.254.169.254/latest/meta-data/iam/security-credentials/role-name Hands-On Labs Lab 07 – AWS Budgets \u0026amp; Cost Management Tạo Budget từ template → 07-01 Hướng dẫn tạo Cost Budget → 07-02 Tạo Usage Budget → 07-03 Tạo Budget cho Reserved Instance → 07-04 Tạo Budget cho Savings Plans → 07-05 Dọn dẹp Budget → 07-06 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.4-week4/1.4.3-day18-2025-10-01/","title":"Ngày 18 - AWS Snow Family &amp; Hybrid Storage","tags":[],"description":"","content":"Ngày: 2025-10-01 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Snow Family Bộ thiết bị/dịch vụ chuyên dụng để di chuyển khối lượng dữ liệu lớn vào/ra AWS khi băng thông hạn chế hoặc dữ liệu quá khủng.\nAWS Snowcone: Thiết bị nhỏ gọn, chịu va đập (~8 TB). Phù hợp môi trường edge, vùng xa. AWS Snowball: Snowball Edge Storage Optimized: Tối đa ~80 TB lưu trữ khả dụng. Snowball Edge Compute Optimized: Thêm khả năng compute mạnh với ~42 TB lưu trữ. AWS Snowmobile: Trung tâm dữ liệu container hóa, phục vụ chuyển dữ liệu quy mô exabyte (tới 100 PB). So sánh Snow Family:\nThiết bị Lưu trữ Compute Use case Snowcone 8 TB 2 vCPU Edge, IoT Snowball Storage 80 TB 40 vCPU Di chuyển dữ liệu Snowball Compute 42 TB 52 vCPU Edge computing Snowmobile 100 PB N/A Di dời datacenter Khi nào dùng Snow Family:\nBăng thông hạn chế hoặc chi phí cao. Khối lượng dữ liệu rất lớn (TB tới PB). Địa điểm xa xôi, khó kết nối. Nhu cầu xử lý edge computing. Yêu cầu tuân thủ lưu trữ dữ liệu tại chỗ. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.5-week5/1.5.3-day23-2025-10-08/","title":"Ngày 23 - Amazon Cognito &amp; Organizations","tags":[],"description":"","content":"Ngày: 2025-10-08 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon Cognito Dịch vụ managed cho xác thực/ủy quyền và quản lý người dùng cho web \u0026amp; mobile. Thành phần: User Pools: Thư mục người dùng phục vụ đăng ký/đăng nhập. Identity Pools: Danh tính liên kết (federated) cung cấp credential tạm thời để truy cập dịch vụ AWS. Tính năng của Cognito User Pools:\nĐăng ký và đăng nhập. Hỗ trợ IdP xã hội (Google, Facebook, Amazon). Hỗ trợ IdP SAML. Multi-factor authentication (MFA). Xác thực email và số điện thoại. Tùy biến luồng đăng nhập. Lambda trigger để mở rộng logic. Tính năng của Cognito Identity Pools:\nCredential AWS tạm thời. Phân biệt truy cập authenticated và unauthenticated. Kiểm soát truy cập dựa trên role. Tích hợp với User Pool. Hỗ trợ IdP bên ngoài. AWS Organizations Quản lý tập trung nhiều tài khoản AWS trong một tổ chức. Lợi ích\nQuản lý tài khoản tập trung. Consolidated Billing. Cấu trúc phân cấp bằng Organizational Unit (OU). Thiết lập guardrail bằng Service Control Policy (SCP). Organizational Unit (OU) Gom tài khoản theo phòng ban, dự án hoặc môi trường; có thể lồng OUs để áp policy theo tầng. Ví dụ cấu trúc OU:\nRoot ├── Production OU │ ├── Web App Account │ └── Database Account ├── Development OU │ ├── Dev Account │ └── Test Account └── Security OU └── Audit Account Consolidated Billing Một hóa đơn cho mọi tài khoản; hưởng lợi từ volume pricing; không phát sinh phí thêm. Lợi ích:\nGiảm giá theo khối lượng dùng chung giữa các tài khoản. Dễ theo dõi và lập báo cáo. Đơn giản hóa phương thức thanh toán. Chia sẻ Reserved Instance. Hands-On Labs Lab 28 – IAM Cross-Region Role \u0026amp; Policy (Phần 2) Switch Role → 28-5.1 Truy cập EC2 Console – Tokyo → 28-5.2.1 Truy cập EC2 Console – N. Virginia → 28-5.2.2 Tạo EC2 (không đáp ứng tag) → 28-5.2.3 Chỉnh sửa tag tài nguyên EC2 → 28-5.2.4 Kiểm tra chính sách → 28-5.2.5 Lab 27 – AWS Resource Groups \u0026amp; Tagging (Phần 1) Tạo EC2 Instance kèm Tag → 27-2.1.1 Quản lý tag cho tài nguyên AWS → 27-2.1.2 Lọc tài nguyên theo tag → 27-2.1.3 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.6-week6/1.6.3-day28-2025-10-15/","title":"Ngày 28 - Amazon Redshift","tags":[],"description":"","content":"Ngày: 2025-10-15 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon Redshift Dịch vụ data warehouse fully-managed tối ưu cho workload phân tích quy mô lớn (OLAP).\nLưu trữ dạng cột, nén dữ liệu, thực thi song song MPP; mở rộng từ hàng trăm GB tới hàng PB. Tích hợp sâu với S3, Kinesis, DynamoDB, các công cụ BI; hỗ trợ nhiều lớp bảo mật. Concurrency Scaling tự động bổ sung compute khi lưu lượng tăng đột biến. Kiến trúc: cluster gồm leader node + compute nodes; mỗi compute node chia thành nhiều slice. Tùy chọn triển khai:\nRedshift Provisioned Redshift Serverless Redshift Spectrum (truy vấn trực tiếp dữ liệu trên S3) Use case: BI doanh nghiệp, phân tích data lake, dashboard, phân tích xu hướng và dự báo.\nTính năng nổi bật:\nLưu trữ dạng cột: phù hợp truy vấn phân tích. Massively Parallel Processing: phân tán truy vấn trên nhiều node. Result Caching: tăng tốc truy vấn lặp lại. Automatic Compression: giảm dung lượng lưu trữ. Workload Management (WLM): ưu tiên truy vấn quan trọng. Concurrency Scaling: xử lý workload bùng nổ. Redshift vs Data Warehouse truyền thống:\nTiêu chí Redshift DW truyền thống Thiết lập Vài phút Vài tuần/tháng Mở rộng Elastic Cố định Chi phí Pay-as-you-go Đầu tư lớn ban đầu Vận hành Managed Tự quản lý Redshift Spectrum:\nTruy vấn trực tiếp dữ liệu trên S3 mà không cần load. Tách biệt compute và storage. Hỗ trợ nhiều định dạng (Parquet, ORC, JSON\u0026hellip;). Tiết kiệm chi phí cho dữ liệu truy cập không thường xuyên. Labs thực hành Lab 43 – AWS Database Migration Service (DMS) (Phần 2) Cấu hình đích MSSQL → Aurora MySQL → 43-07 Tạo project MSSQL → Aurora MySQL → 43-08 Convert schema MSSQL → Aurora MySQL → 43-09 Convert schema Oracle → MySQL (1) → 43-10 Tạo migration task \u0026amp; endpoints → 43-11 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.7-week7/1.7.3-day33-2025-10-22/","title":"Ngày 33 - Next.js App Router","tags":[],"description":"","content":"Ngày: 2025-10-22 (Thứ Tư)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Next.js 16 App Router Tận dụng Server Components để fetch data trực tiếp từ server và tránh bundle dư thừa. Route /app/books/[id]/page.tsx lo việc fetch dữ liệu, trả về UI đã render sẵn. generateMetadata giúp bổ sung meta SEO dựa trên dữ liệu sách. // app/books/[id]/page.tsx import { getBook } from \u0026#34;@/lib/api\u0026#34;; export default async function BookDetail({ params }) { const book = await getBook(params.id); if (!book) return notFound(); return \u0026lt;BookPage book={book} /\u0026gt;; } Xử lý lỗi \u0026amp; not-found Chỉ cần not-found.tsx cho trường hợp không tìm được sách → coi là flow dự kiến. Không dùng error.tsx để tránh xử lý trùng; các lỗi còn lại sẽ được log ở backend. Giữ UX đồng nhất: hiển thị CTA quay về danh sách và hotline hỗ trợ. Environment \u0026amp; Config Sử dụng biến môi trường rõ ràng: NEXT_PUBLIC_API_URL cho frontend, API_URL cho route handler. Luôn cập nhật .env.example khi thêm biến mới. Gom logic build URL vào helper lib/api.ts để tránh lặp code. Insight Server Components giảm đáng kể latency khi render trang chi tiết. App Router giúp cấu trúc thư mục rõ ràng, dễ mở rộng thêm slice mới. Khi dùng mock API, chỉ cần đổi base URL để fetch từ Prism. Labs thực hành Tạo not-found.tsx tùy biến với CTA điều hướng. Viết helper getBook(id) tái sử dụng cho Server Components và tests. Chạy npm run lint \u0026amp;\u0026amp; npm run build để chắc cấu hình Next.js sạch. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.8-week8/1.8.3-day38-2025-10-29/","title":"Ngày 38 - Mô Hình Seq2seq &amp; LSTM Chi Tiết","tags":[],"description":"","content":"Ngày: 2025-10-29 (Thứ Tư)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nMô Hình Seq2seq Mô hình Sequence-to-Sequence (Seq2seq) giới thiệu kiến trúc encoder-decoder hiệu quả cho các tác vụ như dịch máy và tóm tắt văn bản.\nĐặc Điểm Chính: Ánh xạ chuỗi có độ dài thay đổi thành bộ nhớ có độ dài cố định Đầu vào và đầu ra có thể có độ dài khác nhau Sử dụng LSTM và GRU để tránh vanishing và exploding gradients Encoder nhận token từ làm đầu vào → các vector trạng thái ẩn → decoder tạo ra chuỗi đầu ra Kiến Trúc LSTM: Tìm Hiểu Sâu LSTM là gì? LSTM (Long Short-Term Memory) giống như phiên bản mini của não người khi xử lý trí nhớ.\nCấu Trúc LSTM = 3 Cổng + 1 Trạng Thái Tế Bào 1. Cổng Quên – Quyết Định Quên Gì Quyết định thông tin nào cần loại bỏ khỏi trạng thái cũ.\nCông thức:\nf_t = σ(W_f · [h_{t-1}, x_t] + b_f) Ví dụ não người:\nTin nhắn vô ích từ người đã ghosting bạn → quên Công thức bạn dùng hàng ngày → giữ 2. Cổng Đầu Vào – Quyết Định Nhớ Gì Quyết định thông tin mới nào cần thêm vào bộ nhớ.\nCông thức:\ni_t = σ(W_i · [h_{t-1}, x_t] + b_i) Ĉ_t = tanh(W_C · [h_{t-1}, x_t] + b_C) Ví dụ não người:\nThông tin có giá trị → lưu vào trí nhớ dài hạn Nhiễu không liên quan → loại bỏ ngay lập tức 3. Cập Nhật Trạng Thái Tế Bào – Trí Nhớ Dài Hạn Cập nhật trí nhớ dài hạn bằng cách kết hợp cổng quên và cổng đầu vào.\nCông thức:\nC_t = f_t ⊙ C_{t-1} + i_t ⊙ Ĉ_t Trong đó:\nf_t ⊙ C_{t-1} = những gì cần giữ từ trí nhớ cũ i_t ⊙ Ĉ_t = những gì cần thêm từ đầu vào mới 4. Cổng Đầu Ra – Quyết Định Xuất Ra Gì Quyết định trí nhớ nào sử dụng cho đầu ra hiện tại.\nCông thức:\no_t = σ(W_o · [h_{t-1}, x_t] + b_o) h_t = o_t ⊙ tanh(C_t) Ví dụ não người:\nKhi thi NLP → nhớ lại công thức LSTM Khi nói chuyện với ai đó → nhớ ngữ cảnh cuộc trò chuyện Khi làm DevOps → nhớ thông số AWS LSTM vs Não Người Não Người LSTM Trí nhớ dài hạn Cell State Lọc thông tin không cần thiết Forget Gate Chấp nhận thông tin mới có giá trị Input Gate Truy xuất trí nhớ phù hợp để phản hồi Output Gate Học từ kinh nghiệm tuần tự RNN backbone Không quên nhanh Long-term dependencies Cổng là gì? Cổng = bộ lọc nhận thức\nMỗi cổng = một cơ chế quyết định \u0026ldquo;giữ hay bỏ\u0026rdquo;\nVí dụ: Khi Bạn Học NLP Cổng Quên: \u0026ldquo;Tôi còn cần nhớ phương pháp lỗi thời này không?\u0026rdquo; → Bỏ nếu không Cổng Đầu Vào: \u0026ldquo;Khái niệm mới này có giá trị không?\u0026rdquo; → Lưu nếu có Cổng Đầu Ra: \u0026ldquo;Tôi cần kiến thức gì ngay bây giờ?\u0026rdquo; → Truy xuất phần liên quan Giới Hạn Hidden State Hidden state không có giới hạn token, nhưng có giới hạn khả năng nhớ hiệu quả.\nGóc Độ Toán Học: Hidden state = vector có kích thước cố định (ví dụ: 128, 256, 512 chiều) Có thể xử lý 10 token hoặc 10.000 token → không bị crash Vấn đề: không thể nhớ mọi thứ Tại Sao? Ngay cả với cell state, gradient suy yếu qua nhiều bước thời gian Các phụ thuộc dài hạn bị mất Các token xa điểm bắt đầu có ảnh hưởng yếu đến đầu ra cuối cùng Giải pháp: Đây là lý do chúng ta cần cơ chế Attention!\nThrottling trong NLP Hai Nghĩa của Throttling: 1. Throttling Cấp Hệ Thống (API) Giới hạn tốc độ request hoặc xử lý token để:\nBảo vệ tài nguyên GPU Phân phối tài nguyên công bằng Tránh quá tải server Kiểm soát chi phí Ví dụ:\nOpenAI GPT: 10 requests/giây, 90k tokens/phút Anthropic Claude: 20 requests/giây HuggingFace: timeout nếu generation mất quá lâu 2. Throttling Cấp Mô Hình (Kiến Trúc) LSTM, Transformer và Attention đều có cơ chế giới hạn xử lý thông tin tại bất kỳ thời điểm nào:\n(A) LSTM Throttling → Cổng Quên Khi chuỗi quá dài:\nCổng quên tự động \u0026ldquo;throttle\u0026rdquo; thông tin cũ Chỉ cho phép một phần ý nghĩa đi qua Giống throttling mạng: \u0026ldquo;quá tải → giảm băng thông → bỏ packet\u0026rdquo; (B) Transformer Throttling → Giới Hạn Context Window\nBERT: 512 tokens GPT-3: 2048-4096 tokens GPT-4: 128k-1M tokens Claude 3.5 Sonnet: 200k-1M tokens Khi đầu vào vượt giới hạn:\nMô hình cắt dữ liệu Hoặc từ chối xử lý Hoặc hạ chất lượng attention (C) Attention Throttling → Sparse Attention Trong các mô hình ngữ cảnh dài (Longformer, BigBird, Mistral):\nKhông thể tính toán full n² attention Chỉ chú ý đến các vùng quan trọng (local attention) Hoặc global tokens Hoặc sliding window (D) Token Generation Throttling Một số decoder sẽ:\nLàm chậm tốc độ sinh token Giới hạn sampling Áp dụng kiểm soát nhiệt độ Cắt beam search Khi đầu vào nhiễu hoặc không chắc chắn, điều này hoạt động như phanh: \u0026ldquo;Không chắc → làm chậm generation → tăng chất lượng\u0026rdquo;\nTóm Tắt LSTM không chỉ là một mô hình — nó là sự bắt chước tính toán cách trí nhớ con người hoạt động. Hiểu các cổng giúp bạn hiểu tại sao một số thông tin tồn tại trong khi thông tin khác biến mất.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/1.9.3-day43-2025-11-05/","title":"Ngày 43 - Sâu Hơn Về Scaled Dot-Product Attention","tags":[],"description":"","content":"Ngày: 2025-11-05 (Thứ Tư)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nScaled Dot-Product Attention: Cơ Chế Lõi Đây là tim và linh hồn của transformers. Hiểu biết sâu về điều này là rất quan trọng.\nCông Thức Attention (Q × K^T) Attention(Q, K, V) = softmax(─────────) × V √(d_k) Trong đó:\nQ = ma trận Query (chúng ta đang tìm kiếm cái gì?) K = ma trận Key (chúng ta có thể attend tới cái gì?) V = ma trận Value (chúng ta nhận được thông tin gì?) d_k = chiều của keys (thường là 64) Tính Toán Từng Bước Hãy tính toán attention cho một ví dụ đơn giản:\nCâu Đầu Vào: \u0026ldquo;I am happy\u0026rdquo;\nGiai Đoạn Thiết Lập Bước 1: Tạo Word Embeddings\nI: [0.1, 0.2, 0.3] am: [0.4, 0.5, 0.6] happy: [0.7, 0.8, 0.9] Bước 2: Chuyển Đổi Thành Q, K, V Trong thực tế, chúng ta học các phép chiếu tuyến tính:\nQ = Embedding × W_q K = Embedding × W_k V = Embedding × W_v Để đơn giản, hãy nói rằng:\nQ = [0.1, 0.2, 0.3] K = [0.1, 0.2, 0.3] V = [0.1, 0.2, 0.3] [0.4, 0.5, 0.6] [0.4, 0.5, 0.6] [0.4, 0.5, 0.6] [0.7, 0.8, 0.9] [0.7, 0.8, 0.9] [0.7, 0.8, 0.9] (Trong thực tế, Q, K, V sẽ là các phép chiếu khác nhau, nhưng điều này cho thấy khái niệm)\nGiai Đoạn Tính Toán Bước 3: Tính Q × K^T (dot products)\nQ × K^T = [0.1, 0.2, 0.3] [0.1, 0.4, 0.7] [0.4, 0.5, 0.6] × [0.2, 0.5, 0.8] [0.7, 0.8, 0.9] [0.3, 0.6, 0.9] Q₁·K₁ = 0.1×0.1 + 0.2×0.2 + 0.3×0.3 = 0.01 + 0.04 + 0.09 = 0.14 Q₁·K₂ = 0.1×0.4 + 0.2×0.5 + 0.3×0.6 = 0.04 + 0.10 + 0.18 = 0.32 Q₁·K₃ = 0.1×0.7 + 0.2×0.8 + 0.3×0.9 = 0.07 + 0.16 + 0.27 = 0.50 Ma trận kết quả: [0.14, 0.32, 0.50] [0.32, 0.77, 1.22] [0.50, 1.22, 1.94] Diễn Giải:\nQ₁ (query cho \u0026ldquo;I\u0026rdquo;) có điểm tương tự: [0.14, 0.32, 0.50] 0.14 với \u0026ldquo;I\u0026rdquo; chính nó 0.32 với \u0026ldquo;am\u0026rdquo; 0.50 với \u0026ldquo;happy\u0026rdquo; Bước 4: Tỷ Lệ Theo √d_k\nd_k = 3 (chiều embedding), vì vậy √d_k = √3 ≈ 1.73\nMa trận được tỷ lệ = Q×K^T / √3: [0.14/1.73, 0.32/1.73, 0.50/1.73] [0.08, 0.18, 0.29] [0.32/1.73, 0.77/1.73, 1.22/1.73] = [0.18, 0.44, 0.70] [0.50/1.73, 1.22/1.73, 1.94/1.73] [0.29, 0.70, 1.12] Tại Sao Tỷ Lệ?\nKhi d_k lớn (ví dụ: 64), dot products trở nên rất lớn Các số lớn khiến softmax có gradient rất nhỏ (bão hòa) Tỷ lệ theo √d_k giữ các số trong phạm vi hợp lý để huấn luyện Bước 5: Áp Dụng Softmax\nSoftmax chuyển đổi điểm thành xác suất (tổng bằng 1):\nsoftmax(x) = exp(x) / sum(exp(x)) Cho hàng đầu tiên [0.08, 0.18, 0.29]: exp(0.08) ≈ 1.083 exp(0.18) ≈ 1.197 exp(0.29) ≈ 1.336 Tổng ≈ 3.616 Xác suất: [1.083/3.616, 1.197/3.616, 1.336/3.616] ≈ [0.30, 0.33, 0.37] Cả ba hàng:\nTrọng số Softmax (ma trận attention): [0.30, 0.33, 0.37] [0.26, 0.37, 0.37] [0.25, 0.36, 0.39] Diễn Giải:\nTừ \u0026ldquo;I\u0026rdquo; chi 30% sự chú ý cho chính nó, 33% cho \u0026ldquo;am\u0026rdquo;, 37% cho \u0026ldquo;happy\u0026rdquo; Từ \u0026ldquo;am\u0026rdquo; chi 26% sự chú ý cho \u0026ldquo;I\u0026rdquo;, 37% cho chính nó, 37% cho \u0026ldquo;happy\u0026rdquo; Từ \u0026ldquo;happy\u0026rdquo; chi 25% cho \u0026ldquo;I\u0026rdquo;, 36% cho \u0026ldquo;am\u0026rdquo;, 39% cho chính nó Bước 6: Nhân Với Ma Trận Value (V)\nContext = Softmax_weights × V Context(cho \u0026#34;I\u0026#34;): 0.30×[0.1,0.2,0.3] + 0.33×[0.4,0.5,0.6] + 0.37×[0.7,0.8,0.9] = [0.03,0.06,0.09] + [0.13,0.17,0.20] + [0.26,0.30,0.33] = [0.42, 0.53, 0.62] Context(cho \u0026#34;am\u0026#34;): 0.26×[0.1,0.2,0.3] + 0.37×[0.4,0.5,0.6] + 0.37×[0.7,0.8,0.9] = [0.026,0.052,0.078] + [0.148,0.185,0.222] + [0.259,0.296,0.333] = [0.433, 0.533, 0.633] Context(cho \u0026#34;happy\u0026#34;): 0.25×[0.1,0.2,0.3] + 0.36×[0.4,0.5,0.6] + 0.39×[0.7,0.8,0.9] = [0.025,0.05,0.075] + [0.144,0.18,0.216] + [0.273,0.312,0.351] = [0.442, 0.542, 0.642] Ma Trận Context Đầu Ra:\n[0.42, 0.53, 0.62] [0.433, 0.533, 0.633] [0.442, 0.542, 0.642] Mỗi từ bây giờ có một vector ngữ cảnh kết hợp thông tin từ tất cả các từ được tính trọng số bằng điểm attention!\nTại Sao Scaled Dot-Product Attention? Khía Cạnh Lý Do Dot Product Thước đo tương tự hiệu quả (chỉ là phép nhân ma trận) Scaling Ngăn chặn bão hòa softmax (giữ gradient khỏe mạnh) Softmax Chuyển đổi tương tự thành trọng số chuẩn hóa [0,1] Nhân Với V Lấy thông tin thực tế (kết hợp có trọng số) Multi-Head Attention: Nhiều Quan Điểm Thay vì một đầu attention, chúng ta sử dụng h = 8 (hoặc nhiều hơn) đầu attention:\nMultiHeadAttention(Q, K, V) = Concat(Head₁, ..., Head₈) × W_o Trong đó: Head_i = Attention(Q × W_q^i, K × W_k^i, V × W_v^i) Các đầu khác nhau học các mối quan hệ khác nhau:\nĐầu 1: Mối quan hệ chủ ngữ-động từ Đầu 2: Mối quan hệ tính từ-danh từ Đầu 3: Mối quan hệ đại từ-tham chiếu Đầu 4-8: Các mô hình ngữ nghĩa khác Ví Dụ:\nCâu: \u0026#34;The quick brown fox jumps over the lazy dog\u0026#34; Đầu 1 (chủ ngữ-động từ): - \u0026#34;fox\u0026#34; → \u0026#34;jumps\u0026#34;: 0.9 - \u0026#34;dog\u0026#34; → has_property: 0.7 Đầu 2 (tính từ-danh từ): - \u0026#34;quick\u0026#34; → \u0026#34;fox\u0026#34;: 0.85 - \u0026#34;brown\u0026#34; → \u0026#34;fox\u0026#34;: 0.8 - \u0026#34;lazy\u0026#34; → \u0026#34;dog\u0026#34;: 0.9 Đầu 3 (không gian): - \u0026#34;over\u0026#34; → kết nối \u0026#34;fox\u0026#34; và \u0026#34;dog\u0026#34;: 0.8 Tất cả các quan điểm khác nhau này kết hợp lại tạo ra sự hiểu biết ngữ cảnh phong phú.\nHiệu Quả Tính Toán Tại sao scaled dot-product attention lại hiệu quả đến vậy?\nPhép Toán Ma Trận: Chỉ là phép nhân và softmax (GPU-optimized) Có Thể Song Song Hóa: Có thể xử lý toàn bộ chuỗi cùng lúc Tiết Kiệm Bộ Nhớ: Bộ nhớ O(n²) cho chuỗi độ dài n (chấp nhận được) Huấn Luyện Nhanh: GPU hiện đại có thể thực hiện hàng tỷ dot products/giây So Sánh:\nRNN: O(n) bước tuần tự → chậm Attention: O(1) độ sâu, O(n²) bộ nhớ → nhanh! Những Hiểu Biết Chính ✅ Attention được học: W_q, W_k, W_v là các tham số có thể huấn luyện ✅ Không phụ thuộc vị trí: Không có phụ thuộc tuần tự - có thể attend trên bất kỳ khoảng cách nào ✅ Có thể Diễn Giải: Có thể hình dung các từ nào attend tới từ nào ✅ Hiệu Quả: Chỉ sử dụng phép toán ma trận (GPU-friendly)\nBước Tiếp Theo Bây giờ chúng ta hiểu scaled dot-product attention, chúng ta sẽ khám phá:\nSelf-attention (query=key=value) Masked attention (decoder chỉ nhìn thấy quá khứ) Encoder-decoder attention (kết nối xuyên ngôn ngữ) Chi tiết Multi-head attention (học nhiều mô hình) "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.10-week10/1.10.3-day48-2025-11-12/","title":"Ngày 48 - BERT và ngữ cảnh hai chiều","tags":[],"description":"","content":"Ngày: 2025-11-12 (Thứ Tư)\nTrạng Thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nBERT học như thế nào BERT tiền huấn luyện với ngữ cảnh hai chiều, nên mỗi token nhìn được cả trái lẫn phải.\nMasked Language Modeling (MLM) Mask ngẫu nhiên ~15% token; dự đoán token gốc. Mục tiêu buộc embedding hiểu ngữ cảnh xung quanh. Input: learning from deep learning is like watching the sunset with my best [MASK] Target: friend Next Sentence Prediction (NSP) Nhiệm vụ: dự đoán câu B có theo sau câu A hay không. Hỗ trợ coherence mức câu, hữu ích cho QA và phân loại. Dùng cho downstream Bắt đầu từ trọng số đã pre-train. Cách A: đóng băng encoder, train head nhẹ (feature-based). Cách B: fine-tune encoder + head với learning rate nhỏ. Mẹo thực hành max_seq_length phải phù hợp dữ liệu; tài liệu dài cần chunk. Tránh quên thảm họa: unfreeze dần, lr nhỏ. Batch nhỏ? Dùng gradient accumulation để ổn định. Việc thực hành hôm nay Lập kế hoạch fine-tune BERT cho QA (dataset, max length, lr, epochs). Quyết định có đóng băng tầng thấp hay không dựa vào kích cỡ dữ liệu. Thêm checkpoint đánh giá (dev EM/F1) để dừng sớm khi overfit. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.11-week11/1.11.3-day53-2025-11-19/","title":"Ngày 53 - Hàm chạy trên LMI","tags":[],"description":"","content":"Ngày: 2025-11-19 (Thứ Tư)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nTạo và publish hàm Tạo hàm như thường, gắn capacity provider và publish version để khởi tạo instance.\nTính năng hỗ trợ Đóng gói: ZIP hoặc OCI Runtime: Java, Python, Node, .NET Layers, extensions, function URL, response streaming, durable functions Timeout 15 phút (dài hơn nếu dùng durable) Thiết lập tài nguyên Memory/CPU ảnh hưởng lựa chọn instance Có multi-concurrency mỗi instance; cân đối throughput/chi phí Nhiều hàm có thể dùng chung một provider (pool dùng chung) Quy trình Tạo capacity provider (VPC, role, rule chọn máy) Tạo function kèm ARN provider Publish version để Lambda tạo instance và deploy execution environment "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.12-week12/1.12.3-day58-2025-11-26/","title":"Ngày 58 - Vector &amp; dữ liệu riêng tư","tags":[],"description":"","content":"Ngày: 2025-11-26 (Thứ Tư)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nLưu trữ vector \u0026amp; dữ liệu tổng hợp Amazon S3 Vectors GA: tới 2B vector/index, ~100ms truy vấn, chi phí thấp hơn DB chuyên dụng Clean Rooms sinh dữ liệu tổng hợp an toàn cho ML cộng tác Cân nhắc di chuyển Kích thước index vs. store hiện tại; sharding và đặt vùng Mục tiêu độ trễ truy vấn, ước tính chi phí so với vector DB đang dùng Mẫu truy cập và bảo mật khi chia sẻ dữ liệu Việc cần làm Thiết kế POC chuyển một bộ vector sang S3 Vectors; đo hiệu năng/chi phí Xác định dataset cần synthetic để dùng chung Đặt chính sách lưu trữ/mã hóa và truy cập cho dữ liệu vector "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.3-create-lambda-and-bedrock-call/","title":"Tạo Lambda và gọi Bedrock","tags":[],"description":"","content":"Tạo Lambda và gọi Bedrock Trong phần này, bạn sẽ tạo một Lambda Function và cấu hình để gọi mô hình Amazon Bedrock thông qua Converse API.\nSơ đồ kiến trúc tổng quan đã được giới thiệu ở phần trước, và trong bước này bạn sẽ triển khai từng thành phần cần thiết để Lambda có thể gửi prompt tới Bedrock và nhận kết quả phản hồi.\nỞ các bước tiếp theo, bạn sẽ:\nTạo hàm Lambda mới Gán Execution Role đã chuẩn bị ở phần Prerequisites Viết đoạn mã đầu tiên để gọi mô hình thông qua Converse API Sau khi hoàn thành mục này, Lambda Function của bạn sẽ có thể tương tác trực tiếp với Bedrock và xử lý yêu cầu Hỏi – Đáp từ người dùng.\nNội dung Tạo Lambda Function Gán IAM Role cho Lambda Thêm code gọi Bedrock bằng Converse API "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.3-week3/","title":"Tuần 3 - Dịch vụ Compute trên AWS","tags":[],"description":"","content":"Tuần: 2025-09-22 đến 2025-09-26\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 3 Tuần này tập trung vào các dịch vụ Compute của AWS, đặc biệt là Amazon EC2 và những dịch vụ bổ trợ.\nNội dung chính Amazon EC2 và các loại instance. AMI và chiến lược sao lưu. EBS và Instance Store. EC2 Auto Scaling. Lựa chọn mô hình giá cho EC2. Amazon Lightsail, EFS, FSx. Labs thực hành Lab 01: AWS Account \u0026amp; IAM Setup. Lab 07: AWS Budgets \u0026amp; Cost Management. Lab 09: AWS Support Plans. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/4-eventparticipated/","title":"Các Sự Kiện Tham Gia","tags":[],"description":"","content":"Trong thời gian thực tập, tôi đã may mắn được tham dự nhiều sự kiện ý nghĩa, góp phần nâng cao đáng kể sự phát triển nghề nghiệp của bản thân thông qua những kiến thức sâu sắc và những trải nghiệm khó quên.\nSự Kiện 1 Tên Sự Kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nNgày \u0026amp; Giờ: 09:00 – 17:00 VNT, Thứ Năm, 18 tháng 9 năm 2025\nĐịa Điểm: Tầng 36, 2 Đường Hai Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai Trò: Người tham dự\nMô Tả: Vietnam Cloud Day 2025 là một hội nghị AWS quy mô lớn quy tụ các đại diện chính phủ, lãnh đạo AWS và các nhân vật nổi bật trong ngành để trình bày các bài phát biểu quan trọng. Sự kiện cung cấp hai track chính: phiên phát sóng trực tiếp với các bài keynote và tọa đàm về sự chuyển đổi GenAI cùng các chiến lược điều hành, kèm theo các phiên chuyên sâu đề cập đến hạ tầng dữ liệu hợp nhất cho AI/phân tích, chiến lược triển khai GenAI, quy trình phát triển được hỗ trợ bởi AI, bảo mật ứng dụng GenAI và các tác nhân AI nâng cao năng suất. Sự kiện làm nổi bật các dịch vụ mới nhất của AWS và các kế hoạch tiên tiến cho sự phát triển AI và chuyển đổi đám mây.\nKết Quả: Thu nhận kiến thức về các phương pháp triển khai AI cấp doanh nghiệp, khám phá các giải pháp AWS cho hạ tầng dữ liệu và triển khai GenAI, đồng thời nắm bắt các thực hành bảo mật tốt nhất cho ứng dụng AI và học các kỹ thuật hiện đại hóa hệ thống lỗi thời.\nSự Kiện 2 Tên Sự Kiện: AWS GenAI Builder Club - AI-Driven Development Life Cycle: Reimagining Software Engineering\nNgày \u0026amp; Giờ: 14:00 (2:00 PM), Thứ Sáu, 3 tháng 10 năm 2025\nĐịa Điểm: AWS Event Hall, L26 Tòa Nhà Bitexco, Thành phố Hồ Chí Minh\nVai Trò: Người tham dự\nMô Tả: Buổi gặp mặt AWS GenAI Builder Club này tập trung vào Vòng Đời Phát Triển Dựa trên AI (AI-DLC), nghiên cứu cách AI tạo sinh cách mạng hóa việc tạo ra phần mềm từ thiết kế ban đầu đến triển khai và bảo trì liên tục. Phiên làm việc trình diễn trực tiếp Amazon Q Developer và Kiro, minh họa cách AI có thể xử lý các tác vụ thường xuyên và giải phóng lập trình viên để tập trung vào công việc sáng tạo có giá trị cao hơn. Chương trình bao gồm các nguyên lý cơ bản AI-DLC, tính năng Amazon Q Developer và hướng dẫn tương tác Kiro.\nKết Quả: Khám phá các ứng dụng AI thực tế trong quy trình phát triển phần mềm, có được kinh nghiệm thực hành với công cụ Amazon Q Developer và Kiro, và học các phương pháp hiệu quả để tích hợp AI như đối tác cốt lõi trong quy trình phát triển nhằm tăng hiệu suất và nâng cao tiêu chuẩn mã.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.1-week1/1.1.4-day04-2025-09-11/","title":"Ngày 04 - Tối ưu Chi phí trên AWS","tags":[],"description":"","content":"Ngày: 2025-09-11 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Tối ưu chi phí trên AWS Chiến lược tối ưu chi phí Chọn đúng loại tài nguyên và Region phù hợp. Sử dụng các mô hình giá như Reserved Instances, Savings Plans, Spot Instances. Tắt hoặc lên lịch các tài nguyên không dùng. Tận dụng kiến trúc serverless để giảm chi phí vận hành. Liên tục rà soát hiệu quả chi phí bằng AWS Budgets và Cost Explorer. Gắn thẻ chi phí (Cost Allocation Tags) để theo dõi theo phòng ban. AWS Pricing Calculator calculator.aws\nTạo và chia sẻ ước tính chi phí cho các dịch vụ phổ biến. Giá thay đổi tùy Region. Tính năng chính:\nƯớc tính chi phí trước khi triển khai. So sánh giá giữa các Region. Xuất và chia sẻ bảng dự toán. Có sẵn template cho từng workload. Gói hỗ trợ AWS Support Plans Bốn cấp độ: Basic, Developer, Business, Enterprise. Có thể nâng cấp tạm thời khi gặp sự cố nghiêm trọng. So sánh các gói hỗ trợ Tính năng Basic Developer Business Enterprise Chi phí Miễn phí 29 USD/tháng 100 USD/tháng 15.000 USD/tháng Thời gian phản hồi Không áp dụng 12-24 giờ 1 giờ (khẩn) 15 phút (nghiêm trọng) Hỗ trợ kỹ thuật Diễn đàn Giờ hành chính 24/7 24/7 + TAM Hands-On Labs Lab 07 – AWS Budgets \u0026amp; Cost Management Tạo Budget từ template → 07-01 Hướng dẫn tạo Cost Budget → 07-02 Tạo Usage Budget → 07-03 Tạo Budget cho Reserved Instance (RI) → 07-04 Tạo Budget cho Savings Plans → 07-05 Dọn dẹp các Budget → 07-06 Lab 09 – AWS Support Plans Các gói hỗ trợ AWS → 09-01 Phân loại yêu cầu hỗ trợ → 09-02 Thay đổi gói hỗ trợ → 09-03 Quản lý ticket hỗ trợ → 09-04 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.2-week2/1.2.4-day09-2025-09-18/","title":"Ngày 09 - Kết nối VPC &amp; Cân bằng tải","tags":[],"description":"","content":"Ngày: 2025-09-18 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học VPC Peering \u0026amp; Transit Gateway VPC Peering Cho phép kết nối riêng tư trực tiếp giữa hai VPC mà không qua Internet. Không hỗ trợ định tuyến chuyển tiếp (transitive) và không chấp nhận CIDR trùng nhau. Hạn chế của VPC Peering:\nKhông có peering chuyển tiếp. Không được phép trùng CIDR. Mỗi VPC tối đa 125 kết nối peering. Hỗ trợ peering liên vùng (cross-region). AWS Transit Gateway (TGW) Hoạt động như một hub kết nối nhiều VPC và mạng on-premises, đơn giản hóa kiến trúc mesh phức tạp. TGW Attachment gắn các subnet thuộc một AZ cụ thể vào TGW. Các subnet trong cùng AZ có thể truy cập TGW sau khi được attach. Lợi ích của Transit Gateway:\nHub kết nối tập trung. Đơn giản hóa kiến trúc mạng. Mở rộng tới hàng nghìn VPC. Hỗ trợ peering giữa các region. VPN \u0026amp; Direct Connect Site-to-Site VPN Thiết lập kết nối IPSec bảo mật giữa data center on-premises và AWS VPC. Bao gồm: Virtual Private Gateway (VGW): endpoint đa AZ do AWS quản lý. Customer Gateway (CGW): thiết bị hoặc appliance do khách hàng quản lý. AWS Direct Connect Cung cấp đường truyền riêng giữa data center on-prem và AWS. Độ trễ điển hình: 20–30 ms. Tại Việt Nam hiện có thông qua Hosted Connection (đối tác). Có thể điều chỉnh băng thông linh hoạt. Hands-On Labs Lab 10 – Hybrid DNS (Route 53 Resolver) Tạo Key Pair → 10-02.1 Khởi tạo CloudFormation Template → 10-02.2 Cấu hình Security Group → 10-02.3 Thiết lập hệ thống DNS → 10-05 Tạo Route 53 Outbound Endpoint → 10-05.1 Tạo Resolver Rules → 10-05.2 Tạo Inbound Endpoints → 10-05.3 Lab 19 – VPC Peering Khởi tạo CloudFormation Templates → 19-02.1 Tạo Security Group → 19-02.2 Tạo EC2 instance (test peering) → 19-02.3 Tạo kết nối Peering → 19-04 Cấu hình Route Table (Cross-VPC) → 19-05 Bật Cross-Peer DNS → 19-06 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.3-week3/1.3.4-day14-2025-09-25/","title":"Ngày 14 - EC2 Auto Scaling","tags":[],"description":"","content":"Ngày: 2025-09-25 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon EC2 Auto Scaling EC2 Auto Scaling tự động điều chỉnh số lượng instance EC2 dựa trên nhu cầu. Lợi ích\nCo giãn năng lực linh hoạt. Tăng tính sẵn sàng cho ứng dụng. Tối ưu chi phí. Thành phần chính\nAuto Scaling Group (ASG): nhóm logic chứa các EC2 instance. Launch Template / Configuration: định nghĩa thông số instance. Scaling Policy: quy tắc thêm/bớt instance. Scaling Policy Simple / Step Scaling: thêm/bớt instance khi vượt ngưỡng. Target Tracking: duy trì một metric (ví dụ CPU = 50%). Scheduled Scaling: scale theo lịch định sẵn. Predictive Scaling: dùng ML dự đoán và scale chủ động. Ví dụ Target Tracking:\n{ \u0026#34;TargetTrackingScalingPolicyConfiguration\u0026#34;: { \u0026#34;PredefinedMetricSpecification\u0026#34;: { \u0026#34;PredefinedMetricType\u0026#34;: \u0026#34;ASGAverageCPUUtilization\u0026#34; }, \u0026#34;TargetValue\u0026#34;: 50.0 } } Tích hợp với Load Balancer ASG thường đi kèm Elastic Load Balancer (ELB). Instance mới sẽ tự đăng ký, instance bị hủy sẽ tự hủy đăng ký. Best practices cho Auto Scaling:\nDùng nhiều AZ để tăng độ sẵn sàng. Thiết lập cooldown hợp lý. Giám sát metric trên CloudWatch. Sử dụng lifecycle hook cho tác vụ tùy chỉnh. Kiểm thử policy trước khi đưa vào production. Các mô hình giá của EC2 On-Demand: Trả theo giờ/giây. Linh hoạt nhất nhưng chi phí cao. Reserved Instances: Cam kết 1 hoặc 3 năm để được giảm giá; gắn với loại/family cụ thể. Savings Plans: Cam kết 1 hoặc 3 năm; linh hoạt hơn giữa các family. Spot Instances: Dùng công suất dư thừa, giảm tới 90%; có thể bị thu hồi sau 2 phút báo trước. Nên kết hợp nhiều mô hình giá trong Auto Scaling Group để tối ưu chi phí.\nSo sánh giá:\nMô hình Giảm giá Linh hoạt Cam kết On-Demand 0% Cao Không Reserved 40-60% Thấp 1-3 năm Savings Plans 40-60% Trung bình 1-3 năm Spot 50-90% Thấp Không Hands-On Labs Lab 09 – AWS Support Plans Các gói hỗ trợ AWS → 09-01 Phân loại yêu cầu hỗ trợ → 09-02 Thay đổi gói hỗ trợ → 09-03 Quản lý ticket hỗ trợ → 09-04 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.4-week4/1.4.4-day19-2025-10-02/","title":"Ngày 19 - Disaster Recovery trên AWS","tags":[],"description":"","content":"Ngày: 2025-10-02 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Disaster Recovery (DR) trên AWS Disaster Recovery là quá trình khôi phục dịch vụ CNTT sau sự cố lớn (mất điện, thiên tai, phần cứng hỏng, tấn công mạng).\nRTO (Recovery Time Objective): Thời gian cần để khôi phục dịch vụ. RPO (Recovery Point Objective): Mức dữ liệu tối đa có thể mất (theo thời gian). Chiến lược DR (tăng dần theo độ phức tạp \u0026amp; chi phí) Backup \u0026amp; Restore\nChỉ lưu backup (snapshot EBS/RDS, S3/Glacier). Khôi phục hạ tầng mới khi gặp sự cố. RTO: vài giờ tới vài ngày. RPO: phụ thuộc tần suất backup. Chi phí: thấp nhất. Pilot Light\nDuy trì các dịch vụ lõi ở trạng thái thu nhỏ trên AWS. Scale lên toàn bộ sản xuất khi DR. RTO: hàng giờ. RPO: vài phút. Chi phí: trung bình. Warm Standby\nHệ thống hoàn chỉnh chạy ở quy mô giảm trên AWS. Scale lên khi failover. RTO: phút – giờ. RPO: giây – phút. Chi phí: cao hơn. Multi-Site (Active/Active hoặc Active/Passive)\nMôi trường production chạy song song giữa on-prem và AWS, hoặc giữa nhiều Region AWS. Có thể chuyển hướng traffic ngay lập tức (Route 53, Global Accelerator). RTO/RPO: gần như bằng 0. Chi phí: cao nhất. So sánh chiến lược DR:\nChiến lược RTO RPO Chi phí Độ phức tạp Backup \u0026amp; Restore Giờ – Ngày Giờ $ Thấp Pilot Light Giờ Phút $$ Trung bình Warm Standby Phút Giây $$$ Trung bình-Cao Multi-Site Giây Gần 0 $$$$ Cao Best Practices cho DR Lập kế hoạch Xác định yêu cầu RTO và RPO. Tài liệu hóa quy trình khôi phục. Nhận diện hệ thống và phụ thuộc quan trọng. Thiết lập kế hoạch truyền thông. Triển khai Tự động hóa quy trình khôi phục. Sử dụng nhiều AZ và Region. Triển khai cơ chế sao chép dữ liệu. Kiểm thử backup định kỳ. Kiểm thử Thực hiện diễn tập DR thường xuyên. Thử nghiệm quy trình khôi phục. Đo lường RTO/RPO thực tế. Cập nhật tài liệu. Hands-On Labs Lab 14 – AWS VM Import/Export (Phần 2) Import máy ảo lên AWS → 14-02.3 Deploy instance từ AMI → 14-02.4 Thiết lập ACL cho S3 Bucket → 14-03.1 Export máy ảo từ instance → 14-03.2 Dọn dẹp tài nguyên trên AWS → 14-05 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.5-week5/1.5.4-day24-2025-10-09/","title":"Ngày 24 - SCPs, Identity Center &amp; KMS","tags":[],"description":"","content":"Ngày: 2025-10-09 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Service Control Policy (SCP) Xác định quyền tối đa cho tài khoản; chỉ giới hạn chứ không cấp quyền. Áp dụng cho tài khoản hoặc OU; ảnh hưởng tất cả user/role, kể cả root; Deny ghi đè Allow. Ví dụ SCP (cấm xóa bucket):\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:DeleteBucket\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tình huống dùng SCP:\nNgăn tài khoản rời khỏi organization. Giới hạn region được phép tạo tài nguyên. Ép buộc yêu cầu mã hóa. Ngăn tắt các dịch vụ bảo mật. Bắt buộc gắn tag nhất định cho tài nguyên. Best practice:\nBắt đầu với least privilege. Thử nghiệm ở môi trường non-prod trước. Dùng explicit deny cho kiểm soát quan trọng. Ghi chú mục đích từng SCP. Rà soát và cập nhật định kỳ. AWS Identity Center (trước là AWS SSO) Tập trung hóa truy cập vào tài khoản AWS và ứng dụng bên ngoài. Nguồn danh tính: built-in, AWS Managed Microsoft AD, AD on-prem (trust/AD Connector), hoặc IdP ngoài. Permission Set định nghĩa quyền cho user/group trên tài khoản đích (Identity Center tạo IAM role tương ứng). Có thể cấp nhiều permission set cho một người dùng. Tính năng Identity Center:\nSingle sign-on cho nhiều tài khoản AWS. Tích hợp Microsoft Active Directory. Hỗ trợ SAML 2.0. MFA. Quản lý permission tập trung. Ghi log audit qua CloudTrail. AWS Key Management Service (KMS) Dịch vụ quản lý khóa bảo vệ dữ liệu, tích hợp sâu với các dịch vụ AWS và hỗ trợ audit đầy đủ. Điểm nổi bật\nTạo/quản lý khóa mà không cần tự vận hành HSM. Kiểm soát truy cập chi tiết với IAM \u0026amp; key policy; mọi thao tác được log trong CloudTrail. Các nhóm khóa\nKhóa do khách hàng quản lý (CMK), khóa do AWS quản lý và khóa thuộc AWS-owned. Loại khóa KMS:\nSymmetric: Một khóa duy nhất để mã hóa/giải mã (AES-256). Asymmetric: Cặp khóa public/private (RSA, ECC). Tính năng KMS:\nTự động xoay vòng khóa. Key policy và grant. Envelope encryption. Tích hợp với dịch vụ AWS. Log CloudTrail. Khóa multi-region. Hands-On Labs Lab 33 – AWS KMS \u0026amp; CloudTrail Integration (Phần 1) Tạo Policy và Role → 33-2.1 Tạo Group và User → 33-2.2 Tạo KMS Key → 33-3 Tạo S3 Bucket → 33-4.1 Upload dữ liệu lên S3 → 33-4.2 Lab 30 – IAM Restriction Policy Tạo Restriction Policy → 30-3 Tạo IAM Limited User → 30-4 Kiểm tra giới hạn của IAM User → 30-5 Dọn dẹp tài nguyên → 30-6 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.6-week6/1.6.4-day29-2025-10-16/","title":"Ngày 29 - Amazon ElastiCache","tags":[],"description":"","content":"Ngày: 2025-10-16 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon ElastiCache Dịch vụ cache in-memory managed cho Redis và Memcached giúp giảm độ trễ và giảm tải database.\nĐộ trễ micro giây, Multi-AZ với failover, scale đơn giản, tích hợp mã hóa/xác thực, vận hành tự động. Redis: hỗ trợ cấu trúc dữ liệu phong phú, backup, replication, cluster mode. Memcached: cache key-value đơn giản, mở rộng ngang với auto-discovery. Use case điển hình: tăng tốc web/mobile, cache truy vấn DB, session store, leaderboard, pub/sub, queue.\nElastiCache for Redis – điểm nổi bật:\nCấu trúc dữ liệu: strings, lists, sets, sorted sets, hashes, bitmap, hyperloglog. Persistence: snapshot và AOF. Replication: mô hình primary-replica tự failover. Cluster Mode: phân mảnh dữ liệu trên nhiều shard. Pub/Sub: nhắn tin thời gian thực. Lua Scripting: chạy logic phía server. Geospatial: truy vấn tọa độ. ElastiCache for Memcached – điểm nổi bật:\nMulti-threaded: tận dụng đa lõi. Auto Discovery: client tự nhận node mới. Horizontal Scaling: thêm/bớt node dễ dàng. Đơn giản: không persistence, cấu hình nhẹ. So sánh Redis vs Memcached:\nTiêu chí Redis Memcached Cấu trúc dữ liệu Phong phú Đơn giản (key-value) Persistence Có Không Replication Có Không Multi-AZ Có Không Backup/Restore Có Không Pub/Sub Có Không Đa luồng Không Có Chiến lược Caching Cache-Aside (Lazy Loading) Ứng dụng kiểm tra cache trước, nếu miss thì đọc DB và ghi lại vào cache. Ưu: chỉ cache dữ liệu thực sự cần. Nhược: cache miss gây trễ, dữ liệu có thể cũ. Write-Through Ghi đồng thời vào cache và database. Ưu: dữ liệu đọc luôn tươi. Nhược: ghi chậm hơn, có thể lưu trữ dữ liệu ít dùng. Write-Behind (Write-Back) Ghi vào cache tức thì, đồng bộ xuống DB bất đồng bộ. Ưu: ghi rất nhanh, giảm tải DB. Nhược: rủi ro mất dữ liệu nếu cache lỗi, phức tạp hơn. Tình huống sử dụng Session Store:\n# Lưu session user vào Redis redis.setex(f\u0026#34;session:{user_id}\u0026#34;, 3600, session_data) # Lấy session session = redis.get(f\u0026#34;session:{user_id}\u0026#34;) Leaderboard:\n# Ghi điểm vào sorted set redis.zadd(\u0026#34;leaderboard\u0026#34;, {user_id: score}) # Lấy top 10 top_10 = redis.zrevrange(\u0026#34;leaderboard\u0026#34;, 0, 9, withscores=True) Rate Limiting:\n# Đếm số lần gọi trong 60 giây pipe = redis.pipeline() pipe.incr(f\u0026#34;rate:{user_id}\u0026#34;) pipe.expire(f\u0026#34;rate:{user_id}\u0026#34;, 60) count = pipe.execute()[0] if count \u0026gt; 100: raise RateLimitExceeded() Labs thực hành Lab 43 – AWS Database Migration Service (DMS) (Phần 3) Kiểm tra dữ liệu trên S3 → 43-12 Tạo migration serverless → 43-13 Tạo thông báo sự kiện → 43-14 Theo dõi log → 43-15 Xử lý sự cố: Memory Pressure → 43-16 Xử lý sự cố: Table Error → 43-17 "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.7-week7/1.7.4-day34-2025-10-23/","title":"Ngày 34 - FastAPI Clean Architecture","tags":[],"description":"","content":"Ngày: 2025-10-23 (Thứ Năm)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Tổng quan Clean Architecture Tách rõ phần cấu hình, model, route và core logic để dễ mở rộng/kiểm thử. Giữ main.py nhẹ: chỉ khởi tạo app, load config và mount router. Dùng Pydantic model để chuẩn hóa request/response, đảm bảo contract trùng OpenAPI. backend/ ├── main.py ├── core/ │ └── config.py ├── models/ │ └── book.py ├── routes/ │ └── books.py └── services/ └── books.py Cấu hình \u0026amp; Dependency core/config.py đọc biến môi trường, gom cấu hình CORS, API prefix, debug flag. Tận dụng dependency injection của FastAPI để truyền service vào router. Giúp thay datasource (in-memory → PostgreSQL) mà không đổi interface hàm. CORS \u0026amp; Độ ổn định API CORS chỉ mở cho origin cần thiết (http://localhost:3000 trong giai đoạn dev). Bật allow_methods=[\u0026quot;GET\u0026quot;] cho slice đầu tiên để giảm bề mặt tấn công. Đảm bảo /openapi.json luôn truy cập được nhằm phục vụ công cụ contract testing. Bắt đầu đơn giản, refactor sau Dùng repository in-memory để demo nhanh, sau đó mới thêm DB thật. Ghi chú TODO rõ ràng để không quên khi sang sprint mới. Logging tối giản, tập trung các lỗi quan trọng (timeout, data mismatch). Labs thực hành Refactor main.py chỉ còn khởi tạo app và register router. Viết service get_book_detail(id) trả dữ liệu giả theo spec. Cấu hình CORSMiddleware khớp URL của frontend mock/production. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.8-week8/1.8.4-day39-2025-10-30/","title":"Ngày 39 - NMT &amp; Tóm Tắt Văn Bản","tags":[],"description":"","content":"Ngày: 2025-10-30 (Thứ Năm)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nDịch Máy Neuron (NMT) Tổng Quan Kiến Trúc Câu đầu vào được chuyển đổi thành biểu diễn số và được mã hóa thành biểu diễn sâu bởi một encoder 6 lớp, sau đó được giải mã bởi một decoder 6 lớp thành bản dịch ở ngôn ngữ đích.\nCác Lớp Encoder và Decoder Các lớp bao gồm:\nSelf-attention: Giúp mô hình tập trung vào các phần khác nhau của đầu vào Các lớp feed-forward: Xử lý thông tin Lớp encoder-decoder attention (chỉ decoder): Sử dụng biểu diễn sâu từ lớp encoder cuối cùng Ví Dụ Cơ Chế Attention Tác Vụ Dịch: \u0026ldquo;The woman took the empty magazine out of her gun\u0026rdquo;\nNgôn Ngữ Đích: Czech\nTrực Quan Hóa Self-Attention Khi dịch \u0026ldquo;magazine\u0026rdquo;, cơ chế attention:\nTạo liên kết attention mạnh giữa \u0026lsquo;magazine\u0026rsquo; và \u0026lsquo;gun\u0026rsquo; Điều này giúp dịch chính xác \u0026ldquo;magazine\u0026rdquo; thành \u0026ldquo;zásobník\u0026rdquo; (hộp đạn súng) Thay vì \u0026ldquo;časopis\u0026rdquo; (tạp chí tin tức) Tại Sao Attention Quan Trọng Attention = cơ chế giúp mô hình tập trung vào các phần quan trọng nhất của đầu vào khi tạo ra đầu ra\nNói cách khác: Attention = xử lý thông tin có chọn lọc thay vì tiêu thụ mọi thứ cùng một lúc\nTrong NLP, attention cho phép mô hình quyết định từ nào ảnh hưởng mạnh nhất đến việc hiểu một từ khác trong câu.\nChi Tiết Triển Khai NMT Các Thành Phần Kiến Trúc Mô Hình: Đầu Vào: Input tokens (ngôn ngữ nguồn) Target tokens (ngôn ngữ đích) Bước 1: Tạo Bản Sao Tạo hai bản sao cho mỗi input và target tokens (cần thiết ở các vị trí khác nhau của mô hình)\nBước 2: Encoder Một bản sao của input tokens → encoder Chuyển đổi thành vector key và value Đi qua lớp embedding → LSTM Bước 3: Pre-attention Decoder Một bản sao của target tokens → pre-attention decoder Dịch chuỗi sang phải + thêm token start-of-sentence (teacher forcing) Đi qua lớp embedding → LSTM Đầu ra trở thành vector query Lưu ý: Encoder và pre-attention decoder có thể chạy song song (không có phụ thuộc)\nBước 4: Chuẩn Bị cho Attention Lấy các vector query, key, value Tạo padding mask để xác định padding tokens Sử dụng bản sao của input tokens cho bước này Bước 5: Lớp Attention Truyền queries, keys, values và mask vào lớp attention\nĐầu ra là context vectors và mask Bước 6: Post-attention Decoder Bỏ mask, truyền context vectors qua:\nLSTM Lớp Dense LogSoftmax Bước 7: Đầu Ra Mô hình trả về:\nLog probabilities Bản sao của target tokens (để tính loss) Tóm Tắt Văn Bản Tóm tắt = nén nội dung trong khi vẫn giữ các ý chính\nHai Loại: 1. Tóm Tắt Extractive Khái niệm: Chọn các câu quan trọng nhất từ văn bản gốc\nĐặc Điểm:\nKhông viết lại văn bản Giữ nguyên từ ngữ gốc Giống như \u0026ldquo;đánh dấu các câu chính\u0026rdquo; Quy Trình (TextRank Cổ Điển):\nTách thành các câu Chuyển đổi câu thành embeddings Tính toán độ tương tự (cosine) Tạo đồ thị (câu là nodes) Xếp hạng sử dụng TextRank Chọn các câu xếp hạng cao nhất Kết Quả: Tập con của văn bản gốc\n2. Tóm Tắt Abstractive Khái niệm: Viết lại các ý chính trong các câu mới\nĐặc Điểm:\nTạo ra các câu chưa từng xuất hiện trong bản gốc Hiểu nội dung → paraphrase Yêu cầu mô hình mạnh (seq2seq, Transformer) Ví Dụ: Bài báo gốc thảo luận về quy trình điều tra của công tố viên\u0026hellip;\nTóm tắt được tạo:\n\u0026ldquo;Công tố viên: Cho đến nay không có video nào được sử dụng trong cuộc điều tra vụ tai nạn.\u0026rdquo;\nCâu này không tồn tại trong bản gốc nhưng nắm bắt ý chính.\nTóm Tắt Extractive vs Abstractive Đặc Điểm Extractive Abstractive Cách tiếp cận Chọn câu hiện có Tạo câu mới Sáng tạo Thấp Cao Độ phức tạp Đơn giản hơn Phức tạp hơn Độ chính xác Trung thành hơn với nguồn Có thể gây lỗi Mô hình TextRank, dựa trên đồ thị Seq2seq, Transformer Pipeline TextRank Tóm tắt extractive từng bước:\nKết hợp các bài báo → văn bản đầy đủ Tách các câu Chuyển đổi câu → vectors (embeddings) Tạo ma trận tương tự Xây dựng đồ thị (câu = nodes, cạnh = tương tự) Xếp hạng nodes sử dụng thuật toán TextRank Chọn các câu xếp hạng cao nhất → Tóm tắt Đây là thuật toán cổ điển thống trị trước deep learning!\nÔn Tập Cú Pháp và Ngữ Nghĩa Cú Pháp – Cấu Trúc Câu Cú Pháp kiểm tra cách các từ kết hợp để tạo thành các câu chính xác ngữ pháp.\nBao Gồm: Thứ tự từ: Tiếng Anh sử dụng S–V–O (Chủ Từ–Động Từ–Tân Từ) Cấu trúc cụm từ: NP (Cụm Danh Từ), VP (Cụm Động Từ), PP (Cụm Giới Từ) Các mối quan hệ phụ thuộc: Cách các từ liên quan đến nhau Liên Quan NLP: Gắn nhãn POS Phân tích cú pháp Nhận dạng thực thể Dịch máy Trả lời câu hỏi Ngữ Nghĩa – Ý Nghĩa của Từ và Câu Ngữ Nghĩa tập trung vào ý nghĩa độc lập với ngữ cảnh bên ngoài.\nBao Gồm: Ngữ nghĩa từ vựng: Ý nghĩa của từ Ngữ nghĩa thành phần: Ý nghĩa của câu Từ đồng nghĩa / trái nghĩa: Ý nghĩa tương tự/đối lập Cấp tính / hạ tính: Mối quan hệ chung/cụ thể Liên Quan NLP: Nhúng từ Các biện pháp tương tự Tìm kiếm ngữ nghĩa Phân loại văn bản Thực Dụng – Ý Định Có Ngữ Cảnh Thực Dụng nghiên cứu ý nghĩa từ ngữ cảnh, ý định của người nói và kiến thức thế giới thực.\nBao Gồm: Hàm ý: Ý nghĩa ẩn Chỉ dẫn: Tham chiếu phụ thuộc ngữ cảnh (cái này/cái kia/ở đây/bạn) Hành động nói: Hứa, yêu cầu, xin lỗi Lịch sự, tính chính thức, châm biếm: Tông điệu và ý định Liên Quan NLP: Hệ thống hội thoại Chatbots Phát hiện cảm xúc và châm biếm Mô hình ngôn ngữ ngữ cảnh (BERT, GPT) "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/","title":"Ngày 44 - Các Loại Attention: Self, Masked, Encoder-Decoder","tags":[],"description":"","content":"Ngày: 2025-11-06 (Thứ Năm)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nBa Loại Attention trong Transformers Transformer sử dụng attention theo ba cách khác nhau. Hiểu biết từng cách là rất quan trọng.\nLoại 1: Self-Attention (Encoder) Định Nghĩa: Mỗi vị trí attend tới tất cả các vị trí trong chuỗi tương tự.\nTrường Hợp Sử Dụng: Trong encoder, chúng ta muốn mỗi từ hiểu bối cảnh của nó bằng cách nhìn vào tất cả các từ khác.\nVí Dụ:\nCâu: \u0026#34;The cat sat on the mat\u0026#34; Cho từ \u0026#34;cat\u0026#34;: - Attend tới \u0026#34;The\u0026#34;: 0.15 (mạo từ) - Attend tới \u0026#34;cat\u0026#34;: 0.40 (chính nó) - Attend tới \u0026#34;sat\u0026#34;: 0.20 (động từ) - Attend tới \u0026#34;on\u0026#34;: 0.10 - Attend tới \u0026#34;the\u0026#34;: 0.08 - Attend tới \u0026#34;mat\u0026#34;: 0.07 Kết quả: Ngữ cảnh \u0026#34;cat\u0026#34; = kết hợp có trọng số của cả 6 từ Tại Sao Hữu Ích:\nNắm bắt ngữ cảnh câu đầy đủ Có thể xác định các mối quan hệ (chủ ngữ-động từ, tính từ-danh từ, v.v.) Mỗi từ nhận thông tin từ toàn bộ câu Triển Khai:\nQ = K = V = Đầu vào (cùng một nguồn!) attention(Q, K, V) = softmax(Q×K^T / √d_k) × V Vì Q, K, V đến từ cùng một nơi, nó được gọi là \u0026ldquo;self-attention\u0026rdquo;.\nLoại 2: Masked Self-Attention (Decoder) Vấn Đề: Trong quá trình huấn luyện, nếu decoder có thể \u0026ldquo;nhìn thấy\u0026rdquo; các từ tương lai, nó gian lận!\nVí Dụ - Vấn Đề:\nTác Vụ: Dịch \u0026#34;Je suis heureux\u0026#34; → \u0026#34;I am happy\u0026#34; Huấn Luyện: Bước 1: Dự đoán \u0026#34;am\u0026#34; bằng cách sử dụng... \u0026#34;am\u0026#34; (nó có thể nhìn thấy câu trả lời!) Bước 2: Dự đoán \u0026#34;happy\u0026#34; bằng cách sử dụng \u0026#34;I am happy\u0026#34; (biết câu trả lời!) Bước 3: Dự đoán \u0026#34;happy\u0026#34; đã xong (gian lận!) Kết Quả: Mô hình huấn luyện hoàn hảo nhưng thất bại vào thời gian kiểm tra! Giải Pháp: Che (ẩn) các vị trí tương lai trong quá trình self-attention.\nMasked Self-Attention:\nThay vì: Chúng ta làm: [0.30, 0.33, 0.37] [0.30, -∞, -∞] [0.26, 0.37, 0.37] → [0.26, 0.37, -∞] [0.25, 0.36, 0.39] [0.25, 0.36, 0.39] Sau softmax: [1.00, 0.00, 0.00] [0.30, 0.70, 0.00] [0.25, 0.36, 0.39] (chuẩn hóa) Ma Trận Mask:\nMask = [1, 0, 0] [1, 1, 0] [1, 1, 1] Hoặc: -∞ cho các vị trí được che Hiệu Ứng:\nVị Trí 0: Attend tới vị trí 0 chỉ Vị Trí 1: Attend tới vị trí 0, 1 chỉ Vị Trí 2: Attend tới vị trí 0, 1, 2 Decoder chỉ có thể sử dụng thông tin quá khứ! Tại Sao Điều Này Hoạt Động:\nTrong quá trình huấn luyện, có thể sử dụng tạo hình autoregressive Trong quá trình suy luận, tạo từ từng từ một một cách tự nhiên Ngăn chặn mô hình \u0026ldquo;nhìn thấy câu trả lời\u0026rdquo; Loại 3: Encoder-Decoder Attention Mục Đích: Decoder attend tới đầu ra encoder.\nVí Dụ:\nEncoder xử lý: \u0026#34;Je suis heureux\u0026#34; (Tiếng Pháp) Tạo ra: Context vectors C Decoder xử lý: \u0026#34;\u0026#34; (bắt đầu rỗng) Để tạo ra từ đầu tiên: - Query: từ decoder (tôi nên dịch cái gì?) - Key, Value: từ encoder (tôi nên nhìn vào các từ tiếng Pháp nào?) Kết Quả: Decoder attend tới các từ tiếng Pháp để tạo ra tiếng Anh Khác Biệt Chính So Với Self-Attention:\nSelf-Attention: Encoder-Decoder: Q, K, V đều từ đầu vào Q từ decoder Cùng chuỗi K, V từ encoder Attend trong bản thân Attend tới chuỗi khác Trường Hợp Sử Dụng:\nDecoder nhìn lại đầu ra encoder Cho phép dịch: Tiếng Pháp → Tiếng Anh Cho phép tóm tắt: Tài Liệu → Tóm Tắt Nói chung hữu ích cho các tác vụ seq2seq So Sánh: Cả Ba Loại Loại Nguồn Q Nguồn K, V Mục Đích Self-Attention Đầu vào Đầu vào Hiểu ngữ cảnh trong chuỗi tương tự Masked Self-Attention Đầu vào Đầu vào (tương lai che) Tạo hình autoregressive, ngăn gian lận Encoder-Decoder Decoder Encoder Hiểu xuyên chuỗi Masked Attention Chi Tiết Toán Học Trước khi che:\nAttention = softmax(Q×K^T / √d_k) × V Với che:\nScores = Q×K^T / √d_k Ma trận Mask M: M[i,j] = 0 nếu j \u0026lt;= i (được phép) M[i,j] = -∞ nếu j \u0026gt; i (che tương lai) Masked_scores = Scores + M Attention = softmax(Masked_scores) × V Ví Dụ với Các Số Thực Điểm attention gốc (3×3):\n[0.1, 0.2, 0.3] [0.4, 0.5, 0.6] [0.7, 0.8, 0.9] Ma trận mask:\n[0, -∞, -∞] [0, 0, -∞] [0, 0, 0] Sau khi thêm mask:\n[0.1, -∞, -∞] [0.4, 0.5, -∞] [0.7, 0.8, 0.9] Sau softmax (áp dụng exp và chuẩn hóa):\nexp(0.1) / exp(0.1) = 1.0, softmax([0.1]) = [1.0] Vì vậy: Hàng 0: [1.0, 0, 0] exp(0.4) ≈ 1.49, exp(0.5) ≈ 1.65 Hàng 1: [1.49/(1.49+1.65), 1.65/(1.49+1.65), 0] ≈ [0.47, 0.53, 0] Hàng 2: softmax([0.7, 0.8, 0.9]) (tất cả được phép) Trọng số attention cuối cùng:\n[1.0, 0.0, 0.0] [0.47, 0.53, 0.0] [0.25, 0.33, 0.42] Hiểu Biết Chính: Vị trí 2 chỉ có thể sử dụng thông tin từ các vị trí 0, 1, 2 (không phải tương lai)\nLuồng Attention Transformer Hoàn Chỉnh ĐẦU VÀO: \u0026#34;Je suis heureux\u0026#34; ↓ CÁC LỚP ENCODER (lặp 6 lần): ├─ Self-Attention: Mỗi từ tiếng Pháp attend tới tất cả các từ tiếng Pháp ├─ Feed-Forward → Đầu ra: C (vector ngữ cảnh tiếng Pháp) CÁC LỚP DECODER (lặp 6 lần): ├─ Masked Self-Attention: Mỗi từ được tạo attend tới các từ trước đó ├─ Encoder-Decoder Attention: Từ được tạo attend tới ngữ cảnh tiếng Pháp ├─ Feed-Forward → Đầu ra: Logits cho dự đoán từ tiếp theo ĐẦU RA: \u0026#34;I am happy\u0026#34; Những Hiểu Biết Chính ✅ Self-Attention: Hiểu lưỡng chiều (encoder) ✅ Masked Attention: Tạo hình một chiều (decoder) ✅ Encoder-Decoder: Chuyển giao xuyên chuỗi ✅ Masking ngăn gian lận: Mô hình không thể sử dụng thông tin tương lai\nTại Sao Không Luôn Sử Dụng Cả Ba? BERT (Encoder-only): Chỉ sử dụng self-attention (lưỡng chiều, tốt cho phân loại) GPT (Decoder-only): Chỉ sử dụng masked self-attention (autoregressive, tốt cho tạo hình) T5 (Đầy Đủ): Sử dụng cả ba (cân bằng, tốt cho seq2seq) Tiếp Theo: Triển Khai Bây giờ chúng ta hiểu ba loại attention, chúng ta sẽ thấy cách triển khai chúng trong code!\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.10-week10/1.10.4-day49-2025-11-13/","title":"Ngày 49 - T5 đa nhiệm dạng text-to-text","tags":[],"description":"","content":"Ngày: 2025-11-13 (Thứ Năm)\nTrạng Thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nMột mô hình, nhiều tác vụ T5 coi mọi thứ là text-to-text, nên cùng một mô hình xử lý QA, tóm tắt, dịch, phân loại thông qua prompt.\nPrompt hóa tác vụ Ví dụ: question: When is Pi Day? context: ... -\u0026gt; March 14 summarize: \u0026lt;bài viết\u0026gt; translate English to German: \u0026lt;câu\u0026gt; Định dạng thống nhất giúp mô hình chia sẻ biểu diễn giữa các nhiệm vụ. Quy mô dữ liệu Pre-train trên C4 (~800 GB) so với Wikipedia (~13 GB). Corpora lớn, sạch giúp tổng quát hóa tốt hơn. Lợi ích đa nhiệm Encoder-decoder dùng chung, chuyển giao giữa tác vụ tốt hơn. Cải thiện bài toán ít dữ liệu nhờ tín hiệu chéo tác vụ. Ghi chú thực tế Kiểm soát độ dài output bằng decoder max_length và repetition penalty. Với QA, prompt rõ ràng phần question và context. Fine-tune đa nhiệm: cân bằng tỉ lệ batch tránh một task lấn át. Việc thực hành hôm nay Soạn prompt cho QA và tóm tắt của bạn. Chọn kích thước model theo GPU (T5-small/base/large). Lập kế hoạch pha trộn tác vụ (tỉ lệ mỗi task) khi fine-tune. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.11-week11/1.11.4-day54-2025-11-20/","title":"Ngày 54 - Mạng &amp; quan sát","tags":[],"description":"","content":"Ngày: 2025-11-20 (Thứ Năm)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nĐường đi lưu lượng và log Mọi traffic từ LMI đi qua ENI của instance trong VPC provider; cần thiết kế kết nối và monitoring phù hợp.\nEgress \u0026amp; đích Dependency phải truy cập được từ VPC provider (NAT/Transit/Peering/PrivateLink) Log CloudWatch cũng đi qua ENI; mở đường tới endpoint (public hoặc PrivateLink) Security Group Không cần inbound; giữ inbound đóng Outbound phải cover dependency và CloudWatch Quan sát Log CloudWatch như thường, miễn có đường kết nối Theo dõi metric instance (EC2 billing, vCPU) + Lambda (invokes, errors) Lưu ý Bỏ qua cấu hình VPC ở mức function cho LMI Giới hạn băng thông/ENI theo loại instance vẫn áp dụng "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.12-week12/1.12.4-day59-2025-11-27/","title":"Ngày 59 - Nền tảng SageMaker AI","tags":[],"description":"","content":"Ngày: 2025-11-27 (Thứ Năm)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nTraining serverless \u0026amp; resilient SageMaker AI serverless MLflow cho thử nghiệm nhanh (không cần hạ tầng, auto scale) HyperPod training thêm checkpointless recovery và elastic scaling theo tài nguyên Lợi ích Chu kỳ thử nghiệm nhanh hơn, không phải dựng cluster Giảm chi phí khôi phục lỗi; tận dụng tài nguyên không đồng nhất tốt hơn Việc cần làm Thiết lập workspace MLflow serverless cho thí nghiệm hiện tại Thử checkpointless/elastic training trên một model đại diện; ghi nhận chi phí/thời gian Cập nhật playbook MLOps với mode training và xử lý lỗi mới "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.4-api-gateway-integration/","title":"Tạo API Gateway","tags":[],"description":"","content":"Tạo API Gateway Ở phần này, bạn sẽ tạo một HTTP API trên Amazon API Gateway để khách hàng (client) có thể gửi câu hỏi đến Lambda Function.\nAPI Gateway sẽ đóng vai trò là endpoint HTTP trung gian giữa client và dịch vụ AI Q\u0026amp;A của bạn.\nNội dung 5.4.1 – Tạo HTTP API 5.4.2 – Gắn API với Lambda Sau khi hoàn thành phần này, bạn sẽ có một HTTP endpoint công khai (hoặc private tùy cấu hình), cho phép client như Postman, cURL, frontend web… gửi câu hỏi đến Lambda và nhận lại câu trả lời từ Bedrock.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.4-week4/","title":"Tuần 4 - Dịch vụ Lưu trữ trên AWS","tags":[],"description":"","content":"Tuần: 2025-09-29 đến 2025-10-03\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 4 Tuần này tập trung vào các dịch vụ lưu trữ của AWS, từ S3 cho tới giải pháp hybrid và chiến lược DR.\nNội dung chính Amazon S3 và các lớp lưu trữ. S3 Static Website Hosting. S3 Glacier cho lưu trữ dài hạn. AWS Snow Family. AWS Storage Gateway. Chiến lược Disaster Recovery. AWS Backup. Labs thực hành Lab 13: AWS Backup. Lab 14: AWS VM Import/Export. Lab 24: AWS Storage Gateway. Lab 25: Amazon FSx. Lab 57: Amazon S3 \u0026amp; CloudFront. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.5-testing-and-logs/","title":"Kiểm thử","tags":[],"description":"","content":"Kiểm thử API bằng Thunder Client (VS Code) Sau khi đã tích hợp API Gateway với Lambda, bạn đã có một endpoint HTTP sẵn sàng để kiểm thử.\nTrong bước này, bạn sẽ sử dụng Thunder Client – một extension phổ biến trong VS Code để gửi request và xem phản hồi.\n🔹 Bước 1 — Lấy Invoke URL từ API Gateway Trong AWS API Gateway:\nMở service API Gateway. Chọn API vừa tạo, ví dụ: bedrock-chatbot-api. Ở menu bên trái, chọn Deploy → Stages. Nhấp vào stage $default. Trong phần Stage details, bạn sẽ thấy Invoke URL. Sao chép Invoke URL, ví dụ:\nhttps://v8p3h9umxg.execute-api.ap-southeast-1.amazonaws.com\nTiếp theo, thêm route path bạn đã cấu hình, ví dụ: /chat\n👉 Endpoint đầy đủ sẽ là:\nhttps://v8p3h9umxg.execute-api.ap-southeast-1.amazonaws.com/chat\n🔹 Bước 2 — Cài và mở Thunder Client trong VS Code Mở VS Code. Vào tab Extensions (biểu tượng ô vuông). Tìm Thunder Client và nhấn Install. Sau khi cài xong, icon Thunder Client sẽ xuất hiện ở sidebar bên trái. Nhấp icon đó và chọn New Request. Chọn method POST. Dán endpoint đã tạo vào ô URL: https://v8p3h9umxg.execute-api.ap-southeast-1.amazonaws.com/chat 🔹 Bước 3 — Gửi JSON body và kiểm tra phản hồi Trong cửa sổ request, chọn tab Body → JSON. Nhập nội dung: { \u0026#34;question\u0026#34;: \u0026#34;Amazon Bedrock là gì?\u0026#34; } Nhấn Send để gửi request. Nếu hệ thống hoạt động đúng, bạn sẽ nhận được phản hồi tương tự: { \u0026ldquo;answer\u0026rdquo;: \u0026ldquo;Amazon Bedrock is a fully managed service\u0026hellip;\u0026rdquo; } Điều này xác nhận rằng:\nAPI Gateway nhận request thành công\nLambda chạy đúng và gọi Bedrock\nHệ thống trả về kết quả theo mong đợi\n🔧 Nếu gặp lỗi?\n403 / AccessDeniedException → Kiểm tra IAM Role của Lambda\n500 Internal Error → Xem CloudWatch Logs\nMissing \u0026lsquo;question\u0026rsquo; field → Kiểm tra JSON body\nTimeout → Tăng timeout của Lambda lên 10–20s\nKết luận Bạn đã kiểm thử thành công toàn bộ pipeline:\nClient → API Gateway → Lambda → Bedrock → Trả kết quả AI\nBạn đã hoàn tất phần kiểm thử của workshop.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.1-week1/1.1.5-day05-2025-09-12/","title":"Ngày 05 - AWS Well-Architected Framework","tags":[],"description":"","content":"Ngày: 2025-09-12 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nKhám phá AWS Well-Architected Framework Bộ nguyên tắc thiết kế và phương pháp thực hành tốt nhất để xây dựng kiến trúc cloud tin cậy, bảo mật, hiệu quả và tiết kiệm chi phí. Công cụ Well-Architected trên Console hỗ trợ tự đánh giá và đề xuất hướng cải thiện. Sáu trụ cột của Well-Architected Framework 1. Vận hành xuất sắc (Operational Excellence) Tập trung vận hành và giám sát hệ thống. Liên tục cải thiện quy trình. Tự động hóa thay đổi. Phản ứng kịp thời trước sự kiện. 2. Bảo mật (Security) Bảo vệ thông tin và hệ thống. Quản lý danh tính và quyền truy cập. Thiết lập cơ chế giám sát phát hiện. Bảo vệ hạ tầng. Giữ an toàn cho dữ liệu. 3. Độ tin cậy (Reliability) Tự động phục hồi khi gặp sự cố. Mở rộng ngang để tăng khả năng chịu lỗi. Kiểm thử kịch bản khôi phục. Quản lý thay đổi bằng tự động hóa. 4. Hiệu năng (Performance Efficiency) Sử dụng tài nguyên tính toán hiệu quả. Chọn đúng loại tài nguyên. Giám sát hiệu năng. Đưa ra quyết định dựa trên dữ liệu. 5. Tối ưu chi phí (Cost Optimization) Tránh chi tiêu không cần thiết. Hiểu rõ mô hình sử dụng. Chọn dịch vụ phù hợp. Tối ưu liên tục theo thời gian. 6. Phát triển bền vững (Sustainability) Giảm tác động đến môi trường. Hiểu dấu chân carbon của hệ thống. Tối đa hóa mức sử dụng tài nguyên. Ưu tiên dịch vụ managed. Ôn lại Best Practices Nguyên tắc thiết kế Ngừng đoán dung lượng: Dùng auto scaling. Kiểm thử ở quy mô sản xuất: Dễ dàng nhân bản môi trường. Tự động hóa thử nghiệm kiến trúc: Áp dụng hạ tầng như mã (IaC). Cho phép kiến trúc tiến hóa: Thiết kế linh hoạt để thay đổi. Ra quyết định dựa trên dữ liệu: Luôn giám sát \u0026amp; đo lường. Cải thiện qua game day: Luyện tập kịch bản sự cố. Tổng kết Tuần 1 Tuần này đã hoàn thành kiến thức nền tảng về AWS:\n✅ Hiểu về Cloud Computing và lợi ích\n✅ Nắm được AWS Global Infrastructure\n✅ Biết cách sử dụng AWS Management Tools\n✅ Học các chiến lược tối ưu chi phí\n✅ Nắm AWS Well-Architected Framework\nLabs đã hoàn tất: 3 labs (IAM Setup, Budgets, Support Plans)\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.2-week2/1.2.5-day10-2025-09-19/","title":"Ngày 10 - Elastic Load Balancing","tags":[],"description":"","content":"Ngày: 2025-09-19 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Elastic Load Balancing (ELB) Tổng quan Dịch vụ fully-managed phân phối lưu lượng tới nhiều target (EC2, container, v.v.). Hỗ trợ giao thức HTTP, HTTPS, TCP, TLS. Có thể triển khai ở subnet public hoặc private. Cung cấp DNS name; chỉ Network Load Balancer hỗ trợ IP tĩnh. Tích hợp health check và ghi log truy cập (lưu S3). Hỗ trợ sticky session (session affinity). Các loại chính: Application, Network, Classic và Gateway Load Balancer. Application Load Balancer (ALB) Hoạt động ở tầng 7 (HTTP/HTTPS). Hỗ trợ định tuyến theo path (ví dụ /mobile vs /desktop). Target: EC2, Lambda, địa chỉ IP, container (ECS/EKS). Tính năng nổi bật của ALB:\nĐịnh tuyến theo host name. Định tuyến theo path. Định tuyến dựa trên HTTP header. Định tuyến theo query string parameter. Hỗ trợ WebSocket. Hỗ trợ HTTP/2. Network Load Balancer (NLB) Hoạt động ở tầng 4 (TCP/TLS). Hỗ trợ IP tĩnh, xử lý hàng triệu request/giây. Target: EC2, địa chỉ IP, container (ECS/EKS). Điểm mạnh của NLB:\nĐộ trễ cực thấp. Cung cấp địa chỉ IP tĩnh. Giữ nguyên nguồn IP truy cập. Hỗ trợ kết nối TCP dài hạn. Có thể chấm dứt TLS (TLS termination). Gateway Load Balancer (GWLB) Hoạt động ở tầng 3 (gói IP). Sử dụng giao thức GENEVE trên cổng 6081. Định tuyến lưu lượng đến các virtual appliance như firewall, công cụ monitor. Danh sách đối tác: aws.amazon.com/elasticloadbalancing/partners Khám phá AWS Advanced Networking – Specialty Study Guide Sách hướng dẫn chính thức bao quát chủ đề kỳ thi, nguyên tắc thiết kế mạng trên AWS và các tình huống kiến trúc thực tế. Hands-On Labs Lab 20 – AWS Transit Gateway Chuẩn bị môi trường → 20-02 Tạo Transit Gateway → 20-03 Tạo TGW Attachment → 20-04 Tạo TGW Route Table → 20-05 Thêm route TGW vào Route Table của VPC → 20-06 Tổng kết Tuần 2 Tuần này đã hoàn thành kiến thức về AWS Networking:\n✅ Amazon VPC và Subnet\n✅ Security Group và NACL\n✅ VPC Peering và Transit Gateway\n✅ VPN và Direct Connect\n✅ Elastic Load Balancing (ALB, NLB, GWLB)\nLabs đã hoàn tất: 4 labs (VPC Basics, Hybrid DNS, VPC Peering, Transit Gateway)\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.3-week3/1.3.5-day15-2025-09-26/","title":"Ngày 15 - Lightsail, EFS &amp; FSx","tags":[],"description":"","content":"Ngày: 2025-09-26 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon Lightsail Dịch vụ compute đơn giản với giá cố định hàng tháng (bắt đầu ~3,5 USD/tháng). Bao gồm băng thông đi kèm với giá thấp hơn EC2. Lý tưởng cho workload nhỏ, môi trường dev/test. Hỗ trợ snapshot để sao lưu. Chạy trong VPC được quản lý và có thể kết nối VPC tiêu chuẩn qua peering (một lần nhấp). Trường hợp dùng Lightsail:\nỨng dụng web đơn giản. Trang WordPress. Môi trường phát triển/thử nghiệm. Ứng dụng doanh nghiệp nhỏ. Học tập và thử nghiệm. So sánh Lightsail và EC2:\nTiêu chí Lightsail EC2 Giá Cố định hàng tháng Trả theo dùng Độ phức tạp Đơn giản Nhiều tùy chọn Khả năng mở rộng Giới hạn Không giới hạn Đối tượng Dự án nhỏ Doanh nghiệp Amazon EFS (Elastic File System) Dịch vụ hệ thống file NFSv4 do AWS quản lý, nhiều EC2 có thể mount đồng thời. Tự động scale tới hàng petabyte. Trả tiền theo dung lượng thực tế sử dụng (khác với EBS phải provision). Có thể mount từ on-prem thông qua VPN hoặc Direct Connect. Tính năng EFS:\nTruy cập đồng thời từ nhiều instance. Tự động mở rộng. Dịch vụ cấp độ Region (đa AZ). Quản lý vòng đời. Mã hóa dữ liệu khi lưu trữ và truyền tải. Các lớp lưu trữ EFS:\nStandard: File truy cập thường xuyên. Infrequent Access (IA): Chi phí thấp cho file ít truy cập. One Zone: Một AZ để tiết kiệm chi phí. Amazon FSx Các hệ thống file được quản lý, mở rộng cho Windows, Lustre, NetApp ONTAP. AWS lo phần thiết lập, mở rộng, sao lưu. Truy cập từ EC2, máy chủ on-prem hoặc người dùng qua giao thức SMB/NFS. Các biến thể FSx:\nFSx for Windows File Server Hệ thống file Windows gốc. Hỗ trợ giao thức SMB. Tích hợp Active Directory. Hỗ trợ DFS namespace. FSx for Lustre Phù hợp workload HPC. Machine Learning, mô phỏng. Độ trễ dưới mili giây. Tích hợp S3. FSx for NetApp ONTAP Hỗ trợ đa giao thức (NFS, SMB, iSCSI). Giảm trùng lặp dữ liệu, nén. Snapshots và replication. AWS Application Migration Service (MGN) Dịch vụ migrate/replicate máy chủ vật lý hoặc ảo lên AWS để DR hoặc hiện đại hóa. Liên tục sao chép máy nguồn sang instance staging EC2 nhẹ. Khi cut-over, MGN tạo EC2 đầy đủ chức năng từ dữ liệu đã replicate. Các giai đoạn migration:\nCài agent lên máy nguồn. Sao chép liên tục vào AWS. Kiểm thử bằng instance test không ảnh hưởng. Cutover sang production. Khám phá Microsoft Workloads on AWS Playlist tuyển chọn về triển khai, tối ưu và best practices khi chạy workload Microsoft trên AWS. Tổng kết Tuần 3 Tuần này đã hoàn thành kiến thức về AWS Compute:\n✅ Amazon EC2 và các loại instance\n✅ AMI, EBS, Instance Store\n✅ EC2 Auto Scaling\n✅ Các mô hình giá của EC2\n✅ Lightsail, EFS, FSx\nLabs đã hoàn tất: 3 labs (IAM Setup, Budgets, Support Plans)\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.4-week4/1.4.5-day20-2025-10-03/","title":"Ngày 20 - AWS Backup &amp; FSx","tags":[],"description":"","content":"Ngày: 2025-10-03 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Backup Dịch vụ backup tập trung giúp tự động hóa và quản trị bảo vệ dữ liệu ở quy mô lớn. Khả năng chính Quản lý tập trung: Định nghĩa và áp chính sách backup cho nhiều dịch vụ. Hỗ trợ đa dịch vụ: EC2, EBS, RDS, DynamoDB, EFS, Storage Gateway, S3,\u0026hellip; Lịch và vòng đời: Tự động hóa lịch backup và retention. Tuân thủ: Đáp ứng yêu cầu governance và audit. Lợi ích Đơn giản vận hành: Không cần script tùy biến hay công cụ rời rạc. Tiết kiệm thời gian: Tự động bảo vệ dựa trên policy. Báo cáo \u0026amp; audit: Theo dõi trạng thái backup và tuân thủ. Backup Vault Lock Cơ chế đảm bảo tính bất biến, ngăn chỉnh sửa/xóa backup đã bảo vệ nhằm đáp ứng yêu cầu tuân thủ nghiêm ngặt. Tính năng nổi bật của AWS Backup:\nSao chép backup liên vùng. Backup chéo tài khoản. Backup plan (chính sách) linh hoạt. Quản lý vòng đời (lưu trữ lạnh, xóa theo hạn). Mã hóa dữ liệu khi lưu trữ. Gắn thẻ để điều khiển chính sách backup theo tag. Ví dụ Backup Plan:\n{ \u0026#34;BackupPlanName\u0026#34;: \u0026#34;DailyBackups\u0026#34;, \u0026#34;Rules\u0026#34;: [{ \u0026#34;RuleName\u0026#34;: \u0026#34;DailyRule\u0026#34;, \u0026#34;ScheduleExpression\u0026#34;: \u0026#34;cron(0 5 ? * * *)\u0026#34;, \u0026#34;StartWindowMinutes\u0026#34;: 60, \u0026#34;CompletionWindowMinutes\u0026#34;: 120, \u0026#34;Lifecycle\u0026#34;: { \u0026#34;DeleteAfterDays\u0026#34;: 30, \u0026#34;MoveToColdStorageAfterDays\u0026#34;: 7 } }] } Khám phá AWS Skill Builder Các learning plan chọn lọc và nội dung chuyên sâu dành cho chuyên gia lưu trữ: Storage Learning Plan: Block Storage Storage Learning Plan: Object Storage Hands-On Labs Lab 13 – AWS Backup Tạo S3 Bucket → 13-02.1 Triển khai hạ tầng mẫu → 13-02.2 Tạo Backup Plan → 13-03 Thiết lập thông báo → 13-04 Kiểm tra khôi phục → 13-05 Dọn dẹp tài nguyên → 13-06 Lab 25 – Amazon FSx (File Systems) Tạo File System SSD Multi-AZ → 25-2.2 Tạo File System HDD Multi-AZ → 25-2.3 Tạo File Share mới → 25-3 Kiểm thử hiệu năng → 25-4 Giám sát hiệu năng → 25-5 Bật tính năng Data Deduplication → 25-6 Bật Shadow Copies → 25-7 Quản lý phiên người dùng \u0026amp; file mở → 25-8 Bật quota người dùng → 25-9 Scale thông lượng → 25-11 Mở rộng dung lượng lưu trữ → 25-12 Xóa môi trường → 25-13 Tổng kết Tuần 4 Tuần này đã hoàn tất các chủ đề về AWS Storage:\n✅ Amazon S3 và các lớp lưu trữ\n✅ S3 Static Website và CORS\n✅ AWS Snow Family\n✅ AWS Storage Gateway\n✅ Chiến lược Disaster Recovery\n✅ AWS Backup\nLabs đã hoàn tất: 5 labs (Backup, VM Import/Export, Storage Gateway, FSx, S3 \u0026amp; CloudFront)\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.5-week5/1.5.5-day25-2025-10-10/","title":"Ngày 25 - AWS Security Hub &amp; Automation","tags":[],"description":"","content":"Ngày: 2025-10-10 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Security Hub Tổng hợp và ưu tiên hóa các phát hiện bảo mật, posture across account/dịch vụ. Khả năng\nKiểm tra tự động, chuẩn hóa findings, workflow xử lý ưu tiên. Hỗ trợ chuẩn tuân thủ: CIS AWS Foundations, PCI DSS, AWS Foundational Security Best Practices. Tích hợp\nGuardDuty, Inspector, Macie, Firewall Manager, IAM Access Analyzer và nhiều công cụ đối tác. Kết quả\nGiảm thời gian thu thập, tập trung khắc phục; cái nhìn hợp nhất và nâng cao hygiene bảo mật. Tính năng Security Hub:\nTheo dõi posture bảo mật liên tục. Kiểm tra tuân thủ tự động. Tổng hợp findings đa tài khoản. Tích hợp 50+ dịch vụ AWS \u0026amp; đối tác. Custom insight và dashboard. Tự động khắc phục qua EventBridge. Chuẩn bảo mật được hỗ trợ:\nAWS Foundational Security Best Practices: hơn 50 control. CIS AWS Foundations Benchmark: chuẩn ngành. PCI DSS: tiêu chuẩn thẻ thanh toán. NIST: khung bảo mật NIST. Security Automation Dịch vụ AWS phục vụ tự động hóa:\nAWS Config: Theo dõi thay đổi cấu hình tài nguyên. Amazon EventBridge: Tự động hóa dựa trên sự kiện. AWS Lambda: Hàm serverless xử lý remediation. AWS Systems Manager: Tự động vá lỗi và quản lý tuân thủ. Mẫu tự động hóa phổ biến:\nTự động khắc phục tài nguyên không tuân thủ. Ứng phó sự cố tự động. Kiểm tra quy tắc security group. Cưỡng chế mã hóa. Đảm bảo tuân thủ tag. Khám phá AWS Certified Security – Specialty: All-in-One Exam Guide (SCS-C01) Tài liệu ôn luyện toàn diện cho chứng chỉ Security Specialty. Hands-On Labs Lab 18 – AWS Security Hub Bật Security Hub → 18-02 Đánh giá từng bộ tiêu chí → 18-03 Dọn dẹp tài nguyên → 18-04 Lab 22 – AWS Lambda Automation with Slack Tạo VPC → 22-2.1 Tạo Security Group → 22-2.2 Tạo EC2 Instance → 22-2.3 Cấu hình Slack Incoming Webhook → 22-2.4 Tạo tag cho instance → 22-3 Tạo role cho Lambda → 22-4 Hàm Stop Instance → 22-5.1 Hàm Start Instance → 22-5.2 Kiểm tra kết quả → 22-6 Dọn dẹp → 22-7 Lab 27 – AWS Resource Groups \u0026amp; Tagging (Phần 2) Sử dụng tag với CLI → 27-2.2 Tạo Resource Group → 27-3 Dọn dẹp tài nguyên → 27-4 Lab 33 – AWS KMS \u0026amp; CloudTrail Integration (Phần 2) Tạo CloudTrail → 33-5.1 Ghi log vào CloudTrail → 33-5.2 Tạo Amazon Athena → 33-5.3 Query bằng Athena → 33-5.4 Kiểm tra \u0026amp; chia sẻ dữ liệu S3 đã mã hóa → 33-6 Dọn dẹp → 33-7 Lab 44 – IAM Advanced Role Control Tạo IAM Group → 44-2 Tạo IAM User → 44-3.1 Kiểm tra quyền → 44-3.2 Tạo IAM Role Admin → 44-4.1 Cấu hình Switch Role → 44-4.2 Giới hạn Switch Role theo IP → 44-4.3.1 Giới hạn Switch Role theo thời gian → 44-4.3.2 Dọn dẹp → 44-5 Tổng kết Tuần 5 Tuần này đã hoàn tất các chủ đề về AWS Security:\n✅ Shared Responsibility Model\n✅ AWS IAM (Users, Groups, Roles, Policies)\n✅ Amazon Cognito\n✅ AWS Organizations \u0026amp; SCPs\n✅ AWS Identity Center\n✅ AWS KMS\n✅ AWS Security Hub\nLabs đã hoàn tất: 8 labs (Security Hub, Lambda Automation, Resource Groups, IAM Policies, KMS \u0026amp; CloudTrail, Advanced Role Control)\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.6-week6/1.6.5-day30-2025-10-17/","title":"Ngày 30 - Database Migration &amp; Best Practices","tags":[],"description":"","content":"Ngày: 2025-10-17 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Database Migration Service (DMS) AWS DMS hỗ trợ di chuyển cơ sở dữ liệu lên AWS nhanh chóng, bảo mật và giảm tối đa downtime.\nĐiểm nổi bật:\nHomogeneous Migration: cùng engine (ví dụ Oracle → Oracle). Heterogeneous Migration: khác engine (Oracle → Aurora). Continuous Replication: giữ đồng bộ nguồn và đích. Schema Conversion: dùng AWS Schema Conversion Tool (SCT). Kiểu migration:\nFull Load: di chuyển toàn bộ dữ liệu hiện tại một lần. Full Load + CDC: tải ban đầu và đồng bộ thay đổi liên tục (Change Data Capture). CDC Only: chỉ replicate phần thay đổi mới. Nguồn hỗ trợ:\nOracle, SQL Server, MySQL, PostgreSQL, MongoDB, SAP ASE, IBM Db2 Amazon RDS, Amazon Aurora, Amazon S3 Đích hỗ trợ:\nAmazon RDS, Amazon Aurora, Amazon Redshift, Amazon DynamoDB Amazon S3, Amazon Elasticsearch, Amazon Kinesis Data Streams Best Practices cho Database Tối ưu hiệu năng RDS/Aurora:\nChọn đúng loại instance. Bật Enhanced Monitoring. Tối ưu câu truy vấn và index. Dùng Read Replica cho workload đọc nhiều. Bật Performance Insights để phân tích bottleneck. Redshift:\nChọn distribution key phù hợp. Dùng sort key cho cột hay lọc. Vacuum \u0026amp; analyze định kỳ. Tận dụng nén cột. Cấu hình workload management (WLM). ElastiCache:\nChọn node type đúng nhu cầu. Dùng cluster mode cho Redis. Cài đặt chính sách loại bỏ (eviction). Theo dõi cache hit rate. Dùng connection pooling. Bảo mật Mã hóa khi lưu (Encryption at Rest): bật cho toàn bộ database. Mã hóa khi truyền: dùng kết nối SSL/TLS. Cô lập mạng: triển khai trong private subnet. IAM Authentication: tận dụng cho RDS/Aurora khi có thể. Secrets Manager: lưu thông tin đăng nhập an toàn. Security Group: giới hạn truy cập tối thiểu. Audit Logging: bật CloudWatch Logs và CloudTrail. High Availability \u0026amp; Disaster Recovery RDS/Aurora:\nBật Multi-AZ cho môi trường production. Cấu hình backup tự động. Thường xuyên kiểm tra quy trình khôi phục. Sử dụng Aurora Global Database cho DR đa vùng. Tạo read replica ở vùng khác nếu cần. Redshift:\nBật snapshot tự động. Sao chép snapshot sang vùng khác. Kết hợp Redshift Spectrum với data lake. Thiết lập cơ chế copy snapshot cross-region. ElastiCache:\nRedis: bật Multi-AZ với failover tự động. Kích hoạt backup/restore. Dùng cluster mode để mở rộng. Thêm retry logic ở mức ứng dụng. Tối ưu chi phí Right-sizing: chọn instance đúng tải. Reserved Instances: cam kết 1–3 năm. Aurora Serverless: cho workload biến thiên. Redshift Serverless: phù hợp phân tích không liên tục. Tối ưu lưu trữ: chọn loại storage thích hợp. Lifecycle Policy: lưu trữ lạnh lên S3/Glacier. Giám sát chi phí: dùng Cost Explorer \u0026amp; Budgets. Khám phá thêm The Data Warehouse Toolkit Tài liệu kinh điển về dimensional modeling và các mẫu thiết kế data warehouse. Tổng kết Week 6 Tuần này hoàn thành trọn bộ kiến thức AWS Database Services:\n✅ Database Fundamentals (RDBMS, NoSQL, OLTP vs OLAP)\n✅ Amazon RDS \u0026amp; Aurora\n✅ Amazon Redshift\n✅ Amazon ElastiCache\n✅ AWS Database Migration Service\nLabs đã hoàn thành: 2 labs (RDS \u0026amp; EC2 Integration, Database Migration Service)\nTổng kết 6 tuần đầu (8/9 - 17/10/2025) 30 ngày làm việc đã hoàn tất:\nWeek 1: Cloud Computing Fundamentals AWS basics, hạ tầng, công cụ quản trị, tối ưu chi phí. Week 2: AWS Networking Services VPC, subnet, security group, load balancing, hybrid connectivity. Week 3: AWS Compute Services EC2, AMI, storage, auto scaling, pricing models. Week 4: AWS Storage Services S3, Glacier, Snow Family, Storage Gateway, backup \u0026amp; DR. Week 5: AWS Security \u0026amp; Identity IAM, Cognito, Organizations, KMS, Security Hub. Week 6: AWS Database Services RDS, Aurora, Redshift, ElastiCache, DMS. Tổng số labs: 25+ labs.\nKế hoạch tiếp theo: Bắt đầu Week 7 từ ngày 20/10/2025 (Thứ Hai).\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.7-week7/1.7.5-day35-2025-10-24/","title":"Ngày 35 - Contract Testing &amp; Retrospective","tags":[],"description":"","content":"Ngày: 2025-10-24 (Thứ Sáu)\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Contract Testing với Schemathesis Chạy schemathesis run --checks all --workers 4 --url http://127.0.0.1:8000/openapi.yaml để tạo bộ test tự động. Schemathesis sinh nhiều trường hợp ngẫu nhiên (happy path, edge case, thiếu field). Đảm bảo backend không trả sai schema khi frontend chuyển sang gọi API thật. Lợi ích Không cần viết tay test case phức tạp. Giảm rủi ro mismatch sau refactor. Hoạt động như quality gate trong CI pipeline. Sai sót \u0026amp; cách khắc phục Sai lầm Nguyên nhân Cách xử lý Tạo cả error.tsx và not-found.tsx Thừa xử lý Chỉ giữ not-found.tsx Dùng --base-url trong Schemathesis Sai câu lệnh Dùng --url đúng chuẩn Timeout khi đọc /openapi.json CORS hoặc phản hồi chậm Dùng file YAML trực tiếp Over-engineer backend Tách quá nhiều file sớm Bắt đầu đơn giản, refactor sau Workflow chuẩn đã được validate 1. Define Contract (OpenAPI) 2. Mock API (Prism) 3. Build Frontend với mock data 4. Implement Backend theo spec 5. Chuyển sang API thật 6. Contract Testing (Schemathesis) Hỗ trợ frontend và backend phát triển song song. Giảm xung đột, tăng tốc demo và giữ chất lượng ổn định. Key Insights Contract-first giữ spec đồng bộ, giảm lỗi integration. Vertical slice cho phép release từng phần và lấy feedback sớm. Tự động hóa (Prism, Schemathesis) giảm effort test thủ công. Bắt đầu đơn giản, refactor dần khi nhu cầu mở rộng. Labs thực hành Chạy Schemathesis với spec mới nhất và ghi nhận kết quả. Cập nhật README workflow để cả team tham khảo. Chuẩn bị backlog cho vertical slice tiếp theo dựa trên feedback demo. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.8-week8/1.8.5-day40-2025-10-31/","title":"Ngày 40 - Đánh Giá MT &amp; Chiến Lược Decoding","tags":[],"description":"","content":"Ngày: 2025-10-31 (Thứ Sáu)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nĐiểm BLEU – Đánh Giá Dựa Trên Precision BLEU (Bilingual Evaluation Understudy) là thuật toán được thiết kế để đánh giá chất lượng dịch máy.\nCách BLEU Hoạt Động Khái Niệm Cốt Lõi: So sánh bản dịch ứng viên với một hoặc nhiều bản dịch tham chiếu (thường là bản dịch của con người)\nPhạm Vi Điểm: 0 đến 1\nGần 1 = bản dịch tốt hơn Gần 0 = bản dịch tệ hơn Tính Toán Điểm BLEU BLEU Vanilla (Có Vấn Đề) Ví Dụ:\nỨng viên: \u0026ldquo;I I am I\u0026rdquo; Tham chiếu 1: \u0026ldquo;Eunice said I\u0026rsquo;m hungry\u0026rdquo; Tham chiếu 2: \u0026ldquo;He said I\u0026rsquo;m hungry\u0026rdquo; Quy Trình:\nĐếm có bao nhiêu từ của ứng viên xuất hiện trong bất kỳ tham chiếu nào Chia cho tổng số từ của ứng viên Kết quả: 4/4 = 1.0 (điểm hoàn hảo!)\nVấn Đề: Bản dịch này tệ nhưng lại được điểm hoàn hảo! Một mô hình chỉ xuất ra các từ phổ biến sẽ đạt điểm tốt.\nBLEU Được Sửa Đổi (Tốt Hơn) Thay Đổi Chính: Sau khi khớp một từ, loại bỏ nó khỏi tham chiếu\nVí Dụ Tương Tự:\n\u0026ldquo;I\u0026rdquo; (đầu tiên) → khớp → loại bỏ \u0026ldquo;I\u0026rdquo; khỏi tham chiếu → đếm = 1 \u0026ldquo;I\u0026rdquo; (thứ hai) → không còn khớp → đếm = 1 \u0026ldquo;am\u0026rdquo; → khớp → loại bỏ \u0026ldquo;am\u0026rdquo; → đếm = 2 \u0026ldquo;I\u0026rdquo; (thứ ba) → không còn khớp → đếm = 2 Kết quả: 2/4 = 0.5 (thực tế hơn!)\nHạn Chế của BLEU ❌ Không xem xét ý nghĩa ngữ nghĩa\nChỉ kiểm tra khớp từ ❌ Không xem xét cấu trúc câu\n\u0026ldquo;Ate I was hungry because\u0026rdquo; vs \u0026ldquo;I ate because I was hungry\u0026rdquo; Cả hai đều được điểm giống nhau! ✅ Vẫn là metric được áp dụng rộng rãi nhất mặc dù có hạn chế\nĐiểm ROUGE – Đánh Giá Dựa Trên Recall ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\nBLEU vs ROUGE Metric Tập Trung Tính Toán BLEU Precision Bao nhiêu từ ứng viên có trong tham chiếu? ROUGE Recall Bao nhiêu từ tham chiếu có trong ứng viên? Tính Toán Điểm ROUGE-N Ví Dụ:\nỨng viên: \u0026ldquo;I I am I\u0026rdquo; Tham chiếu 1: \u0026ldquo;Younes said I am hungry\u0026rdquo; (5 từ) Tham chiếu 2: \u0026ldquo;He said I\u0026rsquo;m hungry\u0026rdquo; (5 từ) Quy Trình cho Tham chiếu 1:\n\u0026ldquo;Younes\u0026rdquo; → không khớp → đếm = 0 \u0026ldquo;said\u0026rdquo; → không khớp → đếm = 0 \u0026ldquo;I\u0026rdquo; → khớp → đếm = 1 \u0026ldquo;am\u0026rdquo; → khớp → đếm = 2 \u0026ldquo;hungry\u0026rdquo; → không khớp → đếm = 2 Điểm ROUGE cho Ref 1: 2/5 = 0.4\nNếu có nhiều tham chiếu: Tính cho mỗi cái, lấy giá trị lớn nhất\nĐiểm F1 – Kết Hợp BLEU và ROUGE Vì BLEU = precision và ROUGE = recall, chúng ta có thể tính điểm F1:\nCông Thức:\nF1 = 2 × (Precision × Recall) / (Precision + Recall) F1 = 2 × (BLEU × ROUGE) / (BLEU + ROUGE) Ví Dụ:\nBLEU = 0.5 ROUGE = 0.4 F1 = 2 × (0.5 × 0.4) / (0.5 + 0.4) = 4/9 ≈ 0.44 Beam Search Decoding Vấn Đề: Chọn từ có xác suất cao nhất ở mỗi bước không đảm bảo chuỗi tốt nhất tổng thể\nGiải Pháp: Beam search tìm các chuỗi có khả năng cao nhất trên một cửa sổ cố định\nCách Beam Search Hoạt Động Độ Rộng Beam (B): Số lượng chuỗi cần giữ ở mỗi bước\nQuy Trình: Bước 1: Bắt đầu với SOS token Lấy xác suất cho từ đầu tiên:\nI: 0.5 am: 0.4 hungry: 0.1 Giữ top B=2: \u0026ldquo;I\u0026rdquo; và \u0026ldquo;am\u0026rdquo;\nBước 2: Tính Xác Suất Có Điều Kiện Cho \u0026ldquo;I\u0026rdquo;:\nI am: 0.5 × 0.5 = 0.25 I I: 0.5 × 0.1 = 0.05 Cho \u0026ldquo;am\u0026rdquo;:\nam I: 0.4 × 0.7 = 0.28 am hungry: 0.4 × 0.2 = 0.08 Giữ top B=2: \u0026ldquo;am I\u0026rdquo; (0.28) và \u0026ldquo;I am\u0026rdquo; (0.25)\nBước 3: Lặp Lại Tiếp tục cho đến khi tất cả B chuỗi đạt EOS token\nBước 4: Chọn Tốt Nhất Chọn chuỗi có xác suất tổng thể cao nhất\nĐặc Điểm Beam Search Ưu Điểm:\nTốt hơn greedy decoding (B=1) Tìm các chuỗi tốt hơn toàn cục Được sử dụng rộng rãi trong production Nhược Điểm:\nTốn bộ nhớ (lưu trữ B chuỗi) Tốn kém về mặt tính toán (chạy mô hình B lần mỗi bước) Phạt các chuỗi dài (tích của nhiều xác suất) Giải Pháp cho Chuỗi Dài: Chuẩn hóa theo độ dài: chia xác suất cho số từ\nMinimum Bayes Risk (MBR) Decoding Khái Niệm: Tạo nhiều mẫu và tìm sự đồng thuận\nQuy Trình MBR: Bước 1: Tạo Nhiều Mẫu Tạo ~30 mẫu ngẫu nhiên từ mô hình\nBước 2: So Sánh Tất Cả Các Cặp Với mỗi mẫu, so sánh với tất cả các mẫu khác sử dụng metric tương tự (ví dụ: ROUGE)\nBước 3: Tính Độ Tương Tự Trung Bình Với mỗi ứng viên, tính độ tương tự trung bình với tất cả các ứng viên khác\nBước 4: Chọn Tốt Nhất Chọn mẫu có độ tương tự trung bình cao nhất (rủi ro thấp nhất)\nCông Thức MBR E* = argmax_E [ trung bình ROUGE(E, E\u0026#39;) cho tất cả E\u0026#39; ] Trong đó:\nE = bản dịch ứng viên E\u0026rsquo; = tất cả các ứng viên khác Mục tiêu: Tìm E tối đa hóa ROUGE trung bình với mọi E' Ví Dụ MBR (4 Ứng Viên) Bước 1: Tính điểm ROUGE theo cặp\nROUGE(C1, C2), ROUGE(C1, C3), ROUGE(C1, C4) Trung bình = R1 Bước 2: Lặp lại cho C2, C3, C4\nLấy R2, R3, R4 Bước 3: Chọn cao nhất\nChọn ứng viên có max(R1, R2, R3, R4) Đặc Điểm MBR Ưu Điểm:\nChính xác hơn về mặt ngữ cảnh so với random sampling Tìm bản dịch đồng thuận Có thể vượt trội beam search Nhược Điểm:\nYêu cầu tạo nhiều mẫu (tốn kém) Yêu cầu so sánh O(n²) Khi Nào Sử Dụng:\nKhi cần bản dịch chất lượng cao Khi chi phí tính toán chấp nhận được Khi đầu ra beam search không nhất quán Tóm Tắt: Các Chiến Lược Decoding Phương Pháp Mô Tả Ưu Điểm Nhược Điểm Greedy Chọn xác suất cao nhất mỗi bước Nhanh, đơn giản Chuỗi không tối ưu Beam Search Giữ top-B chuỗi Chất lượng tốt hơn Chi phí bộ nhớ + tính toán Random Sampling Lấy mẫu từ phân phối Đầu ra đa dạng Chất lượng không nhất quán MBR Đồng thuận từ các mẫu Chất lượng cao Rất tốn kém Tóm Tắt Các Metric Đánh Giá Metric Loại Tập Trung Tốt Nhất Cho BLEU Precision Ứng viên → Tham chiếu MT chung ROUGE Recall Tham chiếu → Ứng viên Tóm tắt F1 Trung bình điều hòa Cả precision \u0026amp; recall Cái nhìn cân bằng Lưu Ý Quan Trọng: Tất cả các metric này:\n❌ Không xem xét ngữ nghĩa ❌ Không xem xét cấu trúc câu ✅ Chỉ đếm khớp n-gram Thay Thế Hiện Đại: Sử dụng các metric neural hoặc đánh giá của con người cho các ứng dụng quan trọng!\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/","title":"Ngày 45 - Decoder Transformer &amp; Triển Khai GPT2","tags":[],"description":"","content":"Ngày: 2025-11-07 (Thứ Sáu)\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nXây Dựng Decoder Transformer: Kiến Trúc GPT2 Bây giờ hãy xem cách tất cả những phần này kết hợp lại trong mã thực tế!\nCấu Trúc Transformer Decoder (kiểu GPT2) Đầu Vào: Câu được tokenize [1, 2, 3, 4, 5] ↓ Lớp Embedding: Chuyển đổi tokens thành vectors ↓ Thêm Positional Encoding: Thêm thông tin vị trí ↓ ┌──────────────────────────────────┐ │ Decoder Block (N lần) │ │ ├─ Masked Self-Attention │ │ ├─ Residual + LayerNorm │ │ ├─ Feed-Forward │ │ └─ Residual + LayerNorm │ └──────────────────────────────────┘ ↓ Lớp Linear: Chiếu tới kích thước vocab ↓ Softmax: Chuyển đổi thành xác suất ↓ Đầu Ra: Xác suất cho từ tiếp theo Triển Khai PyTorch Bước 1: Word Embedding + Positional Encoding import torch import torch.nn as nn class TransformerDecoder(nn.Module): def __init__(self, vocab_size=10000, d_model=512, num_layers=6, num_heads=8, d_ff=2048, max_seq_len=1024, dropout=0.1): super().__init__() # 1. Lớp embedding self.embedding = nn.Embedding(vocab_size, d_model) # 2. Positional encoding (được học) self.positional_encoding = nn.Embedding(max_seq_len, d_model) # 3. Các decoder blocks (lặp N lần) self.decoder_layers = nn.ModuleList([ DecoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers) ]) # 4. Lớp đầu ra self.final_layer = nn.Linear(d_model, vocab_size) self.softmax = nn.Softmax(dim=-1) self.d_model = d_model def forward(self, input_ids, mask=None): # input_ids shape: [batch_size, seq_length] batch_size, seq_len = input_ids.shape # 1. Nhúng các tokens x = self.embedding(input_ids) # [batch, seq_len, d_model] # 2. Thêm positional encoding positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0) pos_encoding = self.positional_encoding(positions) x = x + pos_encoding # [batch, seq_len, d_model] # 3. Truyền qua các lớp decoder for decoder_layer in self.decoder_layers: x = decoder_layer(x, mask) # 4. Chiếu tới vocab logits = self.final_layer(x) # [batch, seq_len, vocab_size] return logits Bước 2: Decoder Block class DecoderBlock(nn.Module): def __init__(self, d_model, num_heads, d_ff, dropout): super().__init__() # 1. Masked multi-head attention self.self_attention = MultiHeadAttention(d_model, num_heads, dropout) self.norm1 = nn.LayerNorm(d_model) # 2. Feed-forward network self.feed_forward = FeedForward(d_model, d_ff, dropout) self.norm2 = nn.LayerNorm(d_model) self.dropout = nn.Dropout(dropout) def forward(self, x, mask=None): # x shape: [batch, seq_len, d_model] # Masked Self-Attention + Residual + Norm attn_output = self.self_attention(x, x, x, mask) # Q=K=V x = x + self.dropout(attn_output) x = self.norm1(x) # Feed-Forward + Residual + Norm ff_output = self.feed_forward(x) x = x + self.dropout(ff_output) x = self.norm2(x) return x Bước 3: Multi-Head Attention class MultiHeadAttention(nn.Module): def __init__(self, d_model, num_heads, dropout): super().__init__() assert d_model % num_heads == 0 self.num_heads = num_heads self.d_k = d_model // num_heads # Các phép chiếu tuyến tính cho Q, K, V self.W_q = nn.Linear(d_model, d_model) self.W_k = nn.Linear(d_model, d_model) self.W_v = nn.Linear(d_model, d_model) # Phép chiếu đầu ra self.W_o = nn.Linear(d_model, d_model) self.dropout = nn.Dropout(dropout) def forward(self, Q, K, V, mask=None): batch_size = Q.shape[0] # 1. Các phép chiếu tuyến tính và chia thành nhiều đầu Q = self.W_q(Q) # [batch, seq_len, d_model] K = self.W_k(K) V = self.W_v(V) # Reshape cho multi-head: [batch, seq_len, num_heads, d_k] Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # Bây giờ: [batch, num_heads, seq_len, d_k] # 2. Scaled dot-product attention scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k) # [batch, num_heads, seq_len, seq_len] # 3. Áp dụng mask (cho causal masking trong decoder) if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) # 4. Softmax attention_weights = torch.softmax(scores, dim=-1) attention_weights = self.dropout(attention_weights) # 5. Nhân với value context = torch.matmul(attention_weights, V) # [batch, num_heads, seq_len, d_k] # 6. Ghép các đầu context = context.transpose(1, 2).contiguous() context = context.view(batch_size, -1, self.d_model) # 7. Phép chiếu tuyến tính cuối cùng output = self.W_o(context) return output Bước 4: Feed-Forward Network class FeedForward(nn.Module): def __init__(self, d_model, d_ff, dropout): super().__init__() self.linear1 = nn.Linear(d_model, d_ff) # 512 → 2048 self.linear2 = nn.Linear(d_ff, d_model) # 2048 → 512 self.relu = nn.ReLU() self.dropout = nn.Dropout(dropout) def forward(self, x): x = self.linear1(x) # Mở rộng x = self.relu(x) # Non-linearity x = self.dropout(x) # Regularization x = self.linear2(x) # Nén return x Bước 5: Causal Mask (để ngăn chặn attend vào tương lai) def create_causal_mask(seq_len, device): \u0026#34;\u0026#34;\u0026#34; Tạo một mask ngăn chặn attention tới các vị trí tương lai. Đầu Ra: [1, 0, 0, 0] [1, 1, 0, 0] [1, 1, 1, 0] [1, 1, 1, 1] Vị trí i chỉ có thể attend tới các vị trí 0...i \u0026#34;\u0026#34;\u0026#34; mask = torch.tril(torch.ones(seq_len, seq_len, device=device)) return mask.unsqueeze(0).unsqueeze(0) # [1, 1, seq_len, seq_len] # Sử Dụng: mask = create_causal_mask(seq_len=10, device=\u0026#39;cuda\u0026#39;) Vòng Lặp Huấn Luyện def train_transformer(model, train_loader, epochs=10, learning_rate=0.0001): optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) loss_fn = nn.CrossEntropyLoss() for epoch in range(epochs): total_loss = 0 for batch_idx, (input_ids, target_ids) in enumerate(train_loader): # Forward pass logits = model(input_ids) # logits: [batch, seq_len, vocab_size] # target_ids: [batch, seq_len] # Tính toán loss loss = loss_fn( logits.view(-1, vocab_size), target_ids.view(-1) ) # Backward pass optimizer.zero_grad() loss.backward() optimizer.step() total_loss += loss.item() print(f\u0026#34;Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\u0026#34;) Suy Luận (Tạo Văn Bản) def generate_text(model, start_token, max_length=50, device=\u0026#39;cuda\u0026#39;): \u0026#34;\u0026#34;\u0026#34; Tạo văn bản tự động sử dụng transformer được huấn luyện. \u0026#34;\u0026#34;\u0026#34; model.eval() generated = [start_token] with torch.no_grad(): for _ in range(max_length): # Chuẩn bị đầu vào input_ids = torch.tensor(generated, device=device).unsqueeze(0) # Forward pass logits = model(input_ids) # Lấy logits cho vị trí cuối cùng last_logits = logits[0, -1, :] # [vocab_size] # Lấy mẫu hoặc tham lam next_token = torch.argmax(last_logits).item() # Tham lam # Hoặc: next_token = torch.multinomial(softmax(last_logits), 1).item() # Lấy mẫu generated.append(next_token) if next_token == end_token: break return generated Ví Dụ Hoàn Chỉnh Hoạt Động # Khởi tạo mô hình model = TransformerDecoder( vocab_size=10000, d_model=512, num_layers=6, num_heads=8, d_ff=2048, max_seq_len=1024, dropout=0.1 ).to(\u0026#39;cuda\u0026#39;) # Tạo dữ liệu giả batch_size, seq_len = 32, 128 input_ids = torch.randint(0, 10000, (batch_size, seq_len)).to(\u0026#39;cuda\u0026#39;) # Forward pass output = model(input_ids) print(f\u0026#34;Output shape: {output.shape}\u0026#34;) # [32, 128, 10000] # Tạo causal mask mask = create_causal_mask(seq_len, \u0026#39;cuda\u0026#39;) # Forward với mask output_masked = model(input_ids, mask) print(f\u0026#34;Masked output shape: {output_masked.shape}\u0026#34;) # Tạo văn bản generated = generate_text(model, start_token=101, max_length=20) print(f\u0026#34;Generated sequence: {generated}\u0026#34;) Tóm Tắt Các Thành Phần Chính Thành Phần Mục Đích Kích Thước Embedding Token → Vector vocab_size → d_model Positional Encoding Thêm thông tin vị trí d_model Multi-Head Attention Học mối quan hệ d_model → d_model Feed-Forward Phép biến đổi phi tuyến d_model → d_ff → d_model LayerNorm Ổn định huấn luyện per-element Output Layer Chiếu tới vocab d_model → vocab_size Tại Sao Kiến Trúc Này Hoạt Động ✅ Xử Lý Song Song: Tất cả các vị trí được xử lý cùng nhau (nhanh!) ✅ Phụ Thuộc Dài Hạn: Attention trực tiếp tới bất kỳ vị trí nào (không có vanishing gradients!) ✅ Có Thể Diễn Giải: Có thể hình dung các mô hình attention ✅ Có Thể Mở Rộng: Có thể lớn lên tới hàng tỷ tham số\nCác Biến Thể GPT2 GPT-2 Small: 117M tham số GPT-2 Medium: 345M tham số GPT-2 Large: 762M tham số GPT-2 XL: 1.5B tham số Tất cả sử dụng kiến trúc decoder giống nhau, chỉ được mở rộng!\nBước Tiếp Theo Huấn Luyện Trước: Huấn luyện trên kho ngữ liệu văn bản lớn (Wikipedia, Sách, v.v.) Tinh Chỉnh: Điều chỉnh cho các tác vụ cụ thể (dịch, phân loại, v.v.) Đánh Giá: Đo chất lượng (perplexity, BLEU, đánh giá của con người) Triển Khai: Sử dụng cho các ứng dụng thực tế Tóm Tắt Tuần 9 Chúng ta đã bao quát:\n✅ Tại sao transformers thay thế RNNs ✅ Kiến trúc transformer hoàn chỉnh ✅ Cơ chế scaled dot-product attention ✅ Self, masked, và encoder-decoder attention ✅ Chi tiết triển khai và code Đây là nền tảng của NLP hiện đại! Tất cả các mô hình tiên tiến (BERT, GPT, T5, Claude, ChatGPT) đều dựa trên kiến trúc transformer.\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.10-week10/1.10.5-day50-2025-11-14/","title":"Ngày 50 - Thực hành fine-tuning","tags":[],"description":"","content":"Ngày: 2025-11-14 (Thứ Sáu)\nTrạng Thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nCông thức fine-tuning Tập trung vào các nút chỉnh: đóng băng tầng nào, lên lịch learning rate ra sao, và đánh giá setup transfer như thế nào.\nĐóng băng vs. train Đóng băng tầng thấp khi dữ liệu ít hoặc miền gần pre-train. Mở dần (từ trên xuống) nếu accuracy đứng yên. Thêm head đặc thù (classification/span QA/seq2seq) và bắt đầu từ đó. Hyperparameter cơ bản Learning rate: 1e-5 đến 3e-5 cho fine-tune toàn encoder; cao hơn nếu đa phần đóng băng. Warmup: ~5-10% số bước để ổn định giai đoạn đầu. Max sequence length: khớp tác vụ; chunk tài liệu dài cho QA. Vòng đánh giá Theo dõi loss + metric (EM/F1 cho QA, ROUGE cho tóm tắt, accuracy/F1 cho phân loại). Early stop theo dev; giữ checkpoint tốt nhất, không chỉ checkpoint cuối. So sánh baseline feature-based vs. fine-tune full trên một tập nhỏ. Khi triển khai Distill hoặc quantize nếu cần giảm độ trễ. Cache tokenizer và quy tắc cắt/truncate để tránh lệch train/serve. Log prompt/input để debug hành vi closed-book vs. có ngữ cảnh. Việc thực hành hôm nay Chạy (hoặc lập kế hoạch) grid nhỏ: learning rate, chiến lược đóng băng, max length. Đánh giá trên tập dev và ghi nhận EM/F1 hoặc ROUGE. Quyết định bước hậu huấn luyện: distillation, quantization, hoặc caching. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.11-week11/1.11.5-day55-2025-11-21/","title":"Ngày 55 - Scaling &amp; vận hành","tags":[],"description":"","content":"Ngày: 2025-11-21 (Thứ Sáu)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nScaling và kiểm soát chi phí Lên kế hoạch scale ở mức instance và multi-concurrency cho traffic ổn định nhưng giới hạn chi phí.\nGuardrail scale Giới hạn max vCPU cho capacity provider Chọn họ máy theo workload (compute/memory/network) Traffic ổn định: ưu tiên máy lớn + multi-concurrency; nếu quá biến động, cân nhắc ở lại Lambda mặc định Chi phí \u0026amp; giá Áp dụng Savings Plan/Reserved Instance cho công suất LMI Theo dõi sử dụng so với cam kết; điều chỉnh mix instance khi cần Checklist rollout Capacity provider đúng role/VPC/allowlist máy Function version đã publish; đường warm OK (không cold start) CloudWatch truy cập được; cảnh báo lỗi/độ trễ/concurrency Chạy benchmark so sánh LMI vs. Lambda mặc định cho workload của bạn "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.12-week12/1.12.5-day60-2025-11-28/","title":"Ngày 60 - Compute mới","tags":[],"description":"","content":"Ngày: 2025-11-28 (Thứ Sáu)\nTrạng Thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nGraviton5 và Trainium3 Graviton5: CPU thế hệ mới, giá/hiệu năng tốt hơn cho nhiều workload EC2 Trainium3 UltraServers (3nm): throughput train/inference cao hơn, chi phí thấp hơn Phân tích phù hợp Dịch vụ nào chuyển sang Graviton5 (web/app, xử lý dữ liệu) và mức tiết kiệm kỳ vọng Bài train/inference nào hưởng lợi từ Trainium3 so với GPU/CPU hiện tại Việc cần làm Chọn 1–2 dịch vụ benchmark Graviton5; theo dõi perf/chi phí Lập POC Trainium3 cho một model mục tiêu; so throughput và ngân sách Cập nhật kế hoạch capacity với họ máy và giá mới "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.5-week5/","title":"Tuần 5 - Bảo mật &amp; Danh tính trên AWS","tags":[],"description":"","content":"Tuần: 2025-10-06 đến 2025-10-10\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 5 Tuần này tập trung vào bảo mật và quản lý danh tính trên AWS.\nNội dung chính Mô hình Trách nhiệm chia sẻ. AWS IAM (Users, Groups, Roles, Policies). Amazon Cognito. AWS Organizations \u0026amp; SCPs. AWS Identity Center (SSO). AWS KMS. AWS Security Hub. Labs thực hành Lab 18: AWS Security Hub. Lab 22: AWS Lambda Automation with Slack. Lab 27: AWS Resource Groups \u0026amp; Tagging. Lab 28: IAM Cross-Region Role \u0026amp; Policy. Lab 30: IAM Restriction Policy. Lab 33: AWS KMS \u0026amp; CloudTrail Integration. Lab 44: IAM Advanced Role Control. Lab 48: IAM Access Keys \u0026amp; Roles. "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây API AI đơn giản với AWS Lambda + Bedrock + API Gateway Tổng quan Amazon Bedrock là dịch vụ fully managed cung cấp các mô hình ngôn ngữ lớn (LLM) như Claude, Llama, Mistral và Titan.\nBạn có thể tích hợp AI vào ứng dụng chỉ thông qua API mà không cần quản lý hạ tầng hay tự vận hành mô hình.\nTrong workshop này, bạn sẽ xây dựng một API AI Hỏi – Đáp (Q\u0026amp;A) đơn giản bằng cách kết hợp:\nAWS Lambda – xử lý request và gọi Bedrock Amazon Bedrock Runtime – gửi prompt và nhận kết quả từ mô hình Amazon API Gateway – tạo HTTP endpoint để client gửi câu hỏi Điểm quan trọng của workshop là bạn sẽ dùng Converse API – giao diện thống nhất cho các mô hình Bedrock có hỗ trợ Converse (ví dụ: Claude 3, Claude 3.5, Llama 3.1, Mistral 24.07…).\nNhờ đó:\nChỉ cần đổi modelId trong Lambda là có thể chuyển sang mô hình khác Không phải thay đổi logic xử lý conversation Dễ dàng thử nghiệm, so sánh nhiều mô hình trên cùng một API Lưu ý: Chỉ những mô hình Bedrock có hỗ trợ Converse API mới dùng được với code trong workshop này.\nNội dung Workshop Giới thiệu Chuẩn bị Lambda gọi Bedrock Tạo API Gateway Kiểm thử Dọn dẹp "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên (Cleanup) Sau khi hoàn thành workshop, bạn nên xóa các tài nguyên AWS không còn sử dụng để tránh phát sinh chi phí.\nDưới đây là danh sách các dịch vụ bạn đã tạo và cách xoá chúng.\n🔹 1. Xoá API Gateway Mở API Gateway Console Chọn API bạn đã tạo, ví dụ: bedrock-chatbot-api Chọn Actions → Delete Xác nhận xoá Điều này sẽ ngăn mọi request đến Lambda và tránh bị tính phí API.\n🔹 2. Xoá Lambda Function Mở Lambda Console Chọn hàm bedrock-chatbot-lambda Chọn Actions → Delete function Xác nhận xoá 🔹 3. Xoá IAM Role và Policy Xoá Policy: Mở IAM Console → Policies Tìm lambda-bedrock Bấm Delete Xoá Role: Mở IAM Console → Roles Tìm lambda-bedrock-role Bấm Delete ⚠️ Bạn chỉ xoá được Role sau khi đã xoá Lambda Function sử dụng nó.\n🔹 4. Kiểm tra CloudWatch Log Groups (tuỳ chọn) Log của Lambda vẫn còn trong CloudWatch và có thể chiếm dung lượng lưu trữ lâu dài.\nMở CloudWatch Console Chọn Logs → Log groups Tìm log của Lambda (ví dụ: /aws/lambda/bedrock-chatbot-lambda) Chọn Actions → Delete log group 🔹 5. Kiểm tra các tài nguyên khác (nếu có) Tuỳ theo cách bạn mở rộng workshop, bạn có thể đã tạo thêm các tài nguyên như:\nS3 bucket Step Functions KMS key VPC / Security Groups Nếu không dùng nữa, hãy xoá để tránh phí.\n🎉 Hoàn tất! Bạn đã dọn dẹp toàn bộ tài nguyên được tạo trong workshop này.\nGiờ tài khoản AWS của bạn sẽ không phát sinh thêm chi phí từ phần lab.\nCảm ơn bạn đã tham gia workshop!\n"},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.6-week6/","title":"Tuần 6 - AWS Database Services","tags":[],"description":"","content":"Tuần: 2025-10-13 đến 2025-10-17\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 6 Tuần này tập trung vào hệ sinh thái cơ sở dữ liệu trên AWS: từ dịch vụ quan hệ managed, NoSQL chuyên dụng, bộ nhớ đệm in-memory cho tới data warehouse phân tích.\nNội dung chính Database Fundamentals (RDBMS, NoSQL, OLTP vs OLAP) Amazon RDS \u0026amp; Aurora Amazon Redshift Amazon ElastiCache AWS Database Migration Service (DMS) Labs thực hành Lab 05: Amazon RDS \u0026amp; EC2 Integration Lab 43: AWS Database Migration Service (DMS) "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại First Cloud Journey (FCJ) - AWS từ ngày 8 tháng 9 năm 2025 đến ngày 28 tháng 11 năm 2025 (12 tuần), tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia nhiều lộ trình học tập về điện toán đám mây AWS và các dự án thực hành, qua đó cải thiện kỹ năng thiết kế kiến trúc đám mây, triển khai dịch vụ AWS, viết tài liệu kỹ thuật, dịch blog và phát triển workshop.\nCác Thành Tựu Chính Trong suốt thời gian thực tập, tôi đã hoàn thành các nhiệm vụ chính sau:\nHành Trình Học AWS (12 Tuần): Nghiên cứu có hệ thống các dịch vụ AWS cốt lõi bao gồm:\nKiến thức cơ bản về Điện toán Đám mây \u0026amp; AWS Well-Architected Framework Mạng (VPC, Load Balancing, VPN, Direct Connect) Compute (EC2, Auto Scaling, Lambda, Containers) Lưu trữ (S3, Glacier, EFS, FSx, Snow Family) Cơ sở dữ liệu (RDS, Aurora, DynamoDB, Redshift) Bảo mật \u0026amp; Danh tính (IAM, Cognito, KMS, Security Hub) Giám sát (CloudWatch, X-Ray, CloudTrail) Đề Xuất FitAI Challenge: Thiết kế kiến trúc serverless toàn diện cho ứng dụng tập thể dục được hỗ trợ bởi AI sử dụng các dịch vụ AWS bao gồm Lambda, API Gateway, SageMaker, Bedrock, S3, Cognito, v.v.\nDịch Blog: Dịch hơn 3 bài blog kỹ thuật AWS từ tiếng Anh sang tiếng Việt, bao gồm các chủ đề như:\nDi chuyển từ AWS CodeDeploy sang Amazon ECS blue/green deployments Tích hợp dữ liệu giữa Amazon SageMaker và Snowflake Các kế hoạch bảo vệ Amazon GuardDuty và Extended Threat Detection Phát Triển Workshop: Tạo workshop thực hành về \u0026ldquo;Truy cập Hybrid An toàn đến S3 sử dụng VPC Endpoints\u0026rdquo; bao gồm Gateway và Interface VPC endpoints.\nTham Gia Sự Kiện: Tham dự 2 sự kiện AWS lớn:\nVietnam Cloud Day 2025 (18 tháng 9 năm 2025) AWS GenAI Builder Club - AI-Driven Development Life Cycle (3 tháng 10 năm 2025) Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Điểm Mạnh Nền tảng kỹ thuật vững chắc: Đã học và áp dụng thành công nhiều dịch vụ AWS trên các lĩnh vực compute, storage, networking, database và security. Kỹ năng viết tài liệu: Tạo ra các tài liệu kỹ thuật chất lượng cao bao gồm proposal, blog dịch và tài liệu workshop. Làm việc nhóm \u0026amp; hợp tác: Tích cực tham gia các hoạt động nhóm và sự kiện AWS, kết nối với các thành viên FCJ và các chuyên gia trong ngành. Khả năng tự học: Thể hiện khả năng tự nghiên cứu các khái niệm đám mây phức tạp và thực hiện các bài lab thực hành. Cần Cải Thiện Nâng cao tính kỷ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ tổ chức nào Cải thiện tư duy giải quyết vấn đề và tiếp cận thách thức một cách có hệ thống hơn Nâng cao kỹ năng giao tiếp trong cả giao tiếp hằng ngày và trong công việc, xử lý tình huống hiệu quả Quản lý thời gian tốt hơn để đảm bảo đúng deadline một cách nhất quán "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.7-week7/","title":"Tuần 7 - Vertical Slice Delivery","tags":[],"description":"","content":"Tuần: 2025-10-20 đến 2025-10-24\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 7 Tuần này hoàn thiện vertical slice 0 cho dự án Ebook Demo, tập trung vào contract-first development và tự động hóa kiểm thử để có thể demo end-to-end sớm.\nNội dung chính Vertical Slice Architecture \u0026amp; phạm vi slice 0 Contract-first development với OpenAPI + Prism mock Next.js 16 App Router \u0026amp; Server Components FastAPI clean architecture và cấu hình CORS Schemathesis contract testing \u0026amp; retrospective Labs thực hành Checklist demo vertical slice 0 Mock API bằng Prism và kết nối Next.js Refactor backend FastAPI theo clean architecture Chạy Schemathesis và cập nhật workflow chuẩn "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.8-week8/","title":"Tuần 8 - Xử Lý Ngôn Ngữ Tự Nhiên &amp; Deep Learning","tags":[],"description":"","content":"Tuần: 2025-10-27 to 2025-10-31\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nTổng Quan Tuần 8 Tuần này cung cấp cái nhìn sâu rộng về Xử Lý Ngôn Ngữ Tự Nhiên (NLP), bao gồm nền tảng ngôn ngữ học, ứng dụng NLP hiện đại, kiến trúc sequence-to-sequence, và phương pháp đánh giá. Từ hiểu biết về âm vị học đến triển khai hệ thống dịch máy, tuần này kết nối lý thuyết và thực hành trong NLP.\nCác Chủ Đề Chính Nền Tảng Ngôn Ngữ Học Các thành phần cốt lõi: Âm Vị Học, Âm Vị Học, Hình Thái Học, Cú Pháp, Ngữ Nghĩa, Thực Dụng Hiểu cấu trúc ngôn ngữ ảnh hưởng đến thiết kế NLP như thế nào Ứng Dụng NLP Công cụ tìm kiếm và nhận dạng ý định Quảng cáo trực tuyến với NER và trích xuất mối quan hệ Trợ lý giọng nói và nhận dạng giọng nói Chatbot với pipeline NLU/NLG Hệ thống dịch máy Tóm tắt văn bản (extractive \u0026amp; abstractive) Kiến Trúc Deep Learning Mô hình Seq2seq với kiến trúc encoder-decoder LSTM chi tiết: forget gate, input gate, cell state, output gate Cơ chế Attention và self-attention Triển khai Neural Machine Translation (NMT) Đánh Giá \u0026amp; Decoding Điểm BLEU (dựa trên precision) Điểm ROUGE (dựa trên recall) Điểm F1 để đánh giá MT Beam search decoding Minimum Bayes Risk (MBR) sampling Phòng Thí Nghiệm Thực Hành Xây dựng workflow voicebot và chatbot Triển khai LSTM cho sequence modeling Tạo encoder-decoder với attention Neural machine translation end-to-end Đánh giá chất lượng dịch với BLEU/ROUGE Triển khai beam search và MBR "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.9-week9/","title":"Tuần 9 - Kiến Trúc &amp; Triển Khai Transformer","tags":[],"description":"","content":"Tuần: 2025-11-03 to 2025-11-07\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nTóm Tắt Tuần 9 Tuần này khám phá kiến trúc Transformer, một mô hình cách mạng thay thế RNNs trong NLP. Chúng ta sẽ hiểu tại sao cần transformers, cách chúng hoạt động bên trong, và triển khai chúng từ đầu. Từ các cơ chế attention đến thiết kế encoder-decoder đầy đủ, tuần này kết nối lý thuyết và triển khai thực tế.\nCác Chủ Đề Chính Hạn Chế của RNNs \u0026amp; Giới Thiệu Transformer Thắt cổ chai xử lý tuần tự trong RNNs Vấn đề Vanishing Gradient Thắt cổ chai thông tin với chuỗi dài Tại sao Attention là tất cả bạn cần Kiến Trúc Transformer Cấu trúc Encoder-Decoder Lớp Multi-head Attention Positional Encoding Residual Connections \u0026amp; Layer Normalization Feed-forward Networks Cơ Chế Attention Scale Dot-product Attention (cơ chế lõi) Self-attention (cùng một câu) Masked Attention (Decoder) Encoder-Decoder Attention Multi-head Attention để tính toán song song Transformer Decoder \u0026amp; GPT2 Positional Embeddings Decoder Block Implementation Feed-forward Layer Design Tính toán Xác suất Output Ứng Dụng \u0026amp; Các Mô Hình GPT-2 (Generative Pre-trained Transformer) BERT (Bidirectional Encoder Representations) T5 (Text-to-Text Transfer Transformer) Ứng dụng: Dịch, Phân loại, QA, Tóm tắt, Phân tích Cảm xúc Mục Tiêu Học Tập ✅ Hiểu hạn chế của RNN và tại sao transformers giải quyết chúng ✅ Nắm bắt kiến trúc transformer hoàn chỉnh ✅ Triển khai các cơ chế attention từ đầu ✅ Xây dựng transformer decoder (kiểu GPT2) ✅ Nhận biết các ứng dụng transformer và các mô hình tiên tiến Chia Nhỏ Theo Ngày Ngày Tập Trung Chủ Đề 41 Vấn Đề RNN Xử lý tuần tự, Vanishing Gradients, Thắt cổ chai thông tin 42 Tổng Quan Kiến Trúc Encoder-Decoder, Multi-head Attention, Positional Encoding 43 Lõi Attention Công thức Scale Dot-product, Phép toán ma trận, Hiệu quả GPU 44 Các Loại Attention Self-attention, Masked Attention, Encoder-Decoder Attention 45 Triển Khai Decoder Kiến trúc GPT2, Các khối xây dựng, Hướng dẫn Code Điều Kiện Tiên Quyết Hiểu biết sâu về RNNs, LSTMs, và attention từ Tuần 8 Thoải mái với phép toán ma trận và đại số tuyến tính Kiến thức PyTorch hoặc TensorFlow rất hữu ích Các Bước Tiếp Theo Học bài báo \u0026ldquo;Attention is All You Need\u0026rdquo; (Vaswani et al., 2017) Triển khai các thành phần transformer từng bước Thử nghiệm với các mô hình được huấn luyện trước (BERT, GPT-2, T5) "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.10-week10/","title":"Tuần 10 - Transfer Learning, BERT &amp; T5","tags":[],"description":"","content":"Tuần: 2025-11-10 đến 2025-11-14\nTrạng thái: \u0026ldquo;Đang thực hiện\u0026rdquo;\nTổng quan Tuần 10 Tuần này tập trung vào transfer learning cho NLP và cách QA hiện đại tận dụng transformer tiền huấn luyện. Ta so sánh huấn luyện truyền thống với reuse đặc trưng và fine-tuning, rồi đi vào hai mô hình tiêu biểu: BERT (ngữ cảnh hai chiều) và T5 (text-to-text đa nhiệm), kèm cách thiết lập QA có ngữ cảnh vs. closed-book.\nChủ đề chính Nền tảng Transfer Learning Pipeline truyền thống vs. pipeline transfer Tái dùng trọng số tiền huấn luyện để hội tụ nhanh hơn So sánh feature-based với fine-tuning Lợi ích: nhanh hơn, chính xác hơn, ít dữ liệu nhãn Hai chế độ Question Answering QA có ngữ cảnh (trích span/sinh ngắn dựa vào đoạn văn) QA closed-book (sinh câu trả lời không có context) Ảnh hưởng của chất lượng tiền huấn luyện lên QA BERT và ngữ cảnh hai chiều Masked Language Modeling cho embedding ngữ cảnh Next Sentence Prediction cho coherence mức câu Dùng cả trái và phải để dự đoán token Ứng dụng: QA, sentiment, phân loại T5 đa nhiệm text-to-text Định dạng text-to-text cho nhiều tác vụ Prompt chung cho rating, QA, tóm tắt, dịch Mở rộng dữ liệu (C4 so với Wikipedia) Chuyển giao đa nhiệm để tổng quát hóa tốt hơn Chiến lược dữ liệu \u0026amp; huấn luyện Pha trộn dữ liệu có nhãn/không nhãn; self-supervised masking Đóng băng backbone vs. thêm head Công thức fine-tuning cho QA/tóm tắt/dịch Mục tiêu học tập Giải thích khi nào nên dùng transfer thay vì huấn luyện từ đầu Phân biệt reuse đặc trưng và fine-tuning toàn bộ So sánh QA có ngữ cảnh và QA closed-book Tóm lược cách BERT và T5 tiền huấn luyện và chuyển giao Nêu vì sao transfer giúp giảm dữ liệu nhãn và thời gian train Lịch trong tuần Ngày Trọng tâm Chủ đề 46 Giới thiệu Transfer Pipeline truyền thống vs. transfer, reuse trọng số, feature-based vs. fine-tuning, lợi ích 47 Question Answering QA có ngữ cảnh vs. closed-book, nhu cầu dữ liệu, cách đánh giá 48 BERT hai chiều Masked LM, NSP, tận dụng ngữ cảnh hai phía cho dự đoán token 49 Mô hình T5 Prompt text-to-text, chia sẻ đa nhiệm, mở rộng dữ liệu (C4 vs. Wikipedia) 50 Thực hành fine-tuning Đóng băng/lộ trình unfreeze, downstream: QA, tóm tắt, dịch Yêu cầu nền tảng Nắm vững kiến trúc transformer từ Tuần 9 Thoải mái với attention và luồng encoder-decoder Cơ bản PyTorch/TensorFlow để fine-tune Bước tiếp theo Đọc paper BERT và T5 để hiểu mục tiêu pre-train Fine-tune thử model BERT QA (kiểu SQuAD span) Thử prompt T5 cho QA, tóm tắt, sentiment So sánh hiệu năng feature-based vs. fine-tune trên dữ liệu của bạn "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.11-week11/","title":"Tuần 11 - Lambda Managed Instances &amp; ghi chú re:Invent","tags":[],"description":"","content":"Tuần: 2025-11-17 đến 2025-11-21\nTrạng thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nTổng quan Tuần 11 Tóm tắt session AWS re:Invent 2025 (CNS382) về Lambda Managed Instances (LMI): chạy hàm Lambda trên EC2 do Lambda quản lý, giữ nguyên trải nghiệm serverless nhưng chọn được loại máy, giá EC2, và loại bỏ cold start. Trọng tâm: khi nào chọn LMI vs. Lambda mặc định, cách cấu hình capacity provider, và lưu ý test/ops cho workload lưu lượng ổn định.\nChủ đề chính Vì sao LMI Giữ trải nghiệm Lambda nhưng tự chọn họ máy EC2 và tận dụng Savings Plan/Reserved Instance Không cold start, hỗ trợ multi-concurrency trên instance Dễ dự báo chi phí với traffic ổn định Kiến trúc \u0026amp; Thiết lập Capacity Provider: cấu hình VPC, loại máy (C/M/R, x86/Graviton), guardrail scaling Quy trình: tạo capacity provider -\u0026gt; tạo function gắn provider -\u0026gt; publish version để khởi tạo instance Vòng đời do Lambda quản lý: patch OS/runtime, routing/auto scaling; thấy instance nhưng không can thiệp được Mạng \u0026amp; Bảo mật Toàn bộ egress đi qua ENI của instance trong VPC provider; không cấu hình VPC ở mức function Đóng inbound SG; đảm bảo đường ra tới dependency/CloudWatch (Internet hoặc PrivateLink) Mặc định mã hóa EBS, có thể dùng KMS của bạn Tính năng hàm \u0026amp; Scaling Hỗ trợ ZIP/OCI; runtime Java/Python/Node/.NET; layers, extensions, function URL, response streaming, durable functions Memory/CPU quyết định chọn instance; có thể giới hạn/loại trừ loại máy Guardrail scaling ở mức instance (vd max vCPU) để kiểm soát chi phí Phù hợp \u0026amp; Đánh đổi Dùng LMI cho workload lưu lượng cao, ổn định, hoặc cần compute/memory/network đặc thù Giữ Lambda mặc định cho traffic đột biến, ngắn Multi-concurrency + billing kiểu EC2 thay đổi bức tranh cost/perf Mục tiêu học tập Nêu khi nào chọn LMI thay vì Lambda mặc định Cấu hình capacity provider (VPC, role, loại máy, guardrail) Mô tả mô hình mạng và đường log của LMI Ghép tính năng Lambda (đóng gói, runtime, URL, streaming, durable) với LMI Đặt giới hạn scale/chi phí và chọn họ máy phù hợp workload Lịch trong tuần Ngày Trọng tâm Chủ đề 51 Tổng quan \u0026amp; use case Lợi ích LMI, tận dụng giá EC2, khi nào không dùng 52 Capacity Provider VPC, IAM operator role, shortlist loại máy, KMS, guardrail 53 Hàm trên LMI Đóng gói/runtime, ánh xạ memory/CPU, multi-concurrency, publish version 54 Mạng \u0026amp; quan sát Đường egress, CloudWatch, SG, logging, monitoring 55 Scaling \u0026amp; vận hành Max vCPU, kế hoạch traffic ổn định, kiểm soát chi phí, checklist rollout Yêu cầu nền tảng Nắm trải nghiệm Lambda và transformer từ tuần trước Kiến thức cơ bản EC2/VPC, IAM, CloudWatch Hiểu Savings Plan/Reserved Instance cho EC2 Bước tiếp theo Phác capacity provider cho workload mục tiêu (VPC, shortlist instance, guardrail) Lập kế hoạch benchmark LMI vs. Lambda mặc định theo traffic mẫu Vẽ đường giám sát/log (CloudWatch endpoint, PrivateLink nếu cần) Quyết định dùng SP/RI và mục tiêu multi-concurrency cho từng hàm "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/1-worklog/1.12-week12/","title":"Tuần 12 - Thông báo AWS re:Invent 2025","tags":[],"description":"","content":"Tuần: 2025-11-24 đến 2025-11-28\nTrạng thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nTổng quan Tuần 12 Tóm tắt re:Invent 2025: dòng Nova mới (speech-to-speech, đa phương thức, reasoning giá rẻ), Bedrock mở rộng (model open-weight, reinforcement fine-tuning), vector/AI hạ tầng (S3 Vectors GA), và phần cứng compute mới như Graviton5, Trainium3 UltraServers. Trọng tâm là lập kế hoạch áp dụng thực tế.\nChủ đề chính GenAI \u0026amp; Model Nova 2: Sonic (speech-to-speech), Lite (nhanh/rẻ), Omni (đa phương thức), Forge để huấn luyện frontier model tùy biến Nova Act cho agent UI ổn định; Bedrock AgentCore thêm policy/quality cho agent Bedrock bổ sung model open-weight (Mistral Large 3, Ministral 3) và reinforcement fine-tuning Vector \u0026amp; Dữ liệu Amazon S3 Vectors GA: tới 2B vector/index, ~100ms truy vấn, chi phí thấp hơn DB chuyên dụng Clean Rooms sinh dữ liệu tổng hợp bảo vệ riêng tư cho ML cộng tác Nền tảng AI Dev SageMaker AI với serverless MLflow; training checkpointless và elastic trên HyperPod Compute \u0026amp; Hardware Graviton5 CPU giá/hiệu năng tốt hơn trên EC2 Trainium3 UltraServers (3nm) cho train/inference nhanh và rẻ hơn Mục tiêu học tập Xác định launch AI/compute nào tác động tới workload hiện tại Lên pilot cho Nova và tính năng Bedrock mới Phác lộ trình chuyển sang S3 Vectors cho lưu trữ/search vector Đánh giá phù hợp Graviton5/Trainium3 cho mục tiêu cost/perf Lịch trong tuần Ngày Trọng tâm Chủ đề 56 Model mới Nova 2 (Sonic, Lite, Omni), Forge, Nova Act 57 Bedrock \u0026amp; Agent Model open-weight, reinforcement fine-tuning, AgentCore policy/quality 58 Vector \u0026amp; dữ liệu S3 Vectors GA, Clean Rooms synthetic, kế hoạch scale/chi phí 59 SageMaker Serverless MLflow, checkpointless \u0026amp; elastic training trên HyperPod 60 Compute mới Graviton5, Trainium3 UltraServers, checklist fit/migration Yêu cầu nền tảng Hiểu catalog Bedrock và khả năng agent Nắm kiến trúc vector search cơ bản Biết các họ EC2 và lựa chọn accelerator Bước tiếp theo Chọn 1 pilot cho Nova (speech/đa phương thức/reasoning) và lập kế hoạch đánh giá Lập POC chuyển sang S3 Vectors so với vector store hiện tại Đặt mục tiêu benchmark cho Graviton5/Trainium3 so với máy đang dùng Xác định yêu cầu governance/policy trước khi dùng AgentCore và Nova Act "},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://phuvo05.github.io/My-FCJ-Workshop/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]